{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§î Ensemble LearningÏùÄ Imbalanced DataÏóêÎèÑ Ìö®Í≥ºÍ∞Ä ÏûàÏùÑÍπå?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "# import fetch_california_housing as dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import copy\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F  \n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Distribution (Target Y) ÌôïÏù∏\n",
    "\n",
    "- DatasetÏùÑ ÌôïÏù∏ÌïòÏó¨ Imbalanced DataÏù∏ÏßÄ ÌôïÏù∏ÌïòÍ∏∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_distribution(y):\n",
    "    # View distribution\n",
    "    sns.distplot(y)\n",
    "    plt.xlabel('x values')\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = 'diabetes'\n",
    "# dataset_name = 'california_house'\n",
    "\n",
    "if dataset_name == 'diabetes':\n",
    "    x, y= datasets.load_diabetes(return_X_y=True)\n",
    "    threshold_rare = 270\n",
    "elif dataset_name == 'california_house':\n",
    "    data = datasets.fetch_california_housing()\n",
    "    x = data.data\n",
    "    y = data.target\n",
    "    threshold_rare = 3.5\n",
    "\n",
    "np.random.seed(seed=rand_seed)\n",
    "sample = np.random.choice(range(len(y)), 500)\n",
    "x_sample, y_sample = x[sample,:], y[sample]\n",
    "\n",
    "\n",
    "view_distribution(y_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape\n",
      "(442, 10)\n",
      "Y shape\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape\")\n",
    "print(x.shape)\n",
    "print(\"Y shape\")\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=rand_seed, train_size=0.8)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, random_state=rand_seed, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling by minmax scaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train :  282\n",
      "num valid :  71\n",
      "num test  :  89\n"
     ]
    }
   ],
   "source": [
    "print(\"num train : \", len(y_train))\n",
    "print(\"num valid : \", len(y_valid))\n",
    "print(\"num test  : \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3500\n",
    "BATCH_SIZE = 2048 \n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "NUM_INPUT = x_train.shape[1]\n",
    "NUM_OUTPUT = 1 \n",
    "NUM_1ST_HIDDEN = 32 \n",
    "NUM_2ND_HIDDEN = 16 \n",
    "NUM_1ST_DROPOUT = 0.6\n",
    "NUM_2ND_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "\n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainData(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "valid_data = TrainData(torch.FloatTensor(x_valid), torch.FloatTensor(y_valid))\n",
    "test_data = TestData(torch.FloatTensor(x_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=2048, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=256)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class BasicRegressor(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(BasicRegressor, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(NUM_INPUT, NUM_1ST_HIDDEN)\n",
    "        self.layer_2 = nn.Linear(NUM_1ST_HIDDEN, NUM_2ND_HIDDEN)\n",
    "        self.layer_out = nn.Linear(NUM_2ND_HIDDEN, NUM_OUTPUT)\n",
    "\n",
    "        # self.actvation = nn.ReLU()\n",
    "        self.actvation_1 = nn.ReLU()\n",
    "        self.actvation_2 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=NUM_1ST_DROPOUT)\n",
    "        self.dropout_2 = nn.Dropout(p=NUM_2ND_DROPOUT)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(NUM_1ST_HIDDEN)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(NUM_2ND_HIDDEN)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.actvation_1(self.layer_1(inputs))\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.actvation_2(self.layer_2(x))\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicRegressor(\n",
      "  (layer_1): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (layer_2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (actvation_1): ReLU()\n",
      "  (actvation_2): ReLU()\n",
      "  (dropout_1): Dropout(p=0.6, inplace=False)\n",
      "  (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "  (batchnorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BasicRegressor()\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_train_data, num_eval_data):\n",
    "\n",
    "    best_loss_on_valid = 999999999\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        eval_epoch_loss = 0\n",
    "        eval_epoch_acc = 0\n",
    "\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "        # acc = calc_accuracy(y_pred, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        # epoch_acc += acc.item()\n",
    "    \n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for x, y in valid_loader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "\n",
    "                    output = model(x)\n",
    "\n",
    "                    eval_loss = criterion(output, y)\n",
    "                # eval_acc = calc_accuracy(output, y)\n",
    "\n",
    "                    eval_epoch_loss += eval_loss.item()\n",
    "                # eval_epoch_acc += eval_acc.item()\n",
    "        \n",
    "            if best_loss_on_valid >= (eval_epoch_loss/num_eval_data):\n",
    "                best_loss_on_valid = (eval_epoch_loss/num_eval_data)\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print(\"Best Model is copied - Best Loss : \", best_loss_on_valid)\n",
    "        \n",
    "\n",
    "\n",
    "            print(f\"Epoch {epoch+0:03}: : Loss: T_{epoch_loss/num_train_data:.3f} V_{eval_epoch_loss/num_eval_data:.3f} | Acc: T_{epoch_acc/num_train_data:.3f}) V_{eval_epoch_acc/num_eval_data:.3f}\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y_pred, y_test):\n",
    "    mse_criterion = nn.L1Loss() \n",
    "    mse = mse_criterion(y_pred, y_test)\n",
    "\n",
    "    return mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l1(y_pred, y_test):\n",
    "    return np.abs(y_pred - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model is copied - Best Loss :  4854.703125\n",
      "Epoch 010: : Loss: T_3610.938 V_4854.703 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4755.359375\n",
      "Epoch 020: : Loss: T_3816.199 V_4755.359 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4683.79296875\n",
      "Epoch 030: : Loss: T_3795.449 V_4683.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 040: : Loss: T_3342.872 V_4695.897 | Acc: T_0.000) V_0.000\n",
      "Epoch 050: : Loss: T_3576.871 V_4724.002 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4645.56787109375\n",
      "Epoch 060: : Loss: T_3627.525 V_4645.568 | Acc: T_0.000) V_0.000\n",
      "Epoch 070: : Loss: T_4201.196 V_4716.375 | Acc: T_0.000) V_0.000\n",
      "Epoch 080: : Loss: T_4180.277 V_4703.083 | Acc: T_0.000) V_0.000\n",
      "Epoch 090: : Loss: T_4017.960 V_4719.386 | Acc: T_0.000) V_0.000\n",
      "Epoch 100: : Loss: T_3343.586 V_4721.548 | Acc: T_0.000) V_0.000\n",
      "Epoch 110: : Loss: T_3777.028 V_4752.033 | Acc: T_0.000) V_0.000\n",
      "Epoch 120: : Loss: T_3511.304 V_4823.896 | Acc: T_0.000) V_0.000\n",
      "Epoch 130: : Loss: T_3354.677 V_4772.962 | Acc: T_0.000) V_0.000\n",
      "Epoch 140: : Loss: T_3595.054 V_4729.743 | Acc: T_0.000) V_0.000\n",
      "Epoch 150: : Loss: T_3512.171 V_4752.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 160: : Loss: T_3589.121 V_4870.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 170: : Loss: T_3426.569 V_4788.629 | Acc: T_0.000) V_0.000\n",
      "Epoch 180: : Loss: T_3667.165 V_4713.004 | Acc: T_0.000) V_0.000\n",
      "Epoch 190: : Loss: T_3289.693 V_4743.298 | Acc: T_0.000) V_0.000\n",
      "Epoch 200: : Loss: T_3718.090 V_4807.362 | Acc: T_0.000) V_0.000\n",
      "Epoch 210: : Loss: T_4081.842 V_4756.842 | Acc: T_0.000) V_0.000\n",
      "Epoch 220: : Loss: T_3714.906 V_4734.966 | Acc: T_0.000) V_0.000\n",
      "Epoch 230: : Loss: T_3942.324 V_4735.218 | Acc: T_0.000) V_0.000\n",
      "Epoch 240: : Loss: T_3698.046 V_4779.802 | Acc: T_0.000) V_0.000\n",
      "Epoch 250: : Loss: T_4165.591 V_4762.507 | Acc: T_0.000) V_0.000\n",
      "Epoch 260: : Loss: T_4510.992 V_4815.374 | Acc: T_0.000) V_0.000\n",
      "Epoch 270: : Loss: T_3885.841 V_4709.801 | Acc: T_0.000) V_0.000\n",
      "Epoch 280: : Loss: T_3763.125 V_4722.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 290: : Loss: T_3495.872 V_4738.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 300: : Loss: T_3881.941 V_4659.799 | Acc: T_0.000) V_0.000\n",
      "Epoch 310: : Loss: T_4033.917 V_4689.149 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4581.763671875\n",
      "Epoch 320: : Loss: T_4057.333 V_4581.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 330: : Loss: T_3846.734 V_4681.748 | Acc: T_0.000) V_0.000\n",
      "Epoch 340: : Loss: T_3814.437 V_4649.462 | Acc: T_0.000) V_0.000\n",
      "Epoch 350: : Loss: T_4091.183 V_4644.251 | Acc: T_0.000) V_0.000\n",
      "Epoch 360: : Loss: T_3755.935 V_4699.003 | Acc: T_0.000) V_0.000\n",
      "Epoch 370: : Loss: T_3494.911 V_4702.280 | Acc: T_0.000) V_0.000\n",
      "Epoch 380: : Loss: T_3980.071 V_4712.460 | Acc: T_0.000) V_0.000\n",
      "Epoch 390: : Loss: T_3484.527 V_4678.389 | Acc: T_0.000) V_0.000\n",
      "Epoch 400: : Loss: T_3890.757 V_4685.102 | Acc: T_0.000) V_0.000\n",
      "Epoch 410: : Loss: T_3943.826 V_4779.712 | Acc: T_0.000) V_0.000\n",
      "Epoch 420: : Loss: T_3564.852 V_4826.930 | Acc: T_0.000) V_0.000\n",
      "Epoch 430: : Loss: T_3592.795 V_4817.118 | Acc: T_0.000) V_0.000\n",
      "Epoch 440: : Loss: T_3926.059 V_4735.386 | Acc: T_0.000) V_0.000\n",
      "Epoch 450: : Loss: T_3419.577 V_4732.512 | Acc: T_0.000) V_0.000\n",
      "Epoch 460: : Loss: T_4410.257 V_4800.214 | Acc: T_0.000) V_0.000\n",
      "Epoch 470: : Loss: T_3210.446 V_4738.373 | Acc: T_0.000) V_0.000\n",
      "Epoch 480: : Loss: T_3524.859 V_4718.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 490: : Loss: T_4028.930 V_4692.649 | Acc: T_0.000) V_0.000\n",
      "Epoch 500: : Loss: T_3792.526 V_4830.718 | Acc: T_0.000) V_0.000\n",
      "Epoch 510: : Loss: T_3479.177 V_4666.739 | Acc: T_0.000) V_0.000\n",
      "Epoch 520: : Loss: T_4199.941 V_4762.382 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_3893.307 V_4765.665 | Acc: T_0.000) V_0.000\n",
      "Epoch 540: : Loss: T_3955.610 V_4716.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 550: : Loss: T_3861.083 V_4760.862 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_3945.219 V_4701.890 | Acc: T_0.000) V_0.000\n",
      "Epoch 570: : Loss: T_3543.675 V_4698.072 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_3742.307 V_4756.840 | Acc: T_0.000) V_0.000\n",
      "Epoch 590: : Loss: T_3871.093 V_4644.370 | Acc: T_0.000) V_0.000\n",
      "Epoch 600: : Loss: T_3558.709 V_4604.397 | Acc: T_0.000) V_0.000\n",
      "Epoch 610: : Loss: T_3998.261 V_4709.052 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_3327.083 V_4689.628 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_3656.742 V_4749.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 640: : Loss: T_4034.672 V_4812.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 650: : Loss: T_3556.958 V_4715.471 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_3687.515 V_4657.025 | Acc: T_0.000) V_0.000\n",
      "Epoch 670: : Loss: T_3447.849 V_4709.123 | Acc: T_0.000) V_0.000\n",
      "Epoch 680: : Loss: T_3978.697 V_4771.888 | Acc: T_0.000) V_0.000\n",
      "Epoch 690: : Loss: T_3158.483 V_4649.492 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_3416.417 V_4694.590 | Acc: T_0.000) V_0.000\n",
      "Epoch 710: : Loss: T_4212.318 V_4794.894 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_4065.523 V_4811.218 | Acc: T_0.000) V_0.000\n",
      "Epoch 730: : Loss: T_3968.739 V_4771.583 | Acc: T_0.000) V_0.000\n",
      "Epoch 740: : Loss: T_3992.901 V_4669.370 | Acc: T_0.000) V_0.000\n",
      "Epoch 750: : Loss: T_3674.667 V_4678.444 | Acc: T_0.000) V_0.000\n",
      "Epoch 760: : Loss: T_4098.739 V_4703.724 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_3531.302 V_4795.467 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_4283.549 V_4761.925 | Acc: T_0.000) V_0.000\n",
      "Epoch 790: : Loss: T_4049.740 V_4737.456 | Acc: T_0.000) V_0.000\n",
      "Epoch 800: : Loss: T_3646.455 V_4792.208 | Acc: T_0.000) V_0.000\n",
      "Epoch 810: : Loss: T_3627.095 V_4777.592 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_4365.011 V_4749.478 | Acc: T_0.000) V_0.000\n",
      "Epoch 830: : Loss: T_3761.261 V_4731.161 | Acc: T_0.000) V_0.000\n",
      "Epoch 840: : Loss: T_3590.198 V_4751.925 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_3533.938 V_4744.236 | Acc: T_0.000) V_0.000\n",
      "Epoch 860: : Loss: T_3697.445 V_4748.454 | Acc: T_0.000) V_0.000\n",
      "Epoch 870: : Loss: T_3915.097 V_4759.996 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_3860.472 V_4774.845 | Acc: T_0.000) V_0.000\n",
      "Epoch 890: : Loss: T_4026.476 V_4763.913 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_3257.668 V_4748.542 | Acc: T_0.000) V_0.000\n",
      "Epoch 910: : Loss: T_3984.422 V_4792.560 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_3121.007 V_4733.741 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_3935.401 V_4815.425 | Acc: T_0.000) V_0.000\n",
      "Epoch 940: : Loss: T_4018.033 V_4712.403 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_3711.672 V_4754.313 | Acc: T_0.000) V_0.000\n",
      "Epoch 960: : Loss: T_4092.147 V_4694.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_3906.246 V_4719.339 | Acc: T_0.000) V_0.000\n",
      "Epoch 980: : Loss: T_3320.512 V_4625.270 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_3516.846 V_4837.033 | Acc: T_0.000) V_0.000\n",
      "Epoch 1000: : Loss: T_4283.502 V_4812.682 | Acc: T_0.000) V_0.000\n",
      "Epoch 1010: : Loss: T_4637.978 V_4785.724 | Acc: T_0.000) V_0.000\n",
      "Epoch 1020: : Loss: T_3596.750 V_4695.005 | Acc: T_0.000) V_0.000\n",
      "Epoch 1030: : Loss: T_3779.051 V_4764.723 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_3596.353 V_4691.687 | Acc: T_0.000) V_0.000\n",
      "Epoch 1050: : Loss: T_3408.353 V_4714.057 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_3992.825 V_4764.353 | Acc: T_0.000) V_0.000\n",
      "Epoch 1070: : Loss: T_3756.943 V_4837.204 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_4406.955 V_4781.994 | Acc: T_0.000) V_0.000\n",
      "Epoch 1090: : Loss: T_4033.038 V_4806.894 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_4215.011 V_4749.476 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_3876.096 V_4781.011 | Acc: T_0.000) V_0.000\n",
      "Epoch 1120: : Loss: T_3367.087 V_4754.216 | Acc: T_0.000) V_0.000\n",
      "Epoch 1130: : Loss: T_3214.025 V_4725.988 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_3844.003 V_4838.660 | Acc: T_0.000) V_0.000\n",
      "Epoch 1150: : Loss: T_3472.377 V_4796.293 | Acc: T_0.000) V_0.000\n",
      "Epoch 1160: : Loss: T_3950.213 V_4782.768 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_3426.752 V_4798.926 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_3619.901 V_4741.350 | Acc: T_0.000) V_0.000\n",
      "Epoch 1190: : Loss: T_3263.172 V_4674.255 | Acc: T_0.000) V_0.000\n",
      "Epoch 1200: : Loss: T_3845.094 V_4684.599 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_3750.609 V_4747.694 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_3472.016 V_4800.498 | Acc: T_0.000) V_0.000\n",
      "Epoch 1230: : Loss: T_3682.524 V_4784.019 | Acc: T_0.000) V_0.000\n",
      "Epoch 1240: : Loss: T_4091.792 V_4783.506 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_3601.758 V_4818.297 | Acc: T_0.000) V_0.000\n",
      "Epoch 1260: : Loss: T_3770.745 V_4791.944 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_3663.580 V_4752.236 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_3705.302 V_4776.214 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_4091.584 V_4816.096 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_3255.948 V_4766.013 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_3833.547 V_4725.877 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_3954.133 V_4668.149 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_3893.300 V_4798.562 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_3807.069 V_4794.958 | Acc: T_0.000) V_0.000\n",
      "Epoch 1350: : Loss: T_3549.710 V_4856.109 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_3786.917 V_4865.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_4125.839 V_4766.127 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_3973.493 V_4810.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_3811.017 V_4773.708 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_3723.652 V_4774.453 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_3523.039 V_4833.026 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_4068.559 V_4796.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 1430: : Loss: T_4137.448 V_4782.560 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_3790.218 V_4759.190 | Acc: T_0.000) V_0.000\n",
      "Epoch 1450: : Loss: T_3407.323 V_4762.380 | Acc: T_0.000) V_0.000\n",
      "Epoch 1460: : Loss: T_3628.858 V_4736.245 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_3834.316 V_4691.639 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_3823.543 V_4858.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 1490: : Loss: T_4089.384 V_4816.993 | Acc: T_0.000) V_0.000\n",
      "Epoch 1500: : Loss: T_3992.162 V_4854.626 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_3662.684 V_4785.199 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_3631.913 V_4774.328 | Acc: T_0.000) V_0.000\n",
      "Epoch 1530: : Loss: T_3577.246 V_4805.315 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_3631.145 V_4757.765 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_4029.125 V_4769.541 | Acc: T_0.000) V_0.000\n",
      "Epoch 1560: : Loss: T_3872.479 V_4831.302 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_3735.967 V_4794.813 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_3570.116 V_4719.587 | Acc: T_0.000) V_0.000\n",
      "Epoch 1590: : Loss: T_3718.457 V_4797.015 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_3608.830 V_4775.802 | Acc: T_0.000) V_0.000\n",
      "Epoch 1610: : Loss: T_3409.492 V_4811.388 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_3519.344 V_4804.435 | Acc: T_0.000) V_0.000\n",
      "Epoch 1630: : Loss: T_4154.273 V_4767.832 | Acc: T_0.000) V_0.000\n",
      "Epoch 1640: : Loss: T_3240.866 V_4810.206 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_4074.381 V_4810.211 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_3596.410 V_4822.305 | Acc: T_0.000) V_0.000\n",
      "Epoch 1670: : Loss: T_4145.850 V_4739.074 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_4101.769 V_4787.038 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_3776.323 V_4835.649 | Acc: T_0.000) V_0.000\n",
      "Epoch 1700: : Loss: T_4242.771 V_4874.829 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_3883.833 V_4919.941 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_3586.657 V_4894.185 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_3605.476 V_5012.303 | Acc: T_0.000) V_0.000\n",
      "Epoch 1740: : Loss: T_3477.866 V_4884.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_3854.790 V_4911.051 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_3783.308 V_4855.014 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_3929.239 V_4796.999 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_3245.240 V_4852.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 1790: : Loss: T_4004.745 V_4968.238 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_3409.916 V_4877.999 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_3571.568 V_4696.589 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_3510.417 V_4734.706 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_3726.548 V_4882.246 | Acc: T_0.000) V_0.000\n",
      "Epoch 1840: : Loss: T_3750.894 V_4795.328 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_3674.984 V_4782.318 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_3870.936 V_4914.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_3681.970 V_4870.194 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_4064.535 V_4913.186 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_3332.274 V_4824.288 | Acc: T_0.000) V_0.000\n",
      "Epoch 1900: : Loss: T_4290.126 V_4865.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_3495.226 V_4796.851 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_4079.750 V_4778.246 | Acc: T_0.000) V_0.000\n",
      "Epoch 1930: : Loss: T_3703.086 V_4820.253 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_3947.821 V_4771.905 | Acc: T_0.000) V_0.000\n",
      "Epoch 1950: : Loss: T_3674.434 V_5023.088 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_3736.305 V_4894.332 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_3766.262 V_4867.155 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_4020.901 V_4810.848 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_3942.888 V_4827.564 | Acc: T_0.000) V_0.000\n",
      "Epoch 2000: : Loss: T_3535.700 V_4859.616 | Acc: T_0.000) V_0.000\n",
      "Epoch 2010: : Loss: T_3857.465 V_4839.976 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_3805.979 V_4900.851 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_4351.255 V_4863.632 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_3842.470 V_4880.036 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_4102.827 V_4800.709 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_3805.702 V_4858.849 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_3808.946 V_4876.187 | Acc: T_0.000) V_0.000\n",
      "Epoch 2080: : Loss: T_3828.458 V_4844.748 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_3791.746 V_4910.889 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_3437.061 V_4800.377 | Acc: T_0.000) V_0.000\n",
      "Epoch 2110: : Loss: T_3062.449 V_4779.390 | Acc: T_0.000) V_0.000\n",
      "Epoch 2120: : Loss: T_3574.858 V_4830.339 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_4436.535 V_4823.720 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_3424.783 V_4826.572 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_3866.249 V_4880.045 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_3628.394 V_4862.929 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_3930.268 V_4962.163 | Acc: T_0.000) V_0.000\n",
      "Epoch 2180: : Loss: T_3291.927 V_4857.506 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_3087.127 V_4886.301 | Acc: T_0.000) V_0.000\n",
      "Epoch 2200: : Loss: T_3376.042 V_5018.448 | Acc: T_0.000) V_0.000\n",
      "Epoch 2210: : Loss: T_3612.972 V_4776.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_3618.845 V_4806.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_3433.295 V_4838.122 | Acc: T_0.000) V_0.000\n",
      "Epoch 2240: : Loss: T_4033.115 V_4894.221 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4168.977 V_4774.332 | Acc: T_0.000) V_0.000\n",
      "Epoch 2260: : Loss: T_4021.125 V_4877.854 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_3583.393 V_4912.678 | Acc: T_0.000) V_0.000\n",
      "Epoch 2280: : Loss: T_3763.790 V_4810.835 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_3592.970 V_4876.919 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4161.150 V_4806.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_3396.382 V_4941.752 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_4420.311 V_4928.626 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_3957.903 V_4830.901 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_3832.046 V_4896.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4261.264 V_4769.333 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_3849.763 V_4800.063 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_4334.423 V_4806.243 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_3339.188 V_4831.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_3511.142 V_4947.214 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_3624.147 V_4757.689 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_3383.101 V_4806.194 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_3499.559 V_4845.533 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3744.023 V_4853.105 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_3409.836 V_4818.977 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_3557.561 V_4780.758 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_3466.814 V_4751.565 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_3804.329 V_4826.194 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_3542.572 V_4862.927 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_3643.435 V_4909.235 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_3580.285 V_4862.152 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4161.511 V_4879.029 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_3692.550 V_4810.841 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_3786.495 V_4859.053 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_3617.288 V_4974.917 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_3573.449 V_4828.585 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_3898.690 V_4752.112 | Acc: T_0.000) V_0.000\n",
      "Epoch 2570: : Loss: T_3842.772 V_4756.890 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3690.560 V_4804.340 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3417.039 V_4883.806 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_3632.336 V_4820.635 | Acc: T_0.000) V_0.000\n",
      "Epoch 2610: : Loss: T_4109.078 V_4861.334 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3703.062 V_4860.955 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_3635.483 V_4969.456 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_3547.982 V_4820.651 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4144.728 V_4827.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3286.666 V_4849.627 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_3710.945 V_4844.994 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3397.033 V_4864.410 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3839.721 V_4859.083 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3852.700 V_4845.761 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_2933.546 V_4755.654 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3758.054 V_4899.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3442.451 V_4847.090 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3788.010 V_4848.003 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3364.840 V_4899.913 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3937.602 V_4897.433 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3976.756 V_4914.976 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3481.792 V_4788.163 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_3938.771 V_4819.903 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3518.492 V_4869.584 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3613.891 V_4929.567 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3331.044 V_4855.503 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4069.047 V_4863.043 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3931.418 V_4906.934 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_4165.276 V_4889.580 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3393.002 V_4820.868 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3628.214 V_4815.890 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3958.943 V_4744.141 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3125.866 V_4798.315 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3759.941 V_4918.556 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3771.678 V_4695.451 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_3885.446 V_4888.926 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3808.804 V_4835.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3660.616 V_4861.445 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3696.130 V_4818.028 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_4097.114 V_4910.244 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3606.449 V_4883.747 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3302.970 V_4734.741 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3956.383 V_4719.917 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3827.199 V_4884.046 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3673.178 V_4838.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_4030.121 V_4827.306 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3523.652 V_4956.826 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3711.291 V_4920.657 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_4043.129 V_4838.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_2985.730 V_4816.754 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3803.095 V_4767.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3556.312 V_4830.070 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3592.137 V_4889.912 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3421.882 V_4781.293 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_4128.541 V_4780.990 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_3406.712 V_4840.375 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3898.269 V_4854.619 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3722.478 V_4766.319 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3663.198 V_4925.730 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3122.435 V_4907.073 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_4164.345 V_4746.928 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3435.210 V_4918.917 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_2498.129 V_4918.325 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_3900.660 V_4812.705 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3716.028 V_4937.112 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3974.170 V_4894.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3795.937 V_4790.238 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_4184.271 V_4826.718 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3589.305 V_4874.223 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3607.331 V_4764.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_3582.462 V_4841.904 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_4000.750 V_4873.971 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3869.658 V_4830.983 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3776.594 V_4881.856 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3708.420 V_4847.133 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3542.218 V_4825.875 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_4828.248 V_4893.650 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_4063.794 V_4881.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3679.681 V_4792.942 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3501.505 V_4795.556 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3940.121 V_4732.950 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3412.269 V_4835.574 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_4180.404 V_4912.075 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3706.198 V_4874.968 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3622.283 V_4762.539 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3554.308 V_4726.584 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3830.026 V_4915.612 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3502.450 V_4823.032 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3541.892 V_4768.609 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_4194.396 V_4746.922 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3563.550 V_4785.849 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3442.231 V_4851.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3985.282 V_4802.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3605.462 V_4801.792 | Acc: T_0.000) V_0.000\n"
     ]
    }
   ],
   "source": [
    "num_train_data = len(train_loader)\n",
    "num_eval_data = len(valid_loader)\n",
    "\n",
    "\n",
    "elapsed_time_basic_ann = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "best_model = train_model(num_train_data, num_eval_data)\n",
    "\n",
    "\n",
    "elapsed_time_basic_ann.append((datetime.now()-start_time).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time  [15.53642, 0.001251]\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "data = torch.from_numpy(x_test).float().to(device)\n",
    "answer = torch.from_numpy(y_test).float().to(device)\n",
    "\n",
    "# data = torch.from_numpy(x_train).float().to(device)\n",
    "# answer = torch.from_numpy(y_train_onehot).float().to(device)\n",
    "\n",
    "# data = torch.from_numpy(x_valid).float().to(device)\n",
    "# answer = torch.from_numpy(y_valid_onehot).float().to(device)\n",
    "\n",
    "start_time = datetime.now()\n",
    "output = best_model(data)\n",
    "loss_basic_ann = calc_loss(output, answer)\n",
    "elapsed_time_basic_ann.append((datetime.now()-start_time).total_seconds())\n",
    "\n",
    "# print('Accuracy ', acc_basic_ann)\n",
    "print('elapsed time ', elapsed_time_basic_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_distribution(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l1_loss_by_shots(output, answer):\n",
    "    l1_loss = calc_l1(output, answer)\n",
    "    rare_indicies = np.where(y_test>threshold_rare)[0]\n",
    "    # print(rare_indicies)\n",
    "\n",
    "\n",
    "    normal_indicies = np.where(y_test<=threshold_rare)[0]\n",
    "    # print(normal_indicies)\n",
    "\n",
    "\n",
    "    avg_rare_l1 = np.average(l1_loss[rare_indicies])\n",
    "    avg_normal_l1 = np.average(l1_loss[normal_indicies])\n",
    "    avg_total_l1 = np.average(l1_loss)\n",
    "\n",
    "    return avg_rare_l1, avg_normal_l1, avg_total_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare Loss  92.18011\n",
      "Normal Loss  39.84448\n",
      "Total Loss  46.900967\n"
     ]
    }
   ],
   "source": [
    "rare_loss, normal_loss, total_loss = calc_l1_loss_by_shots(output.detach().numpy(), answer.detach().numpy())\n",
    "print(\"Rare Loss \", rare_loss)\n",
    "print(\"Normal Loss \", normal_loss)\n",
    "print(\"Total Loss \", total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENSEMBLE_MODELS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model is copied - Best Loss :  31848.21875\n",
      "Epoch 010: : Loss: T_26657.176 V_31848.219 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31774.376953125\n",
      "Epoch 020: : Loss: T_26603.459 V_31774.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31728.28515625\n",
      "Epoch 030: : Loss: T_26607.461 V_31728.285 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31701.048828125\n",
      "Epoch 040: : Loss: T_26589.430 V_31701.049 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31679.810546875\n",
      "Epoch 050: : Loss: T_26553.770 V_31679.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31651.96875\n",
      "Epoch 060: : Loss: T_26506.652 V_31651.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31624.3125\n",
      "Epoch 070: : Loss: T_26513.510 V_31624.312 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31591.384765625\n",
      "Epoch 080: : Loss: T_26444.135 V_31591.385 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31564.087890625\n",
      "Epoch 090: : Loss: T_26406.002 V_31564.088 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31527.904296875\n",
      "Epoch 100: : Loss: T_26395.213 V_31527.904 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31494.0703125\n",
      "Epoch 110: : Loss: T_26330.008 V_31494.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31434.947265625\n",
      "Epoch 120: : Loss: T_26295.939 V_31434.947 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31389.521484375\n",
      "Epoch 130: : Loss: T_26260.039 V_31389.521 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31327.623046875\n",
      "Epoch 140: : Loss: T_26212.939 V_31327.623 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31259.25\n",
      "Epoch 150: : Loss: T_26149.855 V_31259.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31217.666015625\n",
      "Epoch 160: : Loss: T_26062.232 V_31217.666 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31133.31640625\n",
      "Epoch 170: : Loss: T_25987.219 V_31133.316 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31021.0390625\n",
      "Epoch 180: : Loss: T_25897.119 V_31021.039 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30922.75\n",
      "Epoch 190: : Loss: T_25881.170 V_30922.750 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30851.10546875\n",
      "Epoch 200: : Loss: T_25826.389 V_30851.105 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30800.365234375\n",
      "Epoch 210: : Loss: T_25677.965 V_30800.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30761.9296875\n",
      "Epoch 220: : Loss: T_25646.951 V_30761.930 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30611.982421875\n",
      "Epoch 230: : Loss: T_25601.525 V_30611.982 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30409.232421875\n",
      "Epoch 240: : Loss: T_25477.789 V_30409.232 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30298.955078125\n",
      "Epoch 250: : Loss: T_25400.197 V_30298.955 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30220.017578125\n",
      "Epoch 260: : Loss: T_25264.428 V_30220.018 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30100.548828125\n",
      "Epoch 270: : Loss: T_25212.762 V_30100.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29976.115234375\n",
      "Epoch 280: : Loss: T_25172.854 V_29976.115 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29923.865234375\n",
      "Epoch 290: : Loss: T_24950.635 V_29923.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29782.78125\n",
      "Epoch 300: : Loss: T_24899.316 V_29782.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29711.13671875\n",
      "Epoch 310: : Loss: T_24888.832 V_29711.137 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29610.630859375\n",
      "Epoch 320: : Loss: T_24670.686 V_29610.631 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29317.353515625\n",
      "Epoch 330: : Loss: T_24634.705 V_29317.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29063.44921875\n",
      "Epoch 340: : Loss: T_24461.834 V_29063.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 350: : Loss: T_24478.457 V_29113.326 | Acc: T_0.000) V_0.000\n",
      "Epoch 360: : Loss: T_24326.414 V_29120.477 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28966.1328125\n",
      "Epoch 370: : Loss: T_24247.525 V_28966.133 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28696.423828125\n",
      "Epoch 380: : Loss: T_24102.529 V_28696.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 390: : Loss: T_23953.514 V_28711.768 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28551.07421875\n",
      "Epoch 400: : Loss: T_23699.049 V_28551.074 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28271.5390625\n",
      "Epoch 410: : Loss: T_23838.594 V_28271.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27932.193359375\n",
      "Epoch 420: : Loss: T_23575.932 V_27932.193 | Acc: T_0.000) V_0.000\n",
      "Epoch 430: : Loss: T_23539.053 V_27941.725 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27793.376953125\n",
      "Epoch 440: : Loss: T_23520.859 V_27793.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27772.080078125\n",
      "Epoch 450: : Loss: T_23176.109 V_27772.080 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27542.1328125\n",
      "Epoch 460: : Loss: T_23241.238 V_27542.133 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27375.5625\n",
      "Epoch 470: : Loss: T_22913.469 V_27375.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27166.7890625\n",
      "Epoch 480: : Loss: T_22953.781 V_27166.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27087.46484375\n",
      "Epoch 490: : Loss: T_22915.125 V_27087.465 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26803.015625\n",
      "Epoch 500: : Loss: T_22610.738 V_26803.016 | Acc: T_0.000) V_0.000\n",
      "Epoch 510: : Loss: T_22683.791 V_26808.242 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26735.63671875\n",
      "Epoch 520: : Loss: T_22330.762 V_26735.637 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26410.263671875\n",
      "Epoch 530: : Loss: T_22267.000 V_26410.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26216.658203125\n",
      "Epoch 540: : Loss: T_22143.285 V_26216.658 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25896.021484375\n",
      "Epoch 550: : Loss: T_22063.570 V_25896.021 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25639.123046875\n",
      "Epoch 560: : Loss: T_22113.730 V_25639.123 | Acc: T_0.000) V_0.000\n",
      "Epoch 570: : Loss: T_21704.816 V_25720.783 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25590.732421875\n",
      "Epoch 580: : Loss: T_21639.994 V_25590.732 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25221.693359375\n",
      "Epoch 590: : Loss: T_21419.291 V_25221.693 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25017.11328125\n",
      "Epoch 600: : Loss: T_21196.908 V_25017.113 | Acc: T_0.000) V_0.000\n",
      "Epoch 610: : Loss: T_21022.334 V_25068.514 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24730.75\n",
      "Epoch 620: : Loss: T_21052.529 V_24730.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_21124.586 V_24954.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24620.373046875\n",
      "Epoch 640: : Loss: T_20989.629 V_24620.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24429.443359375\n",
      "Epoch 650: : Loss: T_20593.207 V_24429.443 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24268.734375\n",
      "Epoch 660: : Loss: T_20171.457 V_24268.734 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23918.267578125\n",
      "Epoch 670: : Loss: T_20542.855 V_23918.268 | Acc: T_0.000) V_0.000\n",
      "Epoch 680: : Loss: T_20402.121 V_24031.152 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23623.078125\n",
      "Epoch 690: : Loss: T_20232.828 V_23623.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23591.326171875\n",
      "Epoch 700: : Loss: T_19867.867 V_23591.326 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23475.830078125\n",
      "Epoch 710: : Loss: T_19429.711 V_23475.830 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23247.962890625\n",
      "Epoch 720: : Loss: T_19680.086 V_23247.963 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23126.0625\n",
      "Epoch 730: : Loss: T_19377.490 V_23126.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23020.71875\n",
      "Epoch 740: : Loss: T_19283.531 V_23020.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22667.212890625\n",
      "Epoch 750: : Loss: T_19070.025 V_22667.213 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22229.115234375\n",
      "Epoch 760: : Loss: T_19275.459 V_22229.115 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_19209.002 V_22294.379 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22204.86328125\n",
      "Epoch 780: : Loss: T_18581.404 V_22204.863 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21936.3984375\n",
      "Epoch 790: : Loss: T_18455.381 V_21936.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21864.251953125\n",
      "Epoch 800: : Loss: T_18460.346 V_21864.252 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21349.26171875\n",
      "Epoch 810: : Loss: T_18272.430 V_21349.262 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_18533.443 V_21444.807 | Acc: T_0.000) V_0.000\n",
      "Epoch 830: : Loss: T_18214.957 V_21426.822 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21096.0625\n",
      "Epoch 840: : Loss: T_17859.656 V_21096.062 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_17739.066 V_21134.553 | Acc: T_0.000) V_0.000\n",
      "Epoch 860: : Loss: T_17583.744 V_21178.328 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20753.955078125\n",
      "Epoch 870: : Loss: T_17475.014 V_20753.955 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20409.86328125\n",
      "Epoch 880: : Loss: T_17843.020 V_20409.863 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20363.7890625\n",
      "Epoch 890: : Loss: T_17616.314 V_20363.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19972.78125\n",
      "Epoch 900: : Loss: T_17529.191 V_19972.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19949.0625\n",
      "Epoch 910: : Loss: T_17131.566 V_19949.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19830.5859375\n",
      "Epoch 920: : Loss: T_17007.617 V_19830.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19557.60546875\n",
      "Epoch 930: : Loss: T_17022.061 V_19557.605 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19531.9453125\n",
      "Epoch 940: : Loss: T_16882.412 V_19531.945 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_16611.521 V_19576.850 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19369.1875\n",
      "Epoch 960: : Loss: T_16630.588 V_19369.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19152.2890625\n",
      "Epoch 970: : Loss: T_16470.299 V_19152.289 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18646.35546875\n",
      "Epoch 980: : Loss: T_16013.574 V_18646.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_15856.678 V_18654.520 | Acc: T_0.000) V_0.000\n",
      "Epoch 1000: : Loss: T_15992.348 V_18712.645 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18479.4375\n",
      "Epoch 1010: : Loss: T_15262.881 V_18479.438 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18345.20703125\n",
      "Epoch 1020: : Loss: T_15231.154 V_18345.207 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18083.771484375\n",
      "Epoch 1030: : Loss: T_15300.689 V_18083.771 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17874.560546875\n",
      "Epoch 1040: : Loss: T_15010.766 V_17874.561 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17850.984375\n",
      "Epoch 1050: : Loss: T_15069.727 V_17850.984 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_14969.896 V_17861.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17430.947265625\n",
      "Epoch 1070: : Loss: T_14469.771 V_17430.947 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17343.25\n",
      "Epoch 1080: : Loss: T_14604.680 V_17343.250 | Acc: T_0.000) V_0.000\n",
      "Epoch 1090: : Loss: T_14614.377 V_17515.098 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16775.775390625\n",
      "Epoch 1100: : Loss: T_14492.365 V_16775.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_14187.330 V_16930.986 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16721.837890625\n",
      "Epoch 1120: : Loss: T_14359.497 V_16721.838 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16600.19140625\n",
      "Epoch 1130: : Loss: T_14222.624 V_16600.191 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_13859.911 V_16765.898 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16339.423828125\n",
      "Epoch 1150: : Loss: T_13819.594 V_16339.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16179.0\n",
      "Epoch 1160: : Loss: T_13448.241 V_16179.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16112.396484375\n",
      "Epoch 1170: : Loss: T_13182.750 V_16112.396 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15791.96484375\n",
      "Epoch 1180: : Loss: T_13077.226 V_15791.965 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15648.2197265625\n",
      "Epoch 1190: : Loss: T_13548.287 V_15648.220 | Acc: T_0.000) V_0.000\n",
      "Epoch 1200: : Loss: T_13228.778 V_15664.366 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15302.283203125\n",
      "Epoch 1210: : Loss: T_13286.824 V_15302.283 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_12593.882 V_15493.509 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15185.4521484375\n",
      "Epoch 1230: : Loss: T_13062.292 V_15185.452 | Acc: T_0.000) V_0.000\n",
      "Epoch 1240: : Loss: T_12406.732 V_15210.504 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14415.7509765625\n",
      "Epoch 1250: : Loss: T_12406.405 V_14415.751 | Acc: T_0.000) V_0.000\n",
      "Epoch 1260: : Loss: T_12260.971 V_14702.500 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14383.80859375\n",
      "Epoch 1270: : Loss: T_12149.661 V_14383.809 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_11997.096 V_14586.995 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_12002.512 V_14405.294 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13869.783203125\n",
      "Epoch 1300: : Loss: T_11783.743 V_13869.783 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_11598.023 V_13952.861 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13821.94140625\n",
      "Epoch 1320: : Loss: T_11971.192 V_13821.941 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_11179.005 V_14031.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11580.726 V_13839.263 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13714.8076171875\n",
      "Epoch 1350: : Loss: T_10753.342 V_13714.808 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13460.5390625\n",
      "Epoch 1360: : Loss: T_10811.539 V_13460.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12737.58203125\n",
      "Epoch 1370: : Loss: T_10835.863 V_12737.582 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_10753.752 V_13122.774 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_10619.709 V_13009.310 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_10448.354 V_13107.844 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12377.01171875\n",
      "Epoch 1410: : Loss: T_11113.888 V_12377.012 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_10286.376 V_12817.350 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12145.9345703125\n",
      "Epoch 1430: : Loss: T_10244.347 V_12145.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_10204.303 V_12296.083 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11791.767578125\n",
      "Epoch 1450: : Loss: T_9769.140 V_11791.768 | Acc: T_0.000) V_0.000\n",
      "Epoch 1460: : Loss: T_9713.140 V_11945.788 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11316.7080078125\n",
      "Epoch 1470: : Loss: T_9889.669 V_11316.708 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_9484.147 V_11557.449 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11290.59375\n",
      "Epoch 1490: : Loss: T_9606.805 V_11290.594 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11149.7724609375\n",
      "Epoch 1500: : Loss: T_9240.717 V_11149.772 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_9244.335 V_11316.022 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_8929.432 V_11490.267 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11104.19921875\n",
      "Epoch 1530: : Loss: T_8995.131 V_11104.199 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10609.9990234375\n",
      "Epoch 1540: : Loss: T_8750.150 V_10609.999 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_8832.950 V_10965.120 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10296.146484375\n",
      "Epoch 1560: : Loss: T_8383.569 V_10296.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_8717.641 V_10392.603 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_8734.364 V_10368.076 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9697.533203125\n",
      "Epoch 1590: : Loss: T_8049.922 V_9697.533 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_8803.613 V_10002.562 | Acc: T_0.000) V_0.000\n",
      "Epoch 1610: : Loss: T_8479.995 V_10025.369 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_7789.184 V_10067.270 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9677.298828125\n",
      "Epoch 1630: : Loss: T_8268.764 V_9677.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9590.587890625\n",
      "Epoch 1640: : Loss: T_8464.924 V_9590.588 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9450.88671875\n",
      "Epoch 1650: : Loss: T_7820.949 V_9450.887 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9371.9423828125\n",
      "Epoch 1660: : Loss: T_7752.575 V_9371.942 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8914.3740234375\n",
      "Epoch 1670: : Loss: T_7765.714 V_8914.374 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_7601.930 V_9362.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_7846.089 V_9316.923 | Acc: T_0.000) V_0.000\n",
      "Epoch 1700: : Loss: T_7893.104 V_8966.692 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_7235.195 V_8925.534 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8701.6611328125\n",
      "Epoch 1720: : Loss: T_7234.523 V_8701.661 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_7093.180 V_8746.002 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8676.4755859375\n",
      "Epoch 1740: : Loss: T_6966.637 V_8676.476 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8623.884765625\n",
      "Epoch 1750: : Loss: T_6922.587 V_8623.885 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8433.234375\n",
      "Epoch 1760: : Loss: T_7628.453 V_8433.234 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8298.005859375\n",
      "Epoch 1770: : Loss: T_6522.821 V_8298.006 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_7174.314 V_8344.657 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7979.78369140625\n",
      "Epoch 1790: : Loss: T_6868.618 V_7979.784 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_6286.608 V_8071.195 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_6281.401 V_8041.268 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_6810.905 V_8128.026 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7952.20849609375\n",
      "Epoch 1830: : Loss: T_6548.396 V_7952.208 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7928.9365234375\n",
      "Epoch 1840: : Loss: T_6377.759 V_7928.937 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7609.61083984375\n",
      "Epoch 1850: : Loss: T_6399.662 V_7609.611 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_5817.334 V_7637.950 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7586.0009765625\n",
      "Epoch 1870: : Loss: T_5948.949 V_7586.001 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_6002.818 V_7679.488 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7357.23779296875\n",
      "Epoch 1890: : Loss: T_6872.142 V_7357.238 | Acc: T_0.000) V_0.000\n",
      "Epoch 1900: : Loss: T_5408.189 V_7380.320 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_5753.884 V_7368.997 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7310.22900390625\n",
      "Epoch 1920: : Loss: T_6116.778 V_7310.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7201.349609375\n",
      "Epoch 1930: : Loss: T_5026.766 V_7201.350 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7199.85205078125\n",
      "Epoch 1940: : Loss: T_6131.144 V_7199.852 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7047.3251953125\n",
      "Epoch 1950: : Loss: T_5736.433 V_7047.325 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7044.71044921875\n",
      "Epoch 1960: : Loss: T_5343.907 V_7044.710 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6653.13916015625\n",
      "Epoch 1970: : Loss: T_5424.292 V_6653.139 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_5382.125 V_6953.375 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_5005.790 V_6914.660 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6625.98388671875\n",
      "Epoch 2000: : Loss: T_5847.652 V_6625.984 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6463.09130859375\n",
      "Epoch 2010: : Loss: T_4881.258 V_6463.091 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_5232.768 V_6489.618 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6371.9794921875\n",
      "Epoch 2030: : Loss: T_5510.807 V_6371.979 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6124.08984375\n",
      "Epoch 2040: : Loss: T_5130.166 V_6124.090 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_4921.581 V_6464.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5190.229 V_6185.835 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_4921.696 V_6269.408 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6100.90673828125\n",
      "Epoch 2080: : Loss: T_4846.511 V_6100.907 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5392.688 V_6189.138 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5936.017578125\n",
      "Epoch 2100: : Loss: T_4768.411 V_5936.018 | Acc: T_0.000) V_0.000\n",
      "Epoch 2110: : Loss: T_4691.230 V_6061.555 | Acc: T_0.000) V_0.000\n",
      "Epoch 2120: : Loss: T_4744.074 V_6090.746 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5669.35205078125\n",
      "Epoch 2130: : Loss: T_4387.987 V_5669.352 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_4028.836 V_5958.174 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_4358.586 V_5938.860 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_4564.270 V_5731.593 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_4922.272 V_5739.537 | Acc: T_0.000) V_0.000\n",
      "Epoch 2180: : Loss: T_4570.772 V_5803.690 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5594.923828125\n",
      "Epoch 2190: : Loss: T_4945.706 V_5594.924 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5357.63134765625\n",
      "Epoch 2200: : Loss: T_4718.074 V_5357.631 | Acc: T_0.000) V_0.000\n",
      "Epoch 2210: : Loss: T_4681.594 V_5498.584 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5304.8427734375\n",
      "Epoch 2220: : Loss: T_4505.693 V_5304.843 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_5109.659 V_5468.611 | Acc: T_0.000) V_0.000\n",
      "Epoch 2240: : Loss: T_4015.524 V_5470.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_3855.273 V_5318.035 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5291.15673828125\n",
      "Epoch 2260: : Loss: T_4603.405 V_5291.157 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5250.00048828125\n",
      "Epoch 2270: : Loss: T_4190.421 V_5250.000 | Acc: T_0.000) V_0.000\n",
      "Epoch 2280: : Loss: T_4265.803 V_5308.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_4253.485 V_5281.370 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5170.33740234375\n",
      "Epoch 2300: : Loss: T_4127.184 V_5170.337 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_3698.523 V_5178.087 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5054.2451171875\n",
      "Epoch 2320: : Loss: T_4585.418 V_5054.245 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4992.59619140625\n",
      "Epoch 2330: : Loss: T_4044.886 V_4992.596 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_3676.752 V_5043.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4984.0302734375\n",
      "Epoch 2350: : Loss: T_4294.292 V_4984.030 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_3549.800 V_5076.922 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4880.35498046875\n",
      "Epoch 2370: : Loss: T_3438.257 V_4880.355 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4829.828125\n",
      "Epoch 2380: : Loss: T_3943.410 V_4829.828 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4144.028 V_4962.330 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4060.002 V_5020.587 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4727.1318359375\n",
      "Epoch 2410: : Loss: T_4411.319 V_4727.132 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_3855.083 V_4781.976 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3843.800 V_4841.484 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_3873.477 V_4755.462 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_4098.230 V_4882.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4642.71630859375\n",
      "Epoch 2460: : Loss: T_4449.595 V_4642.716 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4100.049 V_4773.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4634.7626953125\n",
      "Epoch 2480: : Loss: T_4006.370 V_4634.763 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_3563.276 V_4696.196 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4627.4169921875\n",
      "Epoch 2500: : Loss: T_3908.196 V_4627.417 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_3662.998 V_4642.810 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_4231.990 V_4734.714 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_3610.778 V_4774.063 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_4183.260 V_4627.421 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4599.66064453125\n",
      "Epoch 2550: : Loss: T_3699.179 V_4599.661 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_3780.323 V_4662.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4580.78857421875\n",
      "Epoch 2570: : Loss: T_3622.114 V_4580.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3652.146 V_4605.204 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3707.724 V_4606.087 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4566.55615234375\n",
      "Epoch 2600: : Loss: T_3664.975 V_4566.556 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4481.775390625\n",
      "Epoch 2610: : Loss: T_3873.781 V_4481.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3292.998 V_4489.247 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_3683.691 V_4539.215 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4435.74560546875\n",
      "Epoch 2640: : Loss: T_3359.672 V_4435.746 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4319.35009765625\n",
      "Epoch 2650: : Loss: T_3981.013 V_4319.350 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3378.333 V_4461.854 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_3824.177 V_4466.597 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3904.785 V_4336.354 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3639.548 V_4455.339 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3433.382 V_4359.198 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_3486.029 V_4330.958 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3978.138 V_4376.330 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_4012.272 V_4412.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4185.92626953125\n",
      "Epoch 2740: : Loss: T_3769.301 V_4185.926 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3752.669 V_4272.666 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3520.762 V_4288.842 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_4048.527 V_4287.642 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3169.111 V_4359.917 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_3581.419 V_4209.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3173.917 V_4310.172 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3317.555 V_4272.091 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3624.748 V_4242.662 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4092.841 V_4220.882 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3681.946 V_4214.700 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_2998.522 V_4241.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3310.008 V_4261.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3161.323 V_4209.783 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4154.8740234375\n",
      "Epoch 2880: : Loss: T_3930.067 V_4154.874 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3549.475 V_4230.340 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3651.529 V_4251.514 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3238.364 V_4305.323 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_3625.269 V_4249.767 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4100.56787109375\n",
      "Epoch 2930: : Loss: T_3670.222 V_4100.568 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3612.796 V_4169.593 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3327.239 V_4165.247 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3889.584 V_4272.861 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3568.333 V_4178.848 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3396.741 V_4231.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3439.316 V_4186.664 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3305.944 V_4226.132 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3141.975 V_4285.416 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3538.828 V_4321.691 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3142.641 V_4331.088 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3645.288 V_4177.190 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3386.668 V_4172.078 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3385.599 V_4322.223 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3655.296 V_4134.940 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3256.709 V_4222.011 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3314.189 V_4333.548 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3334.084 V_4262.632 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3451.004 V_4361.884 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_3358.634 V_4245.645 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_4157.972 V_4180.745 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3928.998 V_4244.493 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4088.864013671875\n",
      "Epoch 3150: : Loss: T_3387.887 V_4088.864 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3129.245 V_4180.920 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3802.885 V_4233.786 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3362.683 V_4125.296 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3335.208 V_4179.950 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_2939.852 V_4252.926 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3433.460 V_4184.401 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3301.442 V_4131.059 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3636.720 V_4251.262 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3682.122 V_4173.270 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3675.135 V_4290.190 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3469.220 V_4313.532 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4057.361328125\n",
      "Epoch 3270: : Loss: T_3848.542 V_4057.361 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4052.146240234375\n",
      "Epoch 3280: : Loss: T_3441.859 V_4052.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3154.063 V_4144.095 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4050.786865234375\n",
      "Epoch 3300: : Loss: T_3448.666 V_4050.787 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3433.332 V_4151.343 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3443.672 V_4056.823 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4043.742919921875\n",
      "Epoch 3330: : Loss: T_4029.103 V_4043.743 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3183.892 V_4139.223 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3886.241 V_4140.259 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3482.401 V_4172.644 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3249.518 V_4224.042 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3941.811 V_4119.564 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3803.533 V_4071.844 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3952.648 V_4113.121 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4025.673828125\n",
      "Epoch 3410: : Loss: T_3369.166 V_4025.674 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3720.416 V_4104.820 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3216.118 V_4106.070 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3931.548 V_4195.649 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3185.912 V_4088.991 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3391.871 V_4166.417 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_4060.951 V_4039.277 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3129.618 V_4152.384 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3576.745 V_4095.400 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3617.013 V_4128.958 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31867.74609375\n",
      "Epoch 010: : Loss: T_28194.369 V_31867.746 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31838.21484375\n",
      "Epoch 020: : Loss: T_28154.662 V_31838.215 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31794.240234375\n",
      "Epoch 030: : Loss: T_28125.449 V_31794.240 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31743.75\n",
      "Epoch 040: : Loss: T_28095.572 V_31743.750 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31692.75390625\n",
      "Epoch 050: : Loss: T_28060.107 V_31692.754 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31651.654296875\n",
      "Epoch 060: : Loss: T_28019.664 V_31651.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31610.04296875\n",
      "Epoch 070: : Loss: T_27974.002 V_31610.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31574.93359375\n",
      "Epoch 080: : Loss: T_27942.891 V_31574.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31538.908203125\n",
      "Epoch 090: : Loss: T_27874.467 V_31538.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31497.4375\n",
      "Epoch 100: : Loss: T_27813.371 V_31497.438 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31450.728515625\n",
      "Epoch 110: : Loss: T_27781.619 V_31450.729 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31403.697265625\n",
      "Epoch 120: : Loss: T_27687.365 V_31403.697 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31345.763671875\n",
      "Epoch 130: : Loss: T_27625.379 V_31345.764 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31312.583984375\n",
      "Epoch 140: : Loss: T_27599.355 V_31312.584 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31273.865234375\n",
      "Epoch 150: : Loss: T_27442.863 V_31273.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31229.294921875\n",
      "Epoch 160: : Loss: T_27361.980 V_31229.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31142.2890625\n",
      "Epoch 170: : Loss: T_27336.932 V_31142.289 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31029.70703125\n",
      "Epoch 180: : Loss: T_27316.777 V_31029.707 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30891.84765625\n",
      "Epoch 190: : Loss: T_27145.568 V_30891.848 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30800.009765625\n",
      "Epoch 200: : Loss: T_27109.203 V_30800.010 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30675.373046875\n",
      "Epoch 210: : Loss: T_27048.428 V_30675.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30648.15234375\n",
      "Epoch 220: : Loss: T_26955.725 V_30648.152 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30602.5703125\n",
      "Epoch 230: : Loss: T_26847.025 V_30602.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30459.345703125\n",
      "Epoch 240: : Loss: T_26795.195 V_30459.346 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30358.408203125\n",
      "Epoch 250: : Loss: T_26573.410 V_30358.408 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30332.087890625\n",
      "Epoch 260: : Loss: T_26482.477 V_30332.088 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30269.990234375\n",
      "Epoch 270: : Loss: T_26401.613 V_30269.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30011.919921875\n",
      "Epoch 280: : Loss: T_26352.711 V_30011.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29882.5625\n",
      "Epoch 290: : Loss: T_26178.105 V_29882.562 | Acc: T_0.000) V_0.000\n",
      "Epoch 300: : Loss: T_26178.373 V_29888.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29706.57421875\n",
      "Epoch 310: : Loss: T_25960.410 V_29706.574 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29666.705078125\n",
      "Epoch 320: : Loss: T_25923.031 V_29666.705 | Acc: T_0.000) V_0.000\n",
      "Epoch 330: : Loss: T_25752.363 V_29667.223 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29397.080078125\n",
      "Epoch 340: : Loss: T_25667.613 V_29397.080 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29125.634765625\n",
      "Epoch 350: : Loss: T_25843.828 V_29125.635 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29019.650390625\n",
      "Epoch 360: : Loss: T_25410.480 V_29019.650 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28911.455078125\n",
      "Epoch 370: : Loss: T_25381.527 V_28911.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 380: : Loss: T_25146.639 V_29011.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28725.548828125\n",
      "Epoch 390: : Loss: T_25369.297 V_28725.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28441.7265625\n",
      "Epoch 400: : Loss: T_24958.375 V_28441.727 | Acc: T_0.000) V_0.000\n",
      "Epoch 410: : Loss: T_24842.303 V_28561.389 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28236.541015625\n",
      "Epoch 420: : Loss: T_24617.744 V_28236.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27946.990234375\n",
      "Epoch 430: : Loss: T_24516.674 V_27946.990 | Acc: T_0.000) V_0.000\n",
      "Epoch 440: : Loss: T_24368.529 V_28099.072 | Acc: T_0.000) V_0.000\n",
      "Epoch 450: : Loss: T_24195.787 V_28115.982 | Acc: T_0.000) V_0.000\n",
      "Epoch 460: : Loss: T_24154.596 V_27962.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27561.16796875\n",
      "Epoch 470: : Loss: T_23880.246 V_27561.168 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27404.640625\n",
      "Epoch 480: : Loss: T_23892.686 V_27404.641 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27368.478515625\n",
      "Epoch 490: : Loss: T_23874.572 V_27368.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27198.607421875\n",
      "Epoch 500: : Loss: T_23525.482 V_27198.607 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26996.865234375\n",
      "Epoch 510: : Loss: T_23371.990 V_26996.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26573.447265625\n",
      "Epoch 520: : Loss: T_23381.490 V_26573.447 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_22972.314 V_26602.861 | Acc: T_0.000) V_0.000\n",
      "Epoch 540: : Loss: T_23269.875 V_26593.410 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26397.08203125\n",
      "Epoch 550: : Loss: T_22970.516 V_26397.082 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26132.05078125\n",
      "Epoch 560: : Loss: T_22765.029 V_26132.051 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26123.5703125\n",
      "Epoch 570: : Loss: T_22762.090 V_26123.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25990.80078125\n",
      "Epoch 580: : Loss: T_22627.588 V_25990.801 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25856.62109375\n",
      "Epoch 590: : Loss: T_22348.693 V_25856.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25635.75\n",
      "Epoch 600: : Loss: T_22034.316 V_25635.750 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25252.58984375\n",
      "Epoch 610: : Loss: T_22048.629 V_25252.590 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_22103.221 V_25253.039 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25084.5703125\n",
      "Epoch 630: : Loss: T_21740.564 V_25084.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24927.189453125\n",
      "Epoch 640: : Loss: T_21544.260 V_24927.189 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24806.990234375\n",
      "Epoch 650: : Loss: T_21435.074 V_24806.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24453.833984375\n",
      "Epoch 660: : Loss: T_21305.641 V_24453.834 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24383.646484375\n",
      "Epoch 670: : Loss: T_21084.645 V_24383.646 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24235.134765625\n",
      "Epoch 680: : Loss: T_21231.852 V_24235.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24065.294921875\n",
      "Epoch 690: : Loss: T_20593.201 V_24065.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23637.232421875\n",
      "Epoch 700: : Loss: T_20473.490 V_23637.232 | Acc: T_0.000) V_0.000\n",
      "Epoch 710: : Loss: T_20724.762 V_23666.383 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23514.44140625\n",
      "Epoch 720: : Loss: T_20521.018 V_23514.441 | Acc: T_0.000) V_0.000\n",
      "Epoch 730: : Loss: T_20078.061 V_23589.184 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23263.044921875\n",
      "Epoch 740: : Loss: T_20199.566 V_23263.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22978.20703125\n",
      "Epoch 750: : Loss: T_19834.898 V_22978.207 | Acc: T_0.000) V_0.000\n",
      "Epoch 760: : Loss: T_19963.066 V_23056.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22585.822265625\n",
      "Epoch 770: : Loss: T_19506.760 V_22585.822 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22430.919921875\n",
      "Epoch 780: : Loss: T_19406.344 V_22430.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22400.064453125\n",
      "Epoch 790: : Loss: T_19729.574 V_22400.064 | Acc: T_0.000) V_0.000\n",
      "Epoch 800: : Loss: T_18987.684 V_22465.465 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21856.630859375\n",
      "Epoch 810: : Loss: T_19100.240 V_21856.631 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_19038.139 V_22042.867 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21575.990234375\n",
      "Epoch 830: : Loss: T_18522.104 V_21575.990 | Acc: T_0.000) V_0.000\n",
      "Epoch 840: : Loss: T_18700.064 V_21863.668 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21372.9375\n",
      "Epoch 850: : Loss: T_18466.824 V_21372.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21206.900390625\n",
      "Epoch 860: : Loss: T_18116.160 V_21206.900 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20869.447265625\n",
      "Epoch 870: : Loss: T_17849.057 V_20869.447 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20569.12109375\n",
      "Epoch 880: : Loss: T_18156.064 V_20569.121 | Acc: T_0.000) V_0.000\n",
      "Epoch 890: : Loss: T_17877.490 V_20776.729 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_17206.148 V_20642.805 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20514.708984375\n",
      "Epoch 910: : Loss: T_18151.748 V_20514.709 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20426.166015625\n",
      "Epoch 920: : Loss: T_17480.766 V_20426.166 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19835.623046875\n",
      "Epoch 930: : Loss: T_17444.039 V_19835.623 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19826.580078125\n",
      "Epoch 940: : Loss: T_16960.617 V_19826.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19803.12890625\n",
      "Epoch 950: : Loss: T_16949.922 V_19803.129 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19667.818359375\n",
      "Epoch 960: : Loss: T_17149.219 V_19667.818 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16713.885 V_19730.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19181.6171875\n",
      "Epoch 980: : Loss: T_16534.605 V_19181.617 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_16259.396 V_19242.715 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18985.494140625\n",
      "Epoch 1000: : Loss: T_16409.557 V_18985.494 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18768.8203125\n",
      "Epoch 1010: : Loss: T_15972.254 V_18768.820 | Acc: T_0.000) V_0.000\n",
      "Epoch 1020: : Loss: T_15881.324 V_18813.457 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18552.59765625\n",
      "Epoch 1030: : Loss: T_15558.674 V_18552.598 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18142.28125\n",
      "Epoch 1040: : Loss: T_15724.729 V_18142.281 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17871.38671875\n",
      "Epoch 1050: : Loss: T_15873.993 V_17871.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_15002.578 V_18193.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17792.025390625\n",
      "Epoch 1070: : Loss: T_15100.933 V_17792.025 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17559.46875\n",
      "Epoch 1080: : Loss: T_14873.582 V_17559.469 | Acc: T_0.000) V_0.000\n",
      "Epoch 1090: : Loss: T_14895.604 V_17714.348 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14923.600 V_17678.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17218.357421875\n",
      "Epoch 1110: : Loss: T_14754.111 V_17218.357 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16883.880859375\n",
      "Epoch 1120: : Loss: T_14492.617 V_16883.881 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16814.42578125\n",
      "Epoch 1130: : Loss: T_14335.595 V_16814.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14345.577 V_16849.613 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16725.26953125\n",
      "Epoch 1150: : Loss: T_14284.867 V_16725.270 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16588.763671875\n",
      "Epoch 1160: : Loss: T_13724.622 V_16588.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_13824.991 V_16620.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16438.53515625\n",
      "Epoch 1180: : Loss: T_13266.297 V_16438.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16013.126953125\n",
      "Epoch 1190: : Loss: T_13622.520 V_16013.127 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15992.9775390625\n",
      "Epoch 1200: : Loss: T_13787.367 V_15992.978 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15876.861328125\n",
      "Epoch 1210: : Loss: T_13304.812 V_15876.861 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15659.263671875\n",
      "Epoch 1220: : Loss: T_12956.803 V_15659.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15357.6845703125\n",
      "Epoch 1230: : Loss: T_12967.195 V_15357.685 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15343.822265625\n",
      "Epoch 1240: : Loss: T_13317.470 V_15343.822 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_12902.485 V_15552.954 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14836.951171875\n",
      "Epoch 1260: : Loss: T_13429.387 V_14836.951 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_12596.312 V_15276.294 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_12756.819 V_14946.737 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_12660.344 V_14913.889 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14617.0390625\n",
      "Epoch 1300: : Loss: T_12030.366 V_14617.039 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14445.9208984375\n",
      "Epoch 1310: : Loss: T_11883.005 V_14445.921 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_11868.929 V_14551.870 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14146.2998046875\n",
      "Epoch 1330: : Loss: T_12030.407 V_14146.300 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13935.70703125\n",
      "Epoch 1340: : Loss: T_11830.837 V_13935.707 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13767.2568359375\n",
      "Epoch 1350: : Loss: T_11740.640 V_13767.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_11313.464 V_14033.574 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11332.516 V_14037.744 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13237.736328125\n",
      "Epoch 1380: : Loss: T_11099.229 V_13237.736 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_11142.177 V_13526.391 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13176.7763671875\n",
      "Epoch 1400: : Loss: T_11334.228 V_13176.776 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12923.8798828125\n",
      "Epoch 1410: : Loss: T_10998.278 V_12923.880 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_11235.332 V_12930.094 | Acc: T_0.000) V_0.000\n",
      "Epoch 1430: : Loss: T_11377.606 V_12988.546 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12751.775390625\n",
      "Epoch 1440: : Loss: T_10726.310 V_12751.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 1450: : Loss: T_10815.604 V_13018.449 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12392.251953125\n",
      "Epoch 1460: : Loss: T_10330.188 V_12392.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_10406.923 V_12550.049 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_10305.234 V_12464.445 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12298.4619140625\n",
      "Epoch 1490: : Loss: T_10419.322 V_12298.462 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11844.21875\n",
      "Epoch 1500: : Loss: T_9462.622 V_11844.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_10299.363 V_11937.644 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11521.5478515625\n",
      "Epoch 1520: : Loss: T_9890.800 V_11521.548 | Acc: T_0.000) V_0.000\n",
      "Epoch 1530: : Loss: T_9588.952 V_12032.256 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_9423.704 V_11675.972 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11493.0654296875\n",
      "Epoch 1550: : Loss: T_9172.622 V_11493.065 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11153.6357421875\n",
      "Epoch 1560: : Loss: T_8477.296 V_11153.636 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11080.4443359375\n",
      "Epoch 1570: : Loss: T_9602.022 V_11080.444 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10981.17578125\n",
      "Epoch 1580: : Loss: T_9744.543 V_10981.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10767.5107421875\n",
      "Epoch 1590: : Loss: T_9130.068 V_10767.511 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10616.763671875\n",
      "Epoch 1600: : Loss: T_9126.890 V_10616.764 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10482.501953125\n",
      "Epoch 1610: : Loss: T_8662.981 V_10482.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_8489.509 V_10838.389 | Acc: T_0.000) V_0.000\n",
      "Epoch 1630: : Loss: T_8814.249 V_10658.259 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10221.0556640625\n",
      "Epoch 1640: : Loss: T_8443.735 V_10221.056 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_8453.583 V_10229.603 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_8405.698 V_10378.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10091.2197265625\n",
      "Epoch 1670: : Loss: T_8346.842 V_10091.220 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10003.9208984375\n",
      "Epoch 1680: : Loss: T_7868.387 V_10003.921 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9662.3681640625\n",
      "Epoch 1690: : Loss: T_8117.318 V_9662.368 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9332.0654296875\n",
      "Epoch 1700: : Loss: T_8040.521 V_9332.065 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_8347.912 V_9593.049 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_8660.867 V_9414.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_8154.004 V_9352.116 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9015.197265625\n",
      "Epoch 1740: : Loss: T_7437.617 V_9015.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_7580.519 V_9026.889 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_7529.560 V_9063.155 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8754.7978515625\n",
      "Epoch 1770: : Loss: T_7459.364 V_8754.798 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_6968.117 V_8776.889 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8740.6259765625\n",
      "Epoch 1790: : Loss: T_6969.664 V_8740.626 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8662.359375\n",
      "Epoch 1800: : Loss: T_7059.078 V_8662.359 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8563.5634765625\n",
      "Epoch 1810: : Loss: T_7253.009 V_8563.563 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8544.029296875\n",
      "Epoch 1820: : Loss: T_6684.364 V_8544.029 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8396.0625\n",
      "Epoch 1830: : Loss: T_6862.993 V_8396.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8119.13818359375\n",
      "Epoch 1840: : Loss: T_6907.744 V_8119.138 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6620.868 V_8163.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8051.21826171875\n",
      "Epoch 1860: : Loss: T_6877.060 V_8051.218 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_7224.718 V_8236.644 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_6696.915 V_8138.530 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7885.0087890625\n",
      "Epoch 1890: : Loss: T_6509.835 V_7885.009 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7808.2333984375\n",
      "Epoch 1900: : Loss: T_6151.339 V_7808.233 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7542.96923828125\n",
      "Epoch 1910: : Loss: T_5990.116 V_7542.969 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6064.970 V_7718.957 | Acc: T_0.000) V_0.000\n",
      "Epoch 1930: : Loss: T_6309.227 V_7753.175 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_5983.730 V_7606.935 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7285.771484375\n",
      "Epoch 1950: : Loss: T_5827.904 V_7285.771 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_5747.815 V_7561.700 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7175.88134765625\n",
      "Epoch 1970: : Loss: T_6244.561 V_7175.881 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_6184.559 V_7409.427 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7083.05029296875\n",
      "Epoch 1990: : Loss: T_5963.474 V_7083.050 | Acc: T_0.000) V_0.000\n",
      "Epoch 2000: : Loss: T_5930.572 V_7237.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6977.095703125\n",
      "Epoch 2010: : Loss: T_5615.367 V_6977.096 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_6336.910 V_7005.530 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6896.44921875\n",
      "Epoch 2030: : Loss: T_5345.810 V_6896.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_5620.839 V_6954.967 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6814.92529296875\n",
      "Epoch 2050: : Loss: T_5344.469 V_6814.925 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6581.02880859375\n",
      "Epoch 2060: : Loss: T_5369.444 V_6581.029 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_5717.226 V_6748.448 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6433.75341796875\n",
      "Epoch 2080: : Loss: T_5530.698 V_6433.753 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6046.49560546875\n",
      "Epoch 2090: : Loss: T_4712.885 V_6046.496 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_4859.370 V_6536.373 | Acc: T_0.000) V_0.000\n",
      "Epoch 2110: : Loss: T_5194.113 V_6242.640 | Acc: T_0.000) V_0.000\n",
      "Epoch 2120: : Loss: T_4669.536 V_6138.409 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_5399.186 V_6181.499 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_4997.995 V_6216.389 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_5454.103 V_6242.461 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_4957.386 V_6413.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_4841.755 V_6047.521 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5766.89111328125\n",
      "Epoch 2180: : Loss: T_5460.685 V_5766.891 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_5058.867 V_6052.780 | Acc: T_0.000) V_0.000\n",
      "Epoch 2200: : Loss: T_4885.871 V_5767.244 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5573.0947265625\n",
      "Epoch 2210: : Loss: T_4437.201 V_5573.095 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5430.89013671875\n",
      "Epoch 2220: : Loss: T_4781.725 V_5430.890 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_4878.896 V_5818.273 | Acc: T_0.000) V_0.000\n",
      "Epoch 2240: : Loss: T_4541.425 V_5472.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4394.051 V_5746.959 | Acc: T_0.000) V_0.000\n",
      "Epoch 2260: : Loss: T_5282.050 V_5698.313 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5310.2001953125\n",
      "Epoch 2270: : Loss: T_4795.540 V_5310.200 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5301.7470703125\n",
      "Epoch 2280: : Loss: T_4849.420 V_5301.747 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_4415.810 V_5513.020 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4423.877 V_5472.784 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4585.354 V_5426.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_4357.669 V_5462.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5134.68603515625\n",
      "Epoch 2330: : Loss: T_4489.393 V_5134.686 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4255.697 V_5243.238 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4009.191 V_5326.727 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4043.283 V_5332.276 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5043.35791015625\n",
      "Epoch 2370: : Loss: T_3947.032 V_5043.358 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4915.9921875\n",
      "Epoch 2380: : Loss: T_5003.708 V_4915.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4775.498 V_5046.624 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4070.812 V_5005.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4704.191 V_4975.127 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4742.224609375\n",
      "Epoch 2420: : Loss: T_4050.814 V_4742.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4737.8486328125\n",
      "Epoch 2430: : Loss: T_4574.244 V_4737.849 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4146.189 V_4949.731 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_4115.404 V_4992.323 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_4762.253 V_5117.344 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4028.084 V_4768.453 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4555.6796875\n",
      "Epoch 2480: : Loss: T_4077.891 V_4555.680 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_4345.895 V_4792.163 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_3668.844 V_4825.886 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4685.532 V_4762.068 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_3621.818 V_4639.179 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4476.2353515625\n",
      "Epoch 2530: : Loss: T_4129.401 V_4476.235 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_3697.493 V_4590.091 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_4521.645 V_4803.761 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_3929.440 V_4848.041 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4439.70556640625\n",
      "Epoch 2570: : Loss: T_4774.297 V_4439.706 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3876.579 V_4506.275 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4273.2509765625\n",
      "Epoch 2590: : Loss: T_4136.669 V_4273.251 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_4433.728 V_4516.432 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4260.07666015625\n",
      "Epoch 2610: : Loss: T_3662.236 V_4260.077 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3739.579 V_4500.338 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4148.257 V_4485.886 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4234.15478515625\n",
      "Epoch 2640: : Loss: T_3938.011 V_4234.155 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_3588.697 V_4371.896 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_4340.329 V_4459.442 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_3867.838 V_4301.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3882.244 V_4323.062 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3998.088 V_4245.167 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4233.26708984375\n",
      "Epoch 2700: : Loss: T_3740.454 V_4233.267 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_4095.969 V_4267.785 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_4110.424 V_4292.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4132.7529296875\n",
      "Epoch 2730: : Loss: T_3940.111 V_4132.753 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3947.735 V_4289.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4092.377197265625\n",
      "Epoch 2750: : Loss: T_4101.571 V_4092.377 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3458.653 V_4174.860 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_4078.581 V_4302.175 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_4016.301 V_4165.137 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_4210.267 V_4221.584 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4029.565185546875\n",
      "Epoch 2800: : Loss: T_3957.882 V_4029.565 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3675.644 V_4117.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3504.647 V_4139.629 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4139.007 V_4075.169 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3510.683 V_4106.912 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3685.720 V_4098.117 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3883.176 V_4129.585 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3689.776 V_4058.378 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_4034.531 V_4045.563 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3972.07666015625\n",
      "Epoch 2890: : Loss: T_3210.250 V_3972.077 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_4039.529 V_4107.634 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3599.212 V_4165.331 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_3415.077 V_4081.681 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3003.381 V_4008.632 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3755.541 V_4041.772 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3484.436 V_3995.887 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3944.42431640625\n",
      "Epoch 2960: : Loss: T_3585.389 V_3944.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3887.90576171875\n",
      "Epoch 2970: : Loss: T_3131.291 V_3887.906 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3476.980 V_3894.157 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3914.321 V_3966.456 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3591.501 V_4031.450 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3265.008 V_3946.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3640.704 V_4010.184 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3676.910 V_3931.364 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3766.813 V_3925.448 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3611.386 V_3898.085 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3819.076171875\n",
      "Epoch 3060: : Loss: T_3232.373 V_3819.076 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3799.050 V_3909.153 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3784.323 V_3924.272 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3830.425 V_3852.241 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3260.248 V_3876.544 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3804.933 V_4028.233 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_3905.807 V_3920.810 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3431.625 V_3978.145 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3955.358 V_3876.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3731.094970703125\n",
      "Epoch 3150: : Loss: T_3383.965 V_3731.095 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3901.907 V_3743.849 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3790.660 V_3942.000 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3523.427 V_3944.248 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3650.762 V_3984.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_3769.938 V_3839.731 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3934.571 V_3799.474 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3812.151 V_3913.909 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3743.833 V_3793.900 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3346.464 V_3807.420 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3826.029 V_3837.941 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3012.036 V_3805.224 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_3765.078 V_3733.799 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3607.484 V_3775.613 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3727.326 V_3762.988 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3105.603 V_3760.885 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3841.229 V_3780.311 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3777.170 V_3875.753 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3545.222 V_3808.579 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3893.861 V_3862.831 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3563.239 V_3825.367 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3470.917 V_3919.085 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3395.174 V_3927.737 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3554.804 V_3763.183 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3107.439 V_3833.109 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_4041.299 V_3801.911 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3671.150634765625\n",
      "Epoch 3410: : Loss: T_3472.414 V_3671.151 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3524.254 V_3765.865 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3481.897 V_3824.155 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3107.880 V_3712.698 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3767.179 V_3817.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3615.989 V_3813.783 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3806.931 V_3697.192 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3243.393 V_3826.669 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_4115.018 V_3709.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_4117.111 V_3806.287 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31864.662109375\n",
      "Epoch 010: : Loss: T_26146.488 V_31864.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31857.119140625\n",
      "Epoch 020: : Loss: T_26128.650 V_31857.119 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31830.333984375\n",
      "Epoch 030: : Loss: T_26077.400 V_31830.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31786.31640625\n",
      "Epoch 040: : Loss: T_26068.875 V_31786.316 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31726.830078125\n",
      "Epoch 050: : Loss: T_26024.949 V_31726.830 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31677.0703125\n",
      "Epoch 060: : Loss: T_26018.574 V_31677.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31635.310546875\n",
      "Epoch 070: : Loss: T_25964.260 V_31635.311 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31593.556640625\n",
      "Epoch 080: : Loss: T_25924.254 V_31593.557 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31543.57421875\n",
      "Epoch 090: : Loss: T_25851.205 V_31543.574 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31513.59765625\n",
      "Epoch 100: : Loss: T_25827.404 V_31513.598 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31466.451171875\n",
      "Epoch 110: : Loss: T_25736.441 V_31466.451 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31407.7890625\n",
      "Epoch 120: : Loss: T_25717.469 V_31407.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31342.99609375\n",
      "Epoch 130: : Loss: T_25676.662 V_31342.996 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31301.662109375\n",
      "Epoch 140: : Loss: T_25591.051 V_31301.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31266.17578125\n",
      "Epoch 150: : Loss: T_25498.219 V_31266.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31211.89453125\n",
      "Epoch 160: : Loss: T_25477.805 V_31211.895 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31156.9921875\n",
      "Epoch 170: : Loss: T_25414.078 V_31156.992 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31047.85546875\n",
      "Epoch 180: : Loss: T_25347.604 V_31047.855 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31025.3515625\n",
      "Epoch 190: : Loss: T_25287.582 V_31025.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30918.53515625\n",
      "Epoch 200: : Loss: T_25192.170 V_30918.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30846.369140625\n",
      "Epoch 210: : Loss: T_25209.363 V_30846.369 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30678.5390625\n",
      "Epoch 220: : Loss: T_25050.203 V_30678.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30595.205078125\n",
      "Epoch 230: : Loss: T_24939.941 V_30595.205 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30505.275390625\n",
      "Epoch 240: : Loss: T_24893.330 V_30505.275 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30369.96875\n",
      "Epoch 250: : Loss: T_24757.021 V_30369.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30202.4921875\n",
      "Epoch 260: : Loss: T_24786.449 V_30202.492 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30150.912109375\n",
      "Epoch 270: : Loss: T_24651.836 V_30150.912 | Acc: T_0.000) V_0.000\n",
      "Epoch 280: : Loss: T_24518.572 V_30171.152 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30043.32421875\n",
      "Epoch 290: : Loss: T_24373.309 V_30043.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29810.623046875\n",
      "Epoch 300: : Loss: T_24334.002 V_29810.623 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29729.7109375\n",
      "Epoch 310: : Loss: T_24166.752 V_29729.711 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29682.13671875\n",
      "Epoch 320: : Loss: T_24085.666 V_29682.137 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29579.478515625\n",
      "Epoch 330: : Loss: T_23900.896 V_29579.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29506.251953125\n",
      "Epoch 340: : Loss: T_23935.443 V_29506.252 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29246.486328125\n",
      "Epoch 350: : Loss: T_23816.016 V_29246.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29145.83203125\n",
      "Epoch 360: : Loss: T_23579.771 V_29145.832 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29042.158203125\n",
      "Epoch 370: : Loss: T_23629.750 V_29042.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28815.30859375\n",
      "Epoch 380: : Loss: T_23520.277 V_28815.309 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28661.234375\n",
      "Epoch 390: : Loss: T_23403.121 V_28661.234 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28535.90625\n",
      "Epoch 400: : Loss: T_23167.150 V_28535.906 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28486.30078125\n",
      "Epoch 410: : Loss: T_23259.844 V_28486.301 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28413.45703125\n",
      "Epoch 420: : Loss: T_22884.771 V_28413.457 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28163.52734375\n",
      "Epoch 430: : Loss: T_23177.176 V_28163.527 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28041.607421875\n",
      "Epoch 440: : Loss: T_22751.906 V_28041.607 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27866.021484375\n",
      "Epoch 450: : Loss: T_22596.828 V_27866.021 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27718.962890625\n",
      "Epoch 460: : Loss: T_22464.482 V_27718.963 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27708.306640625\n",
      "Epoch 470: : Loss: T_22267.084 V_27708.307 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27528.47265625\n",
      "Epoch 480: : Loss: T_22281.418 V_27528.473 | Acc: T_0.000) V_0.000\n",
      "Epoch 490: : Loss: T_22160.613 V_27538.139 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27302.1484375\n",
      "Epoch 500: : Loss: T_22020.691 V_27302.148 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27131.0859375\n",
      "Epoch 510: : Loss: T_21820.316 V_27131.086 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26846.595703125\n",
      "Epoch 520: : Loss: T_21720.320 V_26846.596 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26743.333984375\n",
      "Epoch 530: : Loss: T_21590.668 V_26743.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26365.603515625\n",
      "Epoch 540: : Loss: T_21144.699 V_26365.604 | Acc: T_0.000) V_0.000\n",
      "Epoch 550: : Loss: T_21408.631 V_26380.791 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_21214.846 V_26370.447 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26218.39453125\n",
      "Epoch 570: : Loss: T_21090.258 V_26218.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26122.03515625\n",
      "Epoch 580: : Loss: T_20740.930 V_26122.035 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25989.35546875\n",
      "Epoch 590: : Loss: T_20798.672 V_25989.355 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25368.28515625\n",
      "Epoch 600: : Loss: T_20428.883 V_25368.285 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25229.076171875\n",
      "Epoch 610: : Loss: T_20565.879 V_25229.076 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_20345.535 V_25434.543 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_20083.598 V_25278.510 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24995.423828125\n",
      "Epoch 640: : Loss: T_19941.648 V_24995.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24877.138671875\n",
      "Epoch 650: : Loss: T_19819.434 V_24877.139 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24448.3984375\n",
      "Epoch 660: : Loss: T_19478.031 V_24448.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24283.419921875\n",
      "Epoch 670: : Loss: T_19328.723 V_24283.420 | Acc: T_0.000) V_0.000\n",
      "Epoch 680: : Loss: T_19366.482 V_24320.523 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23909.6015625\n",
      "Epoch 690: : Loss: T_19277.336 V_23909.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_19434.348 V_23910.150 | Acc: T_0.000) V_0.000\n",
      "Epoch 710: : Loss: T_19119.641 V_24073.449 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23624.998046875\n",
      "Epoch 720: : Loss: T_18931.574 V_23624.998 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23362.197265625\n",
      "Epoch 730: : Loss: T_18694.092 V_23362.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23340.490234375\n",
      "Epoch 740: : Loss: T_19014.914 V_23340.490 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23076.880859375\n",
      "Epoch 750: : Loss: T_18330.611 V_23076.881 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22668.501953125\n",
      "Epoch 760: : Loss: T_18382.740 V_22668.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_18286.479 V_22998.500 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_18375.510 V_22735.885 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22665.228515625\n",
      "Epoch 790: : Loss: T_18068.389 V_22665.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22107.9453125\n",
      "Epoch 800: : Loss: T_17544.930 V_22107.945 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22072.0\n",
      "Epoch 810: : Loss: T_17951.402 V_22072.000 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_17389.383 V_22124.504 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21747.841796875\n",
      "Epoch 830: : Loss: T_17078.961 V_21747.842 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21398.078125\n",
      "Epoch 840: : Loss: T_17444.113 V_21398.078 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_17177.664 V_21419.760 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21242.9921875\n",
      "Epoch 860: : Loss: T_17445.152 V_21242.992 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20931.60546875\n",
      "Epoch 870: : Loss: T_16657.891 V_20931.605 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_16936.383 V_21125.322 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20679.384765625\n",
      "Epoch 890: : Loss: T_16467.229 V_20679.385 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_16537.186 V_20765.979 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20496.3359375\n",
      "Epoch 910: : Loss: T_16109.757 V_20496.336 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19940.875\n",
      "Epoch 920: : Loss: T_16275.842 V_19940.875 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_15963.087 V_20201.162 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19599.12109375\n",
      "Epoch 940: : Loss: T_16075.278 V_19599.121 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_15749.400 V_19924.879 | Acc: T_0.000) V_0.000\n",
      "Epoch 960: : Loss: T_15531.663 V_19954.350 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19318.740234375\n",
      "Epoch 970: : Loss: T_14692.019 V_19318.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19246.50390625\n",
      "Epoch 980: : Loss: T_15720.059 V_19246.504 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19082.453125\n",
      "Epoch 990: : Loss: T_15108.263 V_19082.453 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18949.17578125\n",
      "Epoch 1000: : Loss: T_15045.989 V_18949.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18758.560546875\n",
      "Epoch 1010: : Loss: T_15042.782 V_18758.561 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18742.888671875\n",
      "Epoch 1020: : Loss: T_14785.681 V_18742.889 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18545.619140625\n",
      "Epoch 1030: : Loss: T_14436.190 V_18545.619 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_14630.938 V_18773.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17959.490234375\n",
      "Epoch 1050: : Loss: T_13809.699 V_17959.490 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_14351.759 V_18154.236 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17521.78515625\n",
      "Epoch 1070: : Loss: T_13954.553 V_17521.785 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_13635.188 V_17956.229 | Acc: T_0.000) V_0.000\n",
      "Epoch 1090: : Loss: T_14045.899 V_17683.350 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_13439.161 V_17559.299 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_13289.414 V_17743.221 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17417.189453125\n",
      "Epoch 1120: : Loss: T_13321.033 V_17417.189 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16879.658203125\n",
      "Epoch 1130: : Loss: T_13152.711 V_16879.658 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16750.40234375\n",
      "Epoch 1140: : Loss: T_13546.995 V_16750.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16650.095703125\n",
      "Epoch 1150: : Loss: T_13539.607 V_16650.096 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16539.38671875\n",
      "Epoch 1160: : Loss: T_13393.110 V_16539.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_12461.121 V_16627.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_12661.191 V_16614.984 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16355.826171875\n",
      "Epoch 1190: : Loss: T_12706.478 V_16355.826 | Acc: T_0.000) V_0.000\n",
      "Epoch 1200: : Loss: T_12518.268 V_16359.423 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_12312.603 V_16442.408 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15826.3291015625\n",
      "Epoch 1220: : Loss: T_12302.568 V_15826.329 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15819.4697265625\n",
      "Epoch 1230: : Loss: T_12336.822 V_15819.470 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15455.7255859375\n",
      "Epoch 1240: : Loss: T_12242.082 V_15455.726 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_11988.209 V_15503.445 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15266.9326171875\n",
      "Epoch 1260: : Loss: T_11711.967 V_15266.933 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_11693.753 V_15363.220 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14486.0390625\n",
      "Epoch 1280: : Loss: T_11427.464 V_14486.039 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_11135.925 V_14973.940 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_11526.828 V_14544.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_11229.238 V_14656.794 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14472.37109375\n",
      "Epoch 1320: : Loss: T_11331.668 V_14472.371 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14431.11328125\n",
      "Epoch 1330: : Loss: T_11116.275 V_14431.113 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11323.049 V_14468.579 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14066.9453125\n",
      "Epoch 1350: : Loss: T_10871.241 V_14066.945 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_11351.287 V_14124.130 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14058.5771484375\n",
      "Epoch 1370: : Loss: T_10117.996 V_14058.577 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13778.369140625\n",
      "Epoch 1380: : Loss: T_10391.668 V_13778.369 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13112.748046875\n",
      "Epoch 1390: : Loss: T_10031.383 V_13112.748 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_10208.547 V_13538.818 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12956.0390625\n",
      "Epoch 1410: : Loss: T_9803.553 V_12956.039 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_9672.536 V_13072.020 | Acc: T_0.000) V_0.000\n",
      "Epoch 1430: : Loss: T_10022.137 V_13206.571 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_9895.645 V_13076.697 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12480.9833984375\n",
      "Epoch 1450: : Loss: T_10175.663 V_12480.983 | Acc: T_0.000) V_0.000\n",
      "Epoch 1460: : Loss: T_9770.650 V_12522.380 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_9762.062 V_12527.268 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_9432.473 V_12562.960 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12222.53125\n",
      "Epoch 1490: : Loss: T_9050.105 V_12222.531 | Acc: T_0.000) V_0.000\n",
      "Epoch 1500: : Loss: T_9308.340 V_12414.796 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_8990.470 V_12280.902 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11904.107421875\n",
      "Epoch 1520: : Loss: T_9055.329 V_11904.107 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11663.0078125\n",
      "Epoch 1530: : Loss: T_9078.575 V_11663.008 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_8773.130 V_11944.770 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11526.6669921875\n",
      "Epoch 1550: : Loss: T_8489.426 V_11526.667 | Acc: T_0.000) V_0.000\n",
      "Epoch 1560: : Loss: T_8510.714 V_11750.017 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11431.9951171875\n",
      "Epoch 1570: : Loss: T_8684.971 V_11431.995 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_8388.012 V_11550.799 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11177.423828125\n",
      "Epoch 1590: : Loss: T_7620.694 V_11177.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_8656.256 V_11242.005 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11020.7197265625\n",
      "Epoch 1610: : Loss: T_7823.160 V_11020.720 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10689.552734375\n",
      "Epoch 1620: : Loss: T_7802.563 V_10689.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10507.25\n",
      "Epoch 1630: : Loss: T_8082.681 V_10507.250 | Acc: T_0.000) V_0.000\n",
      "Epoch 1640: : Loss: T_8238.812 V_10680.039 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10500.7666015625\n",
      "Epoch 1650: : Loss: T_7952.021 V_10500.767 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_7566.748 V_10683.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10266.3154296875\n",
      "Epoch 1670: : Loss: T_7302.421 V_10266.315 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10239.9697265625\n",
      "Epoch 1680: : Loss: T_7651.971 V_10239.970 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10061.6015625\n",
      "Epoch 1690: : Loss: T_7877.002 V_10061.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9989.7041015625\n",
      "Epoch 1700: : Loss: T_7357.112 V_9989.704 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9856.578125\n",
      "Epoch 1710: : Loss: T_7910.044 V_9856.578 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_7266.271 V_9921.765 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9719.6796875\n",
      "Epoch 1730: : Loss: T_7355.521 V_9719.680 | Acc: T_0.000) V_0.000\n",
      "Epoch 1740: : Loss: T_6863.268 V_9727.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9547.734375\n",
      "Epoch 1750: : Loss: T_6886.315 V_9547.734 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9038.7431640625\n",
      "Epoch 1760: : Loss: T_7231.700 V_9038.743 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_6905.334 V_9437.530 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_6334.165 V_9279.252 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8751.1201171875\n",
      "Epoch 1790: : Loss: T_6698.652 V_8751.120 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_6392.366 V_9208.333 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_6525.620 V_9043.975 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_6366.671 V_8840.401 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_6291.326 V_8893.814 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8641.623046875\n",
      "Epoch 1840: : Loss: T_6411.573 V_8641.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6317.708 V_8766.958 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8582.4912109375\n",
      "Epoch 1860: : Loss: T_5964.200 V_8582.491 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8457.09375\n",
      "Epoch 1870: : Loss: T_6639.194 V_8457.094 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8337.353515625\n",
      "Epoch 1880: : Loss: T_5257.562 V_8337.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8186.08203125\n",
      "Epoch 1890: : Loss: T_6571.828 V_8186.082 | Acc: T_0.000) V_0.000\n",
      "Epoch 1900: : Loss: T_5830.948 V_8258.275 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8122.2763671875\n",
      "Epoch 1910: : Loss: T_5934.211 V_8122.276 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6122.488 V_8212.337 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7966.328125\n",
      "Epoch 1930: : Loss: T_5460.104 V_7966.328 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_5724.199 V_8091.306 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7874.0693359375\n",
      "Epoch 1950: : Loss: T_6007.689 V_7874.069 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7730.7763671875\n",
      "Epoch 1960: : Loss: T_5706.926 V_7730.776 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_5728.342 V_7783.342 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7598.955078125\n",
      "Epoch 1980: : Loss: T_5465.176 V_7598.955 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_5659.528 V_7723.547 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7384.857421875\n",
      "Epoch 2000: : Loss: T_5270.686 V_7384.857 | Acc: T_0.000) V_0.000\n",
      "Epoch 2010: : Loss: T_5631.043 V_7490.680 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7233.66796875\n",
      "Epoch 2020: : Loss: T_5520.463 V_7233.668 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_5869.514 V_7580.813 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7157.88720703125\n",
      "Epoch 2040: : Loss: T_4877.235 V_7157.887 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5021.901 V_7249.978 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7157.3681640625\n",
      "Epoch 2060: : Loss: T_4300.423 V_7157.368 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7115.84130859375\n",
      "Epoch 2070: : Loss: T_5005.923 V_7115.841 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6882.46728515625\n",
      "Epoch 2080: : Loss: T_5186.727 V_6882.467 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5243.874 V_7001.412 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_5344.509 V_6907.866 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6746.80712890625\n",
      "Epoch 2110: : Loss: T_4642.740 V_6746.807 | Acc: T_0.000) V_0.000\n",
      "Epoch 2120: : Loss: T_4804.036 V_6785.415 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6725.42626953125\n",
      "Epoch 2130: : Loss: T_4912.953 V_6725.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_4599.182 V_6846.300 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6406.94970703125\n",
      "Epoch 2150: : Loss: T_5100.321 V_6406.950 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_4453.049 V_6659.364 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_4830.021 V_6664.413 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6367.69140625\n",
      "Epoch 2180: : Loss: T_5022.421 V_6367.691 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_4680.343 V_6669.702 | Acc: T_0.000) V_0.000\n",
      "Epoch 2200: : Loss: T_4521.366 V_6470.646 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6198.36328125\n",
      "Epoch 2210: : Loss: T_4022.437 V_6198.363 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6061.74951171875\n",
      "Epoch 2220: : Loss: T_4859.201 V_6061.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_4316.496 V_6143.419 | Acc: T_0.000) V_0.000\n",
      "Epoch 2240: : Loss: T_4144.651 V_6233.265 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4256.118 V_6212.460 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6036.25732421875\n",
      "Epoch 2260: : Loss: T_4650.053 V_6036.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_4274.015 V_6158.467 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6033.29638671875\n",
      "Epoch 2280: : Loss: T_4271.146 V_6033.296 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5929.1796875\n",
      "Epoch 2290: : Loss: T_4120.045 V_5929.180 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4323.829 V_6140.272 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5902.33251953125\n",
      "Epoch 2310: : Loss: T_3666.615 V_5902.333 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5886.640625\n",
      "Epoch 2320: : Loss: T_4113.901 V_5886.641 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5802.19384765625\n",
      "Epoch 2330: : Loss: T_4258.856 V_5802.194 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4287.318 V_5839.399 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4697.444 V_5972.080 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5628.85986328125\n",
      "Epoch 2360: : Loss: T_4359.810 V_5628.860 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_4622.733 V_5804.436 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4126.346 V_5631.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4430.791 V_5707.338 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_3980.556 V_5795.005 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5520.875\n",
      "Epoch 2410: : Loss: T_4249.675 V_5520.875 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5398.41064453125\n",
      "Epoch 2420: : Loss: T_3909.369 V_5398.411 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3936.479 V_5477.537 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_3756.992 V_5413.644 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_4054.305 V_5413.519 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5192.54248046875\n",
      "Epoch 2460: : Loss: T_4401.226 V_5192.542 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_3579.183 V_5535.823 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_3449.302 V_5386.971 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_3805.766 V_5390.358 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_3959.995 V_5212.358 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4456.438 V_5432.974 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_3792.073 V_5217.586 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_3816.613 V_5280.431 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5112.564453125\n",
      "Epoch 2540: : Loss: T_4399.741 V_5112.564 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5101.33837890625\n",
      "Epoch 2550: : Loss: T_3696.769 V_5101.338 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5036.0380859375\n",
      "Epoch 2560: : Loss: T_3747.370 V_5036.038 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4964.9404296875\n",
      "Epoch 2570: : Loss: T_3089.907 V_4964.940 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3617.987 V_5032.452 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3527.061 V_5034.892 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_4019.938 V_5191.330 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4753.650390625\n",
      "Epoch 2610: : Loss: T_3849.636 V_4753.650 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3944.051 V_5082.656 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_3639.121 V_4927.816 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4678.00244140625\n",
      "Epoch 2640: : Loss: T_3965.953 V_4678.002 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4026.332 V_5059.014 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3819.438 V_4821.358 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4657.91455078125\n",
      "Epoch 2670: : Loss: T_3837.960 V_4657.915 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3811.559 V_4763.322 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3393.968 V_4854.410 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3599.046 V_4838.395 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_3583.935 V_4755.203 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3801.292 V_4829.831 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4593.88330078125\n",
      "Epoch 2730: : Loss: T_3696.948 V_4593.883 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3827.060 V_4739.631 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4551.57568359375\n",
      "Epoch 2750: : Loss: T_3869.101 V_4551.576 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3659.592 V_4754.583 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_4190.955 V_4712.918 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3652.891 V_4582.235 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_3614.123 V_4811.941 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3354.363 V_4660.488 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4379.466796875\n",
      "Epoch 2810: : Loss: T_3815.517 V_4379.467 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3361.936 V_4608.801 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4001.698 V_4565.306 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3730.254 V_4500.444 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3829.403 V_4537.126 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3630.472 V_4502.144 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3750.304 V_4426.617 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3472.626 V_4592.344 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3836.798 V_4422.838 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3446.939 V_4430.384 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3125.330 V_4526.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4325.4072265625\n",
      "Epoch 2920: : Loss: T_4067.606 V_4325.407 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3415.046 V_4466.578 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3834.245 V_4519.733 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3466.215 V_4439.202 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4323.62255859375\n",
      "Epoch 2960: : Loss: T_3642.927 V_4323.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3507.038 V_4397.618 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3837.244 V_4426.599 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3829.648 V_4392.677 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3605.035 V_4356.485 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3596.047 V_4551.384 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_4033.644 V_4341.463 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3544.704 V_4503.518 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3914.462 V_4469.121 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4236.13623046875\n",
      "Epoch 3050: : Loss: T_3398.232 V_4236.136 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3689.448 V_4421.676 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_4047.566 V_4337.413 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3504.852 V_4278.073 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3771.844 V_4375.711 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3407.450 V_4391.109 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3245.361 V_4461.282 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_3510.641 V_4384.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3631.525 V_4510.415 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3708.390 V_4459.925 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3115.698 V_4364.687 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3129.493 V_4457.785 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3294.664 V_4439.153 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3446.064 V_4475.072 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3478.795 V_4426.055 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_4117.262 V_4371.800 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3338.592 V_4243.390 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3422.669 V_4360.542 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3216.355 V_4254.235 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3354.820 V_4350.217 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3293.683 V_4354.473 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3518.987 V_4281.326 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_3255.187 V_4341.752 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3751.025 V_4523.030 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3552.211 V_4449.076 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3575.788 V_4338.337 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3445.501 V_4453.610 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3202.830 V_4430.425 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3917.085 V_4375.377 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3306.876 V_4444.547 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3881.339 V_4372.903 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3402.198 V_4311.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3599.619 V_4287.684 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4106.3828125\n",
      "Epoch 3380: : Loss: T_3417.645 V_4106.383 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3701.884 V_4282.014 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3162.098 V_4540.445 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3399.141 V_4236.259 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3845.740 V_4234.328 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3795.098 V_4138.622 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3415.768 V_4286.826 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3115.319 V_4351.893 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3679.512 V_4214.795 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3415.455 V_4243.714 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3528.687 V_4458.529 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3251.561 V_4246.185 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3092.839 V_4327.802 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31760.20703125\n",
      "Epoch 010: : Loss: T_27891.377 V_31760.207 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31690.17578125\n",
      "Epoch 020: : Loss: T_27871.924 V_31690.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31650.544921875\n",
      "Epoch 030: : Loss: T_27833.967 V_31650.545 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31618.078125\n",
      "Epoch 040: : Loss: T_27804.383 V_31618.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31584.419921875\n",
      "Epoch 050: : Loss: T_27766.561 V_31584.420 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31545.17578125\n",
      "Epoch 060: : Loss: T_27733.148 V_31545.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31502.974609375\n",
      "Epoch 070: : Loss: T_27699.268 V_31502.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31476.380859375\n",
      "Epoch 080: : Loss: T_27628.027 V_31476.381 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31455.197265625\n",
      "Epoch 090: : Loss: T_27612.875 V_31455.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31429.82421875\n",
      "Epoch 100: : Loss: T_27570.311 V_31429.824 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31384.197265625\n",
      "Epoch 110: : Loss: T_27507.119 V_31384.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31326.2109375\n",
      "Epoch 120: : Loss: T_27410.152 V_31326.211 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31261.376953125\n",
      "Epoch 130: : Loss: T_27386.682 V_31261.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31186.302734375\n",
      "Epoch 140: : Loss: T_27298.795 V_31186.303 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31145.3984375\n",
      "Epoch 150: : Loss: T_27220.867 V_31145.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31091.6015625\n",
      "Epoch 160: : Loss: T_27143.713 V_31091.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31042.197265625\n",
      "Epoch 170: : Loss: T_27049.705 V_31042.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30961.11328125\n",
      "Epoch 180: : Loss: T_26912.199 V_30961.113 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30835.080078125\n",
      "Epoch 190: : Loss: T_26933.543 V_30835.080 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30746.27734375\n",
      "Epoch 200: : Loss: T_26722.914 V_30746.277 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30632.615234375\n",
      "Epoch 210: : Loss: T_26695.982 V_30632.615 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30565.373046875\n",
      "Epoch 220: : Loss: T_26593.102 V_30565.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30447.88671875\n",
      "Epoch 230: : Loss: T_26518.529 V_30447.887 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30306.9609375\n",
      "Epoch 240: : Loss: T_26466.219 V_30306.961 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30198.271484375\n",
      "Epoch 250: : Loss: T_26380.785 V_30198.271 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30126.556640625\n",
      "Epoch 260: : Loss: T_26206.486 V_30126.557 | Acc: T_0.000) V_0.000\n",
      "Epoch 270: : Loss: T_26139.631 V_30145.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29989.0\n",
      "Epoch 280: : Loss: T_26093.086 V_29989.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29886.0703125\n",
      "Epoch 290: : Loss: T_26079.541 V_29886.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29797.10546875\n",
      "Epoch 300: : Loss: T_25820.371 V_29797.105 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29550.5390625\n",
      "Epoch 310: : Loss: T_25809.777 V_29550.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29497.052734375\n",
      "Epoch 320: : Loss: T_25509.395 V_29497.053 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29296.0703125\n",
      "Epoch 330: : Loss: T_25523.916 V_29296.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29129.455078125\n",
      "Epoch 340: : Loss: T_25408.395 V_29129.455 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29015.875\n",
      "Epoch 350: : Loss: T_25337.566 V_29015.875 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28915.685546875\n",
      "Epoch 360: : Loss: T_25117.613 V_28915.686 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28797.974609375\n",
      "Epoch 370: : Loss: T_25059.264 V_28797.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28751.9375\n",
      "Epoch 380: : Loss: T_24758.312 V_28751.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28746.77734375\n",
      "Epoch 390: : Loss: T_24615.943 V_28746.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28469.82421875\n",
      "Epoch 400: : Loss: T_24606.307 V_28469.824 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28351.1796875\n",
      "Epoch 410: : Loss: T_24578.748 V_28351.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28291.912109375\n",
      "Epoch 420: : Loss: T_24339.342 V_28291.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28053.482421875\n",
      "Epoch 430: : Loss: T_24381.744 V_28053.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27956.6015625\n",
      "Epoch 440: : Loss: T_24110.057 V_27956.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27705.998046875\n",
      "Epoch 450: : Loss: T_23732.092 V_27705.998 | Acc: T_0.000) V_0.000\n",
      "Epoch 460: : Loss: T_23844.059 V_27777.873 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27490.767578125\n",
      "Epoch 470: : Loss: T_23612.883 V_27490.768 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27321.60546875\n",
      "Epoch 480: : Loss: T_23424.049 V_27321.605 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27060.67578125\n",
      "Epoch 490: : Loss: T_23277.779 V_27060.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27032.65234375\n",
      "Epoch 500: : Loss: T_23227.043 V_27032.652 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26900.591796875\n",
      "Epoch 510: : Loss: T_23165.164 V_26900.592 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26762.216796875\n",
      "Epoch 520: : Loss: T_22893.115 V_26762.217 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26595.529296875\n",
      "Epoch 530: : Loss: T_22681.238 V_26595.529 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26560.0546875\n",
      "Epoch 540: : Loss: T_22745.357 V_26560.055 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26247.05078125\n",
      "Epoch 550: : Loss: T_22431.518 V_26247.051 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_22381.771 V_26261.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26012.935546875\n",
      "Epoch 570: : Loss: T_22044.477 V_26012.936 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25694.091796875\n",
      "Epoch 580: : Loss: T_22147.990 V_25694.092 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25343.244140625\n",
      "Epoch 590: : Loss: T_21941.504 V_25343.244 | Acc: T_0.000) V_0.000\n",
      "Epoch 600: : Loss: T_21799.342 V_25615.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25310.619140625\n",
      "Epoch 610: : Loss: T_21494.646 V_25310.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25206.373046875\n",
      "Epoch 620: : Loss: T_21612.701 V_25206.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25019.1875\n",
      "Epoch 630: : Loss: T_21105.576 V_25019.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24939.689453125\n",
      "Epoch 640: : Loss: T_21033.510 V_24939.689 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24511.466796875\n",
      "Epoch 650: : Loss: T_20888.904 V_24511.467 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_20931.209 V_24549.803 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23931.705078125\n",
      "Epoch 670: : Loss: T_20882.744 V_23931.705 | Acc: T_0.000) V_0.000\n",
      "Epoch 680: : Loss: T_20549.516 V_24209.979 | Acc: T_0.000) V_0.000\n",
      "Epoch 690: : Loss: T_20444.207 V_24124.422 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_20344.098 V_24004.701 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23480.16796875\n",
      "Epoch 710: : Loss: T_19917.322 V_23480.168 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23445.478515625\n",
      "Epoch 720: : Loss: T_19817.682 V_23445.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23393.130859375\n",
      "Epoch 730: : Loss: T_19643.426 V_23393.131 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23201.193359375\n",
      "Epoch 740: : Loss: T_19540.656 V_23201.193 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23043.84765625\n",
      "Epoch 750: : Loss: T_19655.301 V_23043.848 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22962.556640625\n",
      "Epoch 760: : Loss: T_19151.518 V_22962.557 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22640.951171875\n",
      "Epoch 770: : Loss: T_19235.531 V_22640.951 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_19076.326 V_22774.408 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22313.9140625\n",
      "Epoch 790: : Loss: T_18753.451 V_22313.914 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22144.015625\n",
      "Epoch 800: : Loss: T_18564.883 V_22144.016 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21997.451171875\n",
      "Epoch 810: : Loss: T_18683.459 V_21997.451 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21633.8125\n",
      "Epoch 820: : Loss: T_18663.740 V_21633.812 | Acc: T_0.000) V_0.000\n",
      "Epoch 830: : Loss: T_18053.314 V_21761.951 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21448.228515625\n",
      "Epoch 840: : Loss: T_18195.779 V_21448.229 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_17843.908 V_21869.389 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21279.572265625\n",
      "Epoch 860: : Loss: T_17624.773 V_21279.572 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20706.201171875\n",
      "Epoch 870: : Loss: T_17683.037 V_20706.201 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_17233.420 V_20881.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20498.548828125\n",
      "Epoch 890: : Loss: T_16959.588 V_20498.549 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_17155.385 V_20657.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20250.76171875\n",
      "Epoch 910: : Loss: T_17195.822 V_20250.762 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_17265.400 V_20476.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_16786.598 V_20269.709 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20074.609375\n",
      "Epoch 940: : Loss: T_17052.473 V_20074.609 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19988.365234375\n",
      "Epoch 950: : Loss: T_16000.982 V_19988.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19762.126953125\n",
      "Epoch 960: : Loss: T_16108.897 V_19762.127 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19287.755859375\n",
      "Epoch 970: : Loss: T_16326.394 V_19287.756 | Acc: T_0.000) V_0.000\n",
      "Epoch 980: : Loss: T_15857.142 V_19620.162 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_15896.676 V_19329.113 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19142.447265625\n",
      "Epoch 1000: : Loss: T_15938.252 V_19142.447 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18879.001953125\n",
      "Epoch 1010: : Loss: T_15519.530 V_18879.002 | Acc: T_0.000) V_0.000\n",
      "Epoch 1020: : Loss: T_15206.322 V_18916.178 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18414.77734375\n",
      "Epoch 1030: : Loss: T_14845.445 V_18414.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18297.642578125\n",
      "Epoch 1040: : Loss: T_15022.122 V_18297.643 | Acc: T_0.000) V_0.000\n",
      "Epoch 1050: : Loss: T_14586.839 V_18304.596 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_14556.111 V_18363.846 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18168.435546875\n",
      "Epoch 1070: : Loss: T_14854.715 V_18168.436 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17939.662109375\n",
      "Epoch 1080: : Loss: T_14508.689 V_17939.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17474.4296875\n",
      "Epoch 1090: : Loss: T_14430.510 V_17474.430 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14820.610 V_17567.799 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_13496.838 V_17669.887 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17246.60546875\n",
      "Epoch 1120: : Loss: T_14057.197 V_17246.605 | Acc: T_0.000) V_0.000\n",
      "Epoch 1130: : Loss: T_13998.028 V_17405.973 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16972.900390625\n",
      "Epoch 1140: : Loss: T_13588.791 V_16972.900 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16906.759765625\n",
      "Epoch 1150: : Loss: T_13530.400 V_16906.760 | Acc: T_0.000) V_0.000\n",
      "Epoch 1160: : Loss: T_13655.296 V_17101.559 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16820.97265625\n",
      "Epoch 1170: : Loss: T_13729.057 V_16820.973 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16359.287109375\n",
      "Epoch 1180: : Loss: T_13561.728 V_16359.287 | Acc: T_0.000) V_0.000\n",
      "Epoch 1190: : Loss: T_13213.578 V_16474.463 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16207.3623046875\n",
      "Epoch 1200: : Loss: T_12613.837 V_16207.362 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_12444.141 V_16213.581 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16057.60546875\n",
      "Epoch 1220: : Loss: T_12756.827 V_16057.605 | Acc: T_0.000) V_0.000\n",
      "Epoch 1230: : Loss: T_12691.451 V_16059.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15567.3095703125\n",
      "Epoch 1240: : Loss: T_12611.473 V_15567.310 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_12497.967 V_15783.906 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15461.197265625\n",
      "Epoch 1260: : Loss: T_12191.071 V_15461.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_11971.318 V_15503.702 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15274.9296875\n",
      "Epoch 1280: : Loss: T_12042.014 V_15274.930 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15255.984375\n",
      "Epoch 1290: : Loss: T_12446.524 V_15255.984 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15102.3134765625\n",
      "Epoch 1300: : Loss: T_12034.011 V_15102.313 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14629.9814453125\n",
      "Epoch 1310: : Loss: T_11822.536 V_14629.981 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_11379.249 V_14820.952 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14488.7763671875\n",
      "Epoch 1330: : Loss: T_11522.641 V_14488.776 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11008.956 V_14512.007 | Acc: T_0.000) V_0.000\n",
      "Epoch 1350: : Loss: T_10826.338 V_14620.529 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14260.7021484375\n",
      "Epoch 1360: : Loss: T_11485.367 V_14260.702 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13811.9228515625\n",
      "Epoch 1370: : Loss: T_11044.327 V_13811.923 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_10660.801 V_13969.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_10637.126 V_14126.491 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_10378.065 V_13850.881 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13682.5595703125\n",
      "Epoch 1410: : Loss: T_9864.587 V_13682.560 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13680.673828125\n",
      "Epoch 1420: : Loss: T_10169.024 V_13680.674 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13287.9453125\n",
      "Epoch 1430: : Loss: T_9950.660 V_13287.945 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_9483.796 V_13427.104 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13190.599609375\n",
      "Epoch 1450: : Loss: T_9936.535 V_13190.600 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13141.212890625\n",
      "Epoch 1460: : Loss: T_9777.334 V_13141.213 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_9905.033 V_13300.329 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12829.544921875\n",
      "Epoch 1480: : Loss: T_9196.790 V_12829.545 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12808.7197265625\n",
      "Epoch 1490: : Loss: T_9608.420 V_12808.720 | Acc: T_0.000) V_0.000\n",
      "Epoch 1500: : Loss: T_8887.291 V_13034.130 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12475.1005859375\n",
      "Epoch 1510: : Loss: T_9404.440 V_12475.101 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12313.900390625\n",
      "Epoch 1520: : Loss: T_9739.257 V_12313.900 | Acc: T_0.000) V_0.000\n",
      "Epoch 1530: : Loss: T_8791.970 V_12557.239 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12255.4033203125\n",
      "Epoch 1540: : Loss: T_9506.049 V_12255.403 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_9174.193 V_12256.410 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12244.62890625\n",
      "Epoch 1560: : Loss: T_9493.220 V_12244.629 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11930.0205078125\n",
      "Epoch 1570: : Loss: T_9184.886 V_11930.021 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_9273.790 V_12066.630 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11506.8447265625\n",
      "Epoch 1590: : Loss: T_8242.659 V_11506.845 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_8637.462 V_11562.737 | Acc: T_0.000) V_0.000\n",
      "Epoch 1610: : Loss: T_8933.872 V_11631.808 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_7467.998 V_11700.815 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11273.7333984375\n",
      "Epoch 1630: : Loss: T_7709.503 V_11273.733 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11205.9091796875\n",
      "Epoch 1640: : Loss: T_7553.725 V_11205.909 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11142.7900390625\n",
      "Epoch 1650: : Loss: T_8050.851 V_11142.790 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_7346.579 V_11222.353 | Acc: T_0.000) V_0.000\n",
      "Epoch 1670: : Loss: T_7750.777 V_11265.300 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10868.87109375\n",
      "Epoch 1680: : Loss: T_7941.978 V_10868.871 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10494.0283203125\n",
      "Epoch 1690: : Loss: T_7782.623 V_10494.028 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10420.1435546875\n",
      "Epoch 1700: : Loss: T_7771.303 V_10420.144 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_6849.316 V_10479.576 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_7117.945 V_10430.384 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10347.0693359375\n",
      "Epoch 1730: : Loss: T_7968.940 V_10347.069 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9841.2861328125\n",
      "Epoch 1740: : Loss: T_7477.713 V_9841.286 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_6778.040 V_9862.624 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9721.7001953125\n",
      "Epoch 1760: : Loss: T_7588.616 V_9721.700 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7260.022 V_9979.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_6944.793 V_9935.750 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9498.0380859375\n",
      "Epoch 1790: : Loss: T_6961.883 V_9498.038 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9460.12109375\n",
      "Epoch 1800: : Loss: T_6984.837 V_9460.121 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_6936.251 V_9675.476 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9445.017578125\n",
      "Epoch 1820: : Loss: T_6011.596 V_9445.018 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9371.0556640625\n",
      "Epoch 1830: : Loss: T_6901.119 V_9371.056 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9297.791015625\n",
      "Epoch 1840: : Loss: T_6382.489 V_9297.791 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6361.839 V_9413.437 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6611.469 V_9342.836 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_5731.035 V_9364.808 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8947.2587890625\n",
      "Epoch 1880: : Loss: T_6660.423 V_8947.259 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6145.014 V_9061.500 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8625.763671875\n",
      "Epoch 1900: : Loss: T_6303.979 V_8625.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_6182.134 V_8979.579 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6279.377 V_8639.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8304.4638671875\n",
      "Epoch 1930: : Loss: T_5851.086 V_8304.464 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_5719.396 V_8432.540 | Acc: T_0.000) V_0.000\n",
      "Epoch 1950: : Loss: T_5670.959 V_8583.682 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_5401.517 V_8380.454 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_5455.496 V_8445.665 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8191.31787109375\n",
      "Epoch 1980: : Loss: T_5667.837 V_8191.318 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8013.98876953125\n",
      "Epoch 1990: : Loss: T_5641.953 V_8013.989 | Acc: T_0.000) V_0.000\n",
      "Epoch 2000: : Loss: T_5479.680 V_8300.247 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7978.2255859375\n",
      "Epoch 2010: : Loss: T_5252.808 V_7978.226 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7582.05908203125\n",
      "Epoch 2020: : Loss: T_5173.608 V_7582.059 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_5296.581 V_7661.867 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_5077.356 V_7850.865 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5183.747 V_7681.170 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5457.852 V_7683.489 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_5034.400 V_7601.877 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7506.1337890625\n",
      "Epoch 2080: : Loss: T_5249.291 V_7506.134 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7270.00146484375\n",
      "Epoch 2090: : Loss: T_4894.537 V_7270.001 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_4908.258 V_7516.985 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7262.15966796875\n",
      "Epoch 2110: : Loss: T_4671.976 V_7262.160 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7175.5322265625\n",
      "Epoch 2120: : Loss: T_5183.401 V_7175.532 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7159.92626953125\n",
      "Epoch 2130: : Loss: T_4215.522 V_7159.926 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7092.40185546875\n",
      "Epoch 2140: : Loss: T_4634.696 V_7092.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7014.12451171875\n",
      "Epoch 2150: : Loss: T_4626.854 V_7014.125 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6909.53955078125\n",
      "Epoch 2160: : Loss: T_4856.325 V_6909.540 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_4832.191 V_7032.392 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6839.619140625\n",
      "Epoch 2180: : Loss: T_4191.323 V_6839.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6799.84423828125\n",
      "Epoch 2190: : Loss: T_4713.411 V_6799.844 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6568.8017578125\n",
      "Epoch 2200: : Loss: T_4615.315 V_6568.802 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6543.7734375\n",
      "Epoch 2210: : Loss: T_4263.805 V_6543.773 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_4465.696 V_6573.320 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6471.4443359375\n",
      "Epoch 2230: : Loss: T_4144.720 V_6471.444 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6428.04296875\n",
      "Epoch 2240: : Loss: T_4135.873 V_6428.043 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4055.304 V_6486.300 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6338.2158203125\n",
      "Epoch 2260: : Loss: T_4490.878 V_6338.216 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_3995.578 V_6430.349 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6299.98291015625\n",
      "Epoch 2280: : Loss: T_4031.576 V_6299.983 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6206.06298828125\n",
      "Epoch 2290: : Loss: T_4166.265 V_6206.063 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6079.27392578125\n",
      "Epoch 2300: : Loss: T_3900.625 V_6079.274 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4308.349 V_6119.201 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_4571.322 V_6160.720 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5851.0947265625\n",
      "Epoch 2330: : Loss: T_3989.174 V_5851.095 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4056.609 V_5958.748 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4348.674 V_5876.693 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4599.305 V_6046.913 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5660.1865234375\n",
      "Epoch 2370: : Loss: T_4107.030 V_5660.187 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_3768.832 V_5966.104 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_3963.136 V_5665.285 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4343.382 V_5800.430 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4056.880 V_5819.339 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_3526.528 V_5673.737 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3951.626 V_5759.919 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5655.0810546875\n",
      "Epoch 2440: : Loss: T_3512.347 V_5655.081 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5590.40234375\n",
      "Epoch 2450: : Loss: T_3815.834 V_5590.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5584.3369140625\n",
      "Epoch 2460: : Loss: T_3898.136 V_5584.337 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5334.03662109375\n",
      "Epoch 2470: : Loss: T_3471.147 V_5334.037 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_3545.543 V_5499.149 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5277.4130859375\n",
      "Epoch 2490: : Loss: T_3640.688 V_5277.413 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5267.10205078125\n",
      "Epoch 2500: : Loss: T_3858.742 V_5267.102 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_3777.505 V_5347.766 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_3605.734 V_5292.317 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_3389.486 V_5347.506 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5244.16943359375\n",
      "Epoch 2540: : Loss: T_3826.481 V_5244.169 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5237.025390625\n",
      "Epoch 2550: : Loss: T_3260.542 V_5237.025 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5127.32373046875\n",
      "Epoch 2560: : Loss: T_3925.123 V_5127.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 2570: : Loss: T_3552.652 V_5228.877 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3936.644 V_5136.270 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3891.797 V_5189.289 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_3823.336 V_5147.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5085.232421875\n",
      "Epoch 2610: : Loss: T_3566.371 V_5085.232 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3444.847 V_5151.604 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4910.95947265625\n",
      "Epoch 2630: : Loss: T_3355.548 V_4910.959 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4907.83544921875\n",
      "Epoch 2640: : Loss: T_3794.008 V_4907.835 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_3268.519 V_4950.657 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3368.064 V_4968.366 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_3507.398 V_4998.005 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3849.121 V_4973.674 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3976.407 V_4956.673 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4837.53955078125\n",
      "Epoch 2700: : Loss: T_3620.181 V_4837.540 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4787.74755859375\n",
      "Epoch 2710: : Loss: T_3449.050 V_4787.748 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3762.086 V_4814.852 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3772.597 V_4806.516 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3566.163 V_4905.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3164.290 V_4851.514 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_2891.566 V_4842.715 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4696.7177734375\n",
      "Epoch 2770: : Loss: T_3430.229 V_4696.718 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_2961.995 V_4711.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4629.90771484375\n",
      "Epoch 2790: : Loss: T_3125.813 V_4629.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4616.80517578125\n",
      "Epoch 2800: : Loss: T_3334.121 V_4616.805 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3200.055 V_4636.694 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3732.965 V_4642.229 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_3322.856 V_4720.614 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4615.47021484375\n",
      "Epoch 2840: : Loss: T_3140.317 V_4615.470 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3467.396 V_4703.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4604.2724609375\n",
      "Epoch 2860: : Loss: T_3324.612 V_4604.272 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4543.5771484375\n",
      "Epoch 2870: : Loss: T_3093.412 V_4543.577 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4442.13525390625\n",
      "Epoch 2880: : Loss: T_3714.710 V_4442.135 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3681.171 V_4561.515 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3400.784 V_4541.463 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3696.452 V_4492.332 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4408.701171875\n",
      "Epoch 2920: : Loss: T_3198.165 V_4408.701 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3454.553 V_4495.202 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_2975.388 V_4531.278 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3197.868 V_4469.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4374.10107421875\n",
      "Epoch 2960: : Loss: T_3294.382 V_4374.101 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3466.336 V_4500.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3708.109 V_4439.234 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3126.992 V_4501.459 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4361.70703125\n",
      "Epoch 3000: : Loss: T_3284.917 V_4361.707 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3351.064 V_4378.649 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3193.663 V_4404.660 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3089.413 V_4399.766 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3693.669 V_4423.167 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3270.917 V_4480.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3232.765 V_4417.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3397.394 V_4366.472 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3192.680 V_4477.593 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_2869.466 V_4398.563 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3490.731 V_4395.281 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3674.615 V_4415.995 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4317.119140625\n",
      "Epoch 3120: : Loss: T_3207.858 V_4317.119 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3861.456 V_4338.084 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4265.34130859375\n",
      "Epoch 3140: : Loss: T_3151.791 V_4265.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3105.824 V_4330.613 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3232.499 V_4369.513 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3322.961 V_4282.259 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_2966.167 V_4346.669 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3105.033 V_4336.390 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_2936.880 V_4322.737 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3209.683 V_4309.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_2982.020 V_4327.060 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3007.746 V_4300.026 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3243.958 V_4332.856 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3179.355 V_4410.038 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3049.673 V_4391.150 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4240.626953125\n",
      "Epoch 3270: : Loss: T_3489.702 V_4240.627 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3047.818 V_4324.099 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4231.34130859375\n",
      "Epoch 3290: : Loss: T_3123.180 V_4231.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3506.679 V_4297.713 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3836.859 V_4278.012 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4165.83203125\n",
      "Epoch 3320: : Loss: T_3694.783 V_4165.832 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3054.718 V_4222.213 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3539.139 V_4249.142 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3450.872 V_4265.284 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3085.004 V_4222.021 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3955.137 V_4242.933 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3134.353 V_4237.406 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3270.567 V_4229.487 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3489.277 V_4216.555 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3485.800 V_4244.245 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4155.076171875\n",
      "Epoch 3420: : Loss: T_3241.451 V_4155.076 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3515.273 V_4233.698 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3380.797 V_4226.910 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_2986.232 V_4313.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3306.218 V_4250.881 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3098.921 V_4319.239 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_2958.501 V_4239.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3427.347 V_4233.067 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3380.441 V_4287.935 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31864.65234375\n",
      "Epoch 010: : Loss: T_27450.953 V_31864.652 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31830.302734375\n",
      "Epoch 020: : Loss: T_27412.105 V_31830.303 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31793.5625\n",
      "Epoch 030: : Loss: T_27382.953 V_31793.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31748.96484375\n",
      "Epoch 040: : Loss: T_27368.914 V_31748.965 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31698.78125\n",
      "Epoch 050: : Loss: T_27323.830 V_31698.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31650.158203125\n",
      "Epoch 060: : Loss: T_27272.152 V_31650.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31600.619140625\n",
      "Epoch 070: : Loss: T_27234.980 V_31600.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31552.82421875\n",
      "Epoch 080: : Loss: T_27162.689 V_31552.824 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31492.123046875\n",
      "Epoch 090: : Loss: T_27180.238 V_31492.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31422.166015625\n",
      "Epoch 100: : Loss: T_27074.068 V_31422.166 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31371.640625\n",
      "Epoch 110: : Loss: T_27063.637 V_31371.641 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31330.609375\n",
      "Epoch 120: : Loss: T_27007.607 V_31330.609 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31287.275390625\n",
      "Epoch 130: : Loss: T_26904.480 V_31287.275 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31216.189453125\n",
      "Epoch 140: : Loss: T_26847.365 V_31216.189 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31172.205078125\n",
      "Epoch 150: : Loss: T_26795.217 V_31172.205 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31088.767578125\n",
      "Epoch 160: : Loss: T_26669.662 V_31088.768 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31000.689453125\n",
      "Epoch 170: : Loss: T_26628.350 V_31000.689 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30915.6796875\n",
      "Epoch 180: : Loss: T_26596.164 V_30915.680 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30851.380859375\n",
      "Epoch 190: : Loss: T_26466.119 V_30851.381 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30771.77734375\n",
      "Epoch 200: : Loss: T_26347.879 V_30771.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30720.259765625\n",
      "Epoch 210: : Loss: T_26203.590 V_30720.260 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30530.7890625\n",
      "Epoch 220: : Loss: T_26253.471 V_30530.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30493.056640625\n",
      "Epoch 230: : Loss: T_26083.379 V_30493.057 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30307.810546875\n",
      "Epoch 240: : Loss: T_26002.553 V_30307.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30280.365234375\n",
      "Epoch 250: : Loss: T_25825.961 V_30280.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30210.32421875\n",
      "Epoch 260: : Loss: T_25868.439 V_30210.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30050.833984375\n",
      "Epoch 270: : Loss: T_25658.803 V_30050.834 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29986.4375\n",
      "Epoch 280: : Loss: T_25753.934 V_29986.438 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29962.634765625\n",
      "Epoch 290: : Loss: T_25559.199 V_29962.635 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29781.806640625\n",
      "Epoch 300: : Loss: T_25392.410 V_29781.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29484.650390625\n",
      "Epoch 310: : Loss: T_25395.793 V_29484.650 | Acc: T_0.000) V_0.000\n",
      "Epoch 320: : Loss: T_25178.750 V_29550.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29324.853515625\n",
      "Epoch 330: : Loss: T_25041.238 V_29324.854 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29194.2890625\n",
      "Epoch 340: : Loss: T_24783.430 V_29194.289 | Acc: T_0.000) V_0.000\n",
      "Epoch 350: : Loss: T_24950.445 V_29220.857 | Acc: T_0.000) V_0.000\n",
      "Epoch 360: : Loss: T_24742.281 V_29210.557 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29012.427734375\n",
      "Epoch 370: : Loss: T_24471.299 V_29012.428 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28723.318359375\n",
      "Epoch 380: : Loss: T_24301.336 V_28723.318 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28686.890625\n",
      "Epoch 390: : Loss: T_24441.557 V_28686.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28582.646484375\n",
      "Epoch 400: : Loss: T_24219.609 V_28582.646 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28524.904296875\n",
      "Epoch 410: : Loss: T_23971.510 V_28524.904 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28367.162109375\n",
      "Epoch 420: : Loss: T_24000.939 V_28367.162 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28162.248046875\n",
      "Epoch 430: : Loss: T_23797.506 V_28162.248 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27983.189453125\n",
      "Epoch 440: : Loss: T_23911.492 V_27983.189 | Acc: T_0.000) V_0.000\n",
      "Epoch 450: : Loss: T_23495.164 V_28023.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 460: : Loss: T_23314.641 V_28051.818 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27863.806640625\n",
      "Epoch 470: : Loss: T_23371.039 V_27863.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27510.89453125\n",
      "Epoch 480: : Loss: T_23350.373 V_27510.895 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27184.111328125\n",
      "Epoch 490: : Loss: T_22909.797 V_27184.111 | Acc: T_0.000) V_0.000\n",
      "Epoch 500: : Loss: T_23040.176 V_27307.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 510: : Loss: T_22917.545 V_27259.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26894.740234375\n",
      "Epoch 520: : Loss: T_22607.518 V_26894.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26683.060546875\n",
      "Epoch 530: : Loss: T_22583.639 V_26683.061 | Acc: T_0.000) V_0.000\n",
      "Epoch 540: : Loss: T_22324.221 V_26931.715 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26649.552734375\n",
      "Epoch 550: : Loss: T_22086.889 V_26649.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26279.484375\n",
      "Epoch 560: : Loss: T_21949.213 V_26279.484 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26216.40234375\n",
      "Epoch 570: : Loss: T_22018.838 V_26216.402 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_22008.225 V_26289.309 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25863.056640625\n",
      "Epoch 590: : Loss: T_21764.404 V_25863.057 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25792.576171875\n",
      "Epoch 600: : Loss: T_21718.787 V_25792.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25519.775390625\n",
      "Epoch 610: : Loss: T_21379.520 V_25519.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_21313.953 V_25639.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25402.056640625\n",
      "Epoch 630: : Loss: T_20850.361 V_25402.057 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24973.38671875\n",
      "Epoch 640: : Loss: T_20920.723 V_24973.387 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24961.0\n",
      "Epoch 650: : Loss: T_20424.744 V_24961.000 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_20710.633 V_24964.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24823.98046875\n",
      "Epoch 670: : Loss: T_20504.541 V_24823.980 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24448.662109375\n",
      "Epoch 680: : Loss: T_20526.748 V_24448.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24319.51953125\n",
      "Epoch 690: : Loss: T_20227.203 V_24319.520 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_19560.990 V_24409.205 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24017.962890625\n",
      "Epoch 710: : Loss: T_19825.543 V_24017.963 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_19491.098 V_24136.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23721.224609375\n",
      "Epoch 730: : Loss: T_19540.283 V_23721.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23363.837890625\n",
      "Epoch 740: : Loss: T_19567.529 V_23363.838 | Acc: T_0.000) V_0.000\n",
      "Epoch 750: : Loss: T_19070.010 V_23520.115 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23342.8828125\n",
      "Epoch 760: : Loss: T_19089.227 V_23342.883 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23134.94921875\n",
      "Epoch 770: : Loss: T_19040.709 V_23134.949 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_19123.506 V_23178.723 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22919.525390625\n",
      "Epoch 790: : Loss: T_18277.094 V_22919.525 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22521.845703125\n",
      "Epoch 800: : Loss: T_18308.895 V_22521.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 810: : Loss: T_18560.631 V_22660.818 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22210.509765625\n",
      "Epoch 820: : Loss: T_18406.670 V_22210.510 | Acc: T_0.000) V_0.000\n",
      "Epoch 830: : Loss: T_18195.752 V_22308.871 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22183.509765625\n",
      "Epoch 840: : Loss: T_18364.152 V_22183.510 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21744.32421875\n",
      "Epoch 850: : Loss: T_17667.582 V_21744.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 860: : Loss: T_17408.531 V_21911.195 | Acc: T_0.000) V_0.000\n",
      "Epoch 870: : Loss: T_17315.033 V_21793.061 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21285.48046875\n",
      "Epoch 880: : Loss: T_17418.574 V_21285.480 | Acc: T_0.000) V_0.000\n",
      "Epoch 890: : Loss: T_17637.732 V_21328.273 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_17219.457 V_21305.420 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20782.6640625\n",
      "Epoch 910: : Loss: T_17085.896 V_20782.664 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_16935.791 V_20894.941 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_16515.883 V_20811.822 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20226.1875\n",
      "Epoch 940: : Loss: T_16278.783 V_20226.188 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_15987.813 V_20826.068 | Acc: T_0.000) V_0.000\n",
      "Epoch 960: : Loss: T_15852.057 V_20500.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20098.0546875\n",
      "Epoch 970: : Loss: T_15723.142 V_20098.055 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19480.296875\n",
      "Epoch 980: : Loss: T_15575.507 V_19480.297 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_15918.080 V_19817.754 | Acc: T_0.000) V_0.000\n",
      "Epoch 1000: : Loss: T_15526.896 V_19704.895 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19454.28125\n",
      "Epoch 1010: : Loss: T_15698.915 V_19454.281 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19425.72265625\n",
      "Epoch 1020: : Loss: T_15192.302 V_19425.723 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18742.072265625\n",
      "Epoch 1030: : Loss: T_15203.387 V_18742.072 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_15374.178 V_19135.018 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18583.927734375\n",
      "Epoch 1050: : Loss: T_14887.113 V_18583.928 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_15052.853 V_18846.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18521.29296875\n",
      "Epoch 1070: : Loss: T_14987.235 V_18521.293 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_14212.555 V_18544.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18304.37890625\n",
      "Epoch 1090: : Loss: T_14727.976 V_18304.379 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17917.416015625\n",
      "Epoch 1100: : Loss: T_14506.172 V_17917.416 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_13948.701 V_18079.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17423.396484375\n",
      "Epoch 1120: : Loss: T_14017.528 V_17423.396 | Acc: T_0.000) V_0.000\n",
      "Epoch 1130: : Loss: T_14261.307 V_17516.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_13304.929 V_17525.811 | Acc: T_0.000) V_0.000\n",
      "Epoch 1150: : Loss: T_14115.432 V_17582.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17417.658203125\n",
      "Epoch 1160: : Loss: T_13255.408 V_17417.658 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17129.302734375\n",
      "Epoch 1170: : Loss: T_13480.398 V_17129.303 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16933.021484375\n",
      "Epoch 1180: : Loss: T_13137.782 V_16933.021 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16822.134765625\n",
      "Epoch 1190: : Loss: T_13103.444 V_16822.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16701.02734375\n",
      "Epoch 1200: : Loss: T_13244.541 V_16701.027 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16450.984375\n",
      "Epoch 1210: : Loss: T_12735.900 V_16450.984 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16086.052734375\n",
      "Epoch 1220: : Loss: T_12689.787 V_16086.053 | Acc: T_0.000) V_0.000\n",
      "Epoch 1230: : Loss: T_12166.303 V_16287.307 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15874.927734375\n",
      "Epoch 1240: : Loss: T_12109.696 V_15874.928 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_12123.068 V_15951.664 | Acc: T_0.000) V_0.000\n",
      "Epoch 1260: : Loss: T_12663.270 V_15935.022 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15566.4365234375\n",
      "Epoch 1270: : Loss: T_12388.104 V_15566.437 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_11674.818 V_15750.458 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15208.7236328125\n",
      "Epoch 1290: : Loss: T_11886.259 V_15208.724 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_12228.638 V_15252.255 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15009.234375\n",
      "Epoch 1310: : Loss: T_11728.999 V_15009.234 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_11216.620 V_15217.129 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14811.87109375\n",
      "Epoch 1330: : Loss: T_11570.472 V_14811.871 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14631.26953125\n",
      "Epoch 1340: : Loss: T_11248.071 V_14631.270 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14477.0478515625\n",
      "Epoch 1350: : Loss: T_10499.438 V_14477.048 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_11068.902 V_14608.868 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14274.9658203125\n",
      "Epoch 1370: : Loss: T_11186.307 V_14274.966 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14170.1884765625\n",
      "Epoch 1380: : Loss: T_10987.528 V_14170.188 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_10827.943 V_14177.426 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13589.50390625\n",
      "Epoch 1400: : Loss: T_10625.848 V_13589.504 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_10687.585 V_13880.354 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_10379.014 V_13689.724 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13331.291015625\n",
      "Epoch 1430: : Loss: T_10222.991 V_13331.291 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13230.2880859375\n",
      "Epoch 1440: : Loss: T_10283.378 V_13230.288 | Acc: T_0.000) V_0.000\n",
      "Epoch 1450: : Loss: T_9667.397 V_13293.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13019.6298828125\n",
      "Epoch 1460: : Loss: T_10158.438 V_13019.630 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_9859.019 V_13277.620 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12572.376953125\n",
      "Epoch 1480: : Loss: T_9537.199 V_12572.377 | Acc: T_0.000) V_0.000\n",
      "Epoch 1490: : Loss: T_9728.570 V_12854.618 | Acc: T_0.000) V_0.000\n",
      "Epoch 1500: : Loss: T_9226.971 V_12730.169 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12519.1240234375\n",
      "Epoch 1510: : Loss: T_9261.190 V_12519.124 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12059.158203125\n",
      "Epoch 1520: : Loss: T_10162.964 V_12059.158 | Acc: T_0.000) V_0.000\n",
      "Epoch 1530: : Loss: T_9067.253 V_12258.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11963.361328125\n",
      "Epoch 1540: : Loss: T_9013.557 V_11963.361 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_9308.081 V_12091.443 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11455.20703125\n",
      "Epoch 1560: : Loss: T_9006.479 V_11455.207 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9404.176 V_11760.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_9240.379 V_11678.481 | Acc: T_0.000) V_0.000\n",
      "Epoch 1590: : Loss: T_8352.559 V_11485.873 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_8321.478 V_11501.710 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11346.74609375\n",
      "Epoch 1610: : Loss: T_8582.106 V_11346.746 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11224.8466796875\n",
      "Epoch 1620: : Loss: T_8296.080 V_11224.847 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10733.0078125\n",
      "Epoch 1630: : Loss: T_8464.408 V_10733.008 | Acc: T_0.000) V_0.000\n",
      "Epoch 1640: : Loss: T_7667.934 V_11018.862 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10706.619140625\n",
      "Epoch 1650: : Loss: T_8075.777 V_10706.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10661.1298828125\n",
      "Epoch 1660: : Loss: T_7376.043 V_10661.130 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10519.2275390625\n",
      "Epoch 1670: : Loss: T_8267.707 V_10519.228 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10399.060546875\n",
      "Epoch 1680: : Loss: T_7873.455 V_10399.061 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_7745.531 V_10531.425 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10092.9580078125\n",
      "Epoch 1700: : Loss: T_7691.718 V_10092.958 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9931.822265625\n",
      "Epoch 1710: : Loss: T_7533.647 V_9931.822 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_7494.315 V_10192.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_6953.427 V_9985.827 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9740.7802734375\n",
      "Epoch 1740: : Loss: T_7338.913 V_9740.780 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_7512.042 V_10005.289 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9351.208984375\n",
      "Epoch 1760: : Loss: T_6918.029 V_9351.209 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7216.887 V_9891.210 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_6679.045 V_9470.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9049.4326171875\n",
      "Epoch 1790: : Loss: T_7194.482 V_9049.433 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_6803.035 V_9141.766 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_6074.386 V_9328.751 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_6600.321 V_9266.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9005.912109375\n",
      "Epoch 1830: : Loss: T_6150.858 V_9005.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8986.474609375\n",
      "Epoch 1840: : Loss: T_5840.110 V_8986.475 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8761.25390625\n",
      "Epoch 1850: : Loss: T_6701.070 V_8761.254 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6194.458 V_8986.012 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8598.7119140625\n",
      "Epoch 1870: : Loss: T_5931.025 V_8598.712 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_6307.543 V_8668.968 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8493.0087890625\n",
      "Epoch 1890: : Loss: T_6575.136 V_8493.009 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8492.7744140625\n",
      "Epoch 1900: : Loss: T_6428.941 V_8492.774 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8473.09375\n",
      "Epoch 1910: : Loss: T_6136.803 V_8473.094 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8429.4833984375\n",
      "Epoch 1920: : Loss: T_5860.579 V_8429.483 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8290.0869140625\n",
      "Epoch 1930: : Loss: T_5931.443 V_8290.087 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8121.09765625\n",
      "Epoch 1940: : Loss: T_5762.542 V_8121.098 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7909.9990234375\n",
      "Epoch 1950: : Loss: T_6290.230 V_7909.999 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_6441.003 V_7952.413 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_5478.762 V_8197.766 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7835.04052734375\n",
      "Epoch 1980: : Loss: T_5369.894 V_7835.041 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7690.54150390625\n",
      "Epoch 1990: : Loss: T_5665.312 V_7690.542 | Acc: T_0.000) V_0.000\n",
      "Epoch 2000: : Loss: T_4767.728 V_7806.502 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7533.8583984375\n",
      "Epoch 2010: : Loss: T_5511.151 V_7533.858 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7339.0849609375\n",
      "Epoch 2020: : Loss: T_5727.372 V_7339.085 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_4928.015 V_7579.701 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7221.96923828125\n",
      "Epoch 2040: : Loss: T_5332.029 V_7221.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7171.220703125\n",
      "Epoch 2050: : Loss: T_4778.418 V_7171.221 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5124.515 V_7216.973 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7162.91259765625\n",
      "Epoch 2070: : Loss: T_4882.722 V_7162.913 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7003.1767578125\n",
      "Epoch 2080: : Loss: T_5015.501 V_7003.177 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_4766.764 V_7042.221 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6916.578125\n",
      "Epoch 2100: : Loss: T_4972.691 V_6916.578 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6821.93994140625\n",
      "Epoch 2110: : Loss: T_4881.739 V_6821.940 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6743.2060546875\n",
      "Epoch 2120: : Loss: T_5157.120 V_6743.206 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_5487.864 V_6776.949 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6573.1240234375\n",
      "Epoch 2140: : Loss: T_4752.147 V_6573.124 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_4747.693 V_6779.467 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6525.0400390625\n",
      "Epoch 2160: : Loss: T_4379.708 V_6525.040 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_4597.862 V_6593.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6274.17626953125\n",
      "Epoch 2180: : Loss: T_4418.949 V_6274.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6234.82763671875\n",
      "Epoch 2190: : Loss: T_4166.601 V_6234.828 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6169.1923828125\n",
      "Epoch 2200: : Loss: T_4666.426 V_6169.192 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6148.458984375\n",
      "Epoch 2210: : Loss: T_4566.551 V_6148.459 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_4184.978 V_6155.549 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_3975.450 V_6191.792 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6029.76171875\n",
      "Epoch 2240: : Loss: T_4368.460 V_6029.762 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4663.977 V_6063.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5874.81005859375\n",
      "Epoch 2260: : Loss: T_4033.080 V_5874.810 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_4389.962 V_5971.266 | Acc: T_0.000) V_0.000\n",
      "Epoch 2280: : Loss: T_4445.333 V_5956.156 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5829.7880859375\n",
      "Epoch 2290: : Loss: T_4576.622 V_5829.788 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_5115.342 V_5882.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5654.89306640625\n",
      "Epoch 2310: : Loss: T_3945.841 V_5654.893 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_3846.080 V_5875.509 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_3969.108 V_5657.561 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5460.2626953125\n",
      "Epoch 2340: : Loss: T_3990.909 V_5460.263 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_3980.948 V_5696.092 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4469.754 V_5575.545 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5294.0966796875\n",
      "Epoch 2370: : Loss: T_4582.087 V_5294.097 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4388.147 V_5460.759 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_3746.491 V_5426.448 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4125.436 V_5499.098 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_3993.643 V_5301.022 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5260.61572265625\n",
      "Epoch 2420: : Loss: T_4370.305 V_5260.616 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3779.218 V_5393.012 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5195.6181640625\n",
      "Epoch 2440: : Loss: T_4383.253 V_5195.618 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_3959.672 V_5209.574 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_3677.528 V_5236.269 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4911.671875\n",
      "Epoch 2470: : Loss: T_3872.364 V_4911.672 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_3853.276 V_5144.630 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_3870.995 V_5113.196 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_3758.421 V_4960.184 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_3351.156 V_4957.778 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4733.32568359375\n",
      "Epoch 2520: : Loss: T_4127.590 V_4733.326 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_4433.143 V_4885.668 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_3787.427 V_4777.332 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_3587.634 V_4795.006 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_3235.797 V_4761.456 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4706.9052734375\n",
      "Epoch 2570: : Loss: T_3946.742 V_4706.905 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_3738.204 V_4744.825 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3038.825 V_4801.674 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_3196.463 V_4716.904 | Acc: T_0.000) V_0.000\n",
      "Epoch 2610: : Loss: T_3755.327 V_4795.593 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_3604.753 V_4792.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4631.423828125\n",
      "Epoch 2630: : Loss: T_3348.296 V_4631.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4588.51123046875\n",
      "Epoch 2640: : Loss: T_3474.871 V_4588.511 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_3798.725 V_4661.664 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3532.945 V_4656.956 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4527.2978515625\n",
      "Epoch 2670: : Loss: T_3443.108 V_4527.298 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4443.78369140625\n",
      "Epoch 2680: : Loss: T_3448.146 V_4443.784 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3517.654 V_4685.468 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3456.539 V_4550.855 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4388.97998046875\n",
      "Epoch 2710: : Loss: T_3747.717 V_4388.980 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4324.6396484375\n",
      "Epoch 2720: : Loss: T_3718.982 V_4324.640 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3676.172 V_4434.952 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3699.069 V_4573.179 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3124.202 V_4393.056 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3512.391 V_4400.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3559.456 V_4566.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3251.554 V_4399.169 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4255.6943359375\n",
      "Epoch 2790: : Loss: T_3790.117 V_4255.694 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3678.528 V_4452.192 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3204.816 V_4309.900 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3499.626 V_4339.903 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4066.956 V_4425.396 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3616.048 V_4284.396 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3265.048 V_4325.592 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3566.768 V_4380.908 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3686.370 V_4382.819 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3858.802 V_4315.383 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4211.78564453125\n",
      "Epoch 2890: : Loss: T_3299.705 V_4211.786 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3496.130 V_4269.104 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4093.0986328125\n",
      "Epoch 2910: : Loss: T_3538.256 V_4093.099 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_3800.869 V_4175.176 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3831.136 V_4198.455 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4080.840576171875\n",
      "Epoch 2940: : Loss: T_2859.165 V_4080.841 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3150.362 V_4143.878 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3647.692 V_4201.496 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3756.347 V_4143.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3639.126 V_4185.193 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4072.96337890625\n",
      "Epoch 2990: : Loss: T_3760.128 V_4072.963 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_2942.948 V_4155.381 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4031.66015625\n",
      "Epoch 3010: : Loss: T_3634.650 V_4031.660 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3224.156 V_4149.795 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3130.776 V_4100.127 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3258.590 V_4136.194 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3275.901 V_4152.358 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3559.963 V_4100.279 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3305.882 V_4149.917 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3719.792 V_4114.179 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3061.887 V_4049.765 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4014.961181640625\n",
      "Epoch 3100: : Loss: T_3604.379 V_4014.961 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3485.529 V_4048.247 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3972.447998046875\n",
      "Epoch 3120: : Loss: T_3713.888 V_3972.448 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3012.659 V_4022.668 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3312.012 V_4039.386 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3591.292 V_4008.886 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3825.059 V_4032.276 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3626.260 V_4054.067 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3898.35791015625\n",
      "Epoch 3180: : Loss: T_3044.896 V_3898.358 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3136.402 V_4003.308 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_3033.922 V_3970.363 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3062.912 V_3980.948 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3431.954 V_4067.133 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3739.006 V_4022.343 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3606.800 V_3904.385 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3376.122 V_3941.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3300.311 V_4103.646 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_3808.102 V_4005.446 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3346.168 V_4016.151 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3424.842 V_3973.213 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3339.917 V_4030.964 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3224.347 V_3963.352 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_2970.843 V_4000.003 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3883.67041015625\n",
      "Epoch 3330: : Loss: T_3657.582 V_3883.670 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3785.957 V_4027.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3457.792 V_3907.381 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3453.140 V_4072.084 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3555.151 V_4171.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3601.194 V_3976.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3424.586 V_3903.713 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3258.083 V_4097.268 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3505.620 V_3971.849 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3121.020 V_3941.474 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3343.426 V_4060.180 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3501.771 V_4056.152 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3509.566 V_3971.826 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3877.225341796875\n",
      "Epoch 3460: : Loss: T_3393.825 V_3877.225 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3116.303 V_3984.333 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3217.465 V_3964.404 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3599.885 V_4015.952 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3045.507 V_3888.823 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31951.798828125\n",
      "Epoch 010: : Loss: T_27610.947 V_31951.799 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31947.1484375\n",
      "Epoch 020: : Loss: T_27591.756 V_31947.148 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31929.486328125\n",
      "Epoch 030: : Loss: T_27561.699 V_31929.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31892.71875\n",
      "Epoch 040: : Loss: T_27544.291 V_31892.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31842.298828125\n",
      "Epoch 050: : Loss: T_27495.430 V_31842.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31798.162109375\n",
      "Epoch 060: : Loss: T_27455.080 V_31798.162 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31722.662109375\n",
      "Epoch 070: : Loss: T_27416.049 V_31722.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31639.6015625\n",
      "Epoch 080: : Loss: T_27381.939 V_31639.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31540.9375\n",
      "Epoch 090: : Loss: T_27298.221 V_31540.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31483.412109375\n",
      "Epoch 100: : Loss: T_27266.576 V_31483.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31466.486328125\n",
      "Epoch 110: : Loss: T_27219.584 V_31466.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31389.06640625\n",
      "Epoch 120: : Loss: T_27154.078 V_31389.066 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31287.689453125\n",
      "Epoch 130: : Loss: T_27149.592 V_31287.689 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31260.24609375\n",
      "Epoch 140: : Loss: T_27041.801 V_31260.246 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31197.078125\n",
      "Epoch 150: : Loss: T_26992.453 V_31197.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31103.666015625\n",
      "Epoch 160: : Loss: T_26921.588 V_31103.666 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31057.17578125\n",
      "Epoch 170: : Loss: T_26831.527 V_31057.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31002.00390625\n",
      "Epoch 180: : Loss: T_26896.861 V_31002.004 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30917.828125\n",
      "Epoch 190: : Loss: T_26705.053 V_30917.828 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30851.79296875\n",
      "Epoch 200: : Loss: T_26610.668 V_30851.793 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30740.46875\n",
      "Epoch 210: : Loss: T_26614.010 V_30740.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30731.4609375\n",
      "Epoch 220: : Loss: T_26442.609 V_30731.461 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30529.376953125\n",
      "Epoch 230: : Loss: T_26322.213 V_30529.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30456.486328125\n",
      "Epoch 240: : Loss: T_26331.600 V_30456.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30430.939453125\n",
      "Epoch 250: : Loss: T_26194.244 V_30430.939 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30262.32421875\n",
      "Epoch 260: : Loss: T_26158.701 V_30262.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30122.5703125\n",
      "Epoch 270: : Loss: T_26188.215 V_30122.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30074.71875\n",
      "Epoch 280: : Loss: T_25997.250 V_30074.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29930.70703125\n",
      "Epoch 290: : Loss: T_25902.848 V_29930.707 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29834.8984375\n",
      "Epoch 300: : Loss: T_25578.326 V_29834.898 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29736.4609375\n",
      "Epoch 310: : Loss: T_25736.451 V_29736.461 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29633.693359375\n",
      "Epoch 320: : Loss: T_25451.029 V_29633.693 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29570.048828125\n",
      "Epoch 330: : Loss: T_25544.961 V_29570.049 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29536.7890625\n",
      "Epoch 340: : Loss: T_25248.490 V_29536.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29264.99609375\n",
      "Epoch 350: : Loss: T_25287.195 V_29264.996 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29150.58984375\n",
      "Epoch 360: : Loss: T_25205.084 V_29150.590 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28988.044921875\n",
      "Epoch 370: : Loss: T_25090.295 V_28988.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28939.7578125\n",
      "Epoch 380: : Loss: T_24815.643 V_28939.758 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28797.123046875\n",
      "Epoch 390: : Loss: T_24823.348 V_28797.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28786.646484375\n",
      "Epoch 400: : Loss: T_24644.965 V_28786.646 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28557.955078125\n",
      "Epoch 410: : Loss: T_24552.430 V_28557.955 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28532.626953125\n",
      "Epoch 420: : Loss: T_24452.000 V_28532.627 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28302.640625\n",
      "Epoch 430: : Loss: T_24369.105 V_28302.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 440: : Loss: T_24284.396 V_28349.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27968.05859375\n",
      "Epoch 450: : Loss: T_24240.133 V_27968.059 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27923.158203125\n",
      "Epoch 460: : Loss: T_23881.816 V_27923.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27757.34765625\n",
      "Epoch 470: : Loss: T_23807.381 V_27757.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27636.77734375\n",
      "Epoch 480: : Loss: T_23898.127 V_27636.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27468.431640625\n",
      "Epoch 490: : Loss: T_23501.133 V_27468.432 | Acc: T_0.000) V_0.000\n",
      "Epoch 500: : Loss: T_23491.916 V_27484.998 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27231.4375\n",
      "Epoch 510: : Loss: T_23523.752 V_27231.438 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27009.228515625\n",
      "Epoch 520: : Loss: T_23017.270 V_27009.229 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_23093.680 V_27067.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26912.109375\n",
      "Epoch 540: : Loss: T_23072.842 V_26912.109 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26810.6875\n",
      "Epoch 550: : Loss: T_22665.600 V_26810.688 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26410.685546875\n",
      "Epoch 560: : Loss: T_22697.264 V_26410.686 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26357.580078125\n",
      "Epoch 570: : Loss: T_22820.404 V_26357.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26297.650390625\n",
      "Epoch 580: : Loss: T_22602.967 V_26297.650 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26198.205078125\n",
      "Epoch 590: : Loss: T_22591.441 V_26198.205 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25881.142578125\n",
      "Epoch 600: : Loss: T_21920.516 V_25881.143 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25880.40234375\n",
      "Epoch 610: : Loss: T_21810.260 V_25880.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25457.142578125\n",
      "Epoch 620: : Loss: T_21790.779 V_25457.143 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_21743.449 V_25611.879 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25260.115234375\n",
      "Epoch 640: : Loss: T_21680.762 V_25260.115 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25098.78125\n",
      "Epoch 650: : Loss: T_21758.361 V_25098.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25038.078125\n",
      "Epoch 660: : Loss: T_21156.986 V_25038.078 | Acc: T_0.000) V_0.000\n",
      "Epoch 670: : Loss: T_21327.572 V_25118.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24725.419921875\n",
      "Epoch 680: : Loss: T_20693.236 V_24725.420 | Acc: T_0.000) V_0.000\n",
      "Epoch 690: : Loss: T_20855.490 V_24901.514 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24700.912109375\n",
      "Epoch 700: : Loss: T_20534.793 V_24700.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24114.6015625\n",
      "Epoch 710: : Loss: T_20767.346 V_24114.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_20756.848 V_24247.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23911.666015625\n",
      "Epoch 730: : Loss: T_20129.719 V_23911.666 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23670.310546875\n",
      "Epoch 740: : Loss: T_19885.617 V_23670.311 | Acc: T_0.000) V_0.000\n",
      "Epoch 750: : Loss: T_20303.518 V_23876.648 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23312.353515625\n",
      "Epoch 760: : Loss: T_19683.734 V_23312.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23053.009765625\n",
      "Epoch 770: : Loss: T_19481.961 V_23053.010 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_19640.535 V_23196.520 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22975.0546875\n",
      "Epoch 790: : Loss: T_19609.217 V_22975.055 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22916.552734375\n",
      "Epoch 800: : Loss: T_19154.752 V_22916.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22860.005859375\n",
      "Epoch 810: : Loss: T_18893.752 V_22860.006 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22482.482421875\n",
      "Epoch 820: : Loss: T_18848.396 V_22482.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22403.267578125\n",
      "Epoch 830: : Loss: T_18758.439 V_22403.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22076.5703125\n",
      "Epoch 840: : Loss: T_18710.613 V_22076.570 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_18953.152 V_22110.518 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21822.263671875\n",
      "Epoch 860: : Loss: T_18507.031 V_21822.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21410.7890625\n",
      "Epoch 870: : Loss: T_18022.627 V_21410.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_18276.291 V_21436.502 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21237.412109375\n",
      "Epoch 890: : Loss: T_17767.871 V_21237.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21216.544921875\n",
      "Epoch 900: : Loss: T_17771.893 V_21216.545 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20959.705078125\n",
      "Epoch 910: : Loss: T_18039.699 V_20959.705 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20800.158203125\n",
      "Epoch 920: : Loss: T_17835.414 V_20800.158 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_17314.734 V_20909.775 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20706.578125\n",
      "Epoch 940: : Loss: T_17125.951 V_20706.578 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20177.279296875\n",
      "Epoch 950: : Loss: T_17359.771 V_20177.279 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19958.921875\n",
      "Epoch 960: : Loss: T_17012.334 V_19958.922 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16863.963 V_20090.900 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19582.431640625\n",
      "Epoch 980: : Loss: T_16457.254 V_19582.432 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_16719.127 V_19814.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 1000: : Loss: T_16382.589 V_19842.773 | Acc: T_0.000) V_0.000\n",
      "Epoch 1010: : Loss: T_16768.717 V_19715.596 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19130.85546875\n",
      "Epoch 1020: : Loss: T_16245.511 V_19130.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 1030: : Loss: T_16372.902 V_19227.750 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19035.19921875\n",
      "Epoch 1040: : Loss: T_15753.468 V_19035.199 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18755.298828125\n",
      "Epoch 1050: : Loss: T_15459.741 V_18755.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18754.865234375\n",
      "Epoch 1060: : Loss: T_15836.202 V_18754.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18693.10546875\n",
      "Epoch 1070: : Loss: T_15711.167 V_18693.105 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18444.7890625\n",
      "Epoch 1080: : Loss: T_15434.689 V_18444.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18216.2109375\n",
      "Epoch 1090: : Loss: T_15198.174 V_18216.211 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18005.88671875\n",
      "Epoch 1100: : Loss: T_15588.491 V_18005.887 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_14913.561 V_18233.982 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17855.154296875\n",
      "Epoch 1120: : Loss: T_14701.174 V_17855.154 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17726.24609375\n",
      "Epoch 1130: : Loss: T_14770.040 V_17726.246 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14448.263 V_17829.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17271.990234375\n",
      "Epoch 1150: : Loss: T_14218.582 V_17271.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16899.849609375\n",
      "Epoch 1160: : Loss: T_14377.361 V_16899.850 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_14151.181 V_16903.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16831.234375\n",
      "Epoch 1180: : Loss: T_14055.415 V_16831.234 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16677.849609375\n",
      "Epoch 1190: : Loss: T_13662.315 V_16677.850 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16536.927734375\n",
      "Epoch 1200: : Loss: T_13724.853 V_16536.928 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_13857.280 V_16558.297 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_13278.652 V_16706.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16322.9912109375\n",
      "Epoch 1230: : Loss: T_13003.002 V_16322.991 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16199.96875\n",
      "Epoch 1240: : Loss: T_12920.150 V_16199.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16098.2587890625\n",
      "Epoch 1250: : Loss: T_12781.947 V_16098.259 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15870.2099609375\n",
      "Epoch 1260: : Loss: T_12943.109 V_15870.210 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15770.482421875\n",
      "Epoch 1270: : Loss: T_12760.068 V_15770.482 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_12976.952 V_15842.752 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15197.33984375\n",
      "Epoch 1290: : Loss: T_12424.167 V_15197.340 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_12684.738 V_15484.335 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15003.125\n",
      "Epoch 1310: : Loss: T_12404.811 V_15003.125 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_12226.699 V_15058.810 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_12037.033 V_15109.498 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14665.63671875\n",
      "Epoch 1340: : Loss: T_11972.753 V_14665.637 | Acc: T_0.000) V_0.000\n",
      "Epoch 1350: : Loss: T_11337.603 V_14769.531 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14182.3505859375\n",
      "Epoch 1360: : Loss: T_11318.911 V_14182.351 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11290.134 V_14406.639 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_12033.729 V_14425.234 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13897.857421875\n",
      "Epoch 1390: : Loss: T_11169.865 V_13897.857 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13788.47265625\n",
      "Epoch 1400: : Loss: T_11496.491 V_13788.473 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_11006.031 V_13924.982 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13669.8876953125\n",
      "Epoch 1420: : Loss: T_10898.378 V_13669.888 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13313.296875\n",
      "Epoch 1430: : Loss: T_10903.268 V_13313.297 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_10577.600 V_13755.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13149.3193359375\n",
      "Epoch 1450: : Loss: T_10780.100 V_13149.319 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12965.388671875\n",
      "Epoch 1460: : Loss: T_10625.448 V_12965.389 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12866.4326171875\n",
      "Epoch 1470: : Loss: T_10707.883 V_12866.433 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12807.525390625\n",
      "Epoch 1480: : Loss: T_10729.447 V_12807.525 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12588.966796875\n",
      "Epoch 1490: : Loss: T_10613.189 V_12588.967 | Acc: T_0.000) V_0.000\n",
      "Epoch 1500: : Loss: T_10333.902 V_12621.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12353.6572265625\n",
      "Epoch 1510: : Loss: T_10304.870 V_12353.657 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12331.3447265625\n",
      "Epoch 1520: : Loss: T_9935.867 V_12331.345 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12077.7861328125\n",
      "Epoch 1530: : Loss: T_9482.940 V_12077.786 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11967.3330078125\n",
      "Epoch 1540: : Loss: T_9535.484 V_11967.333 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11939.25\n",
      "Epoch 1550: : Loss: T_9728.316 V_11939.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11541.119140625\n",
      "Epoch 1560: : Loss: T_9117.368 V_11541.119 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9604.196 V_11565.450 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11461.39453125\n",
      "Epoch 1580: : Loss: T_9337.956 V_11461.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11255.5400390625\n",
      "Epoch 1590: : Loss: T_9143.758 V_11255.540 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11190.1298828125\n",
      "Epoch 1600: : Loss: T_9407.000 V_11190.130 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11025.8388671875\n",
      "Epoch 1610: : Loss: T_8655.499 V_11025.839 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10845.2412109375\n",
      "Epoch 1620: : Loss: T_8757.017 V_10845.241 | Acc: T_0.000) V_0.000\n",
      "Epoch 1630: : Loss: T_9238.113 V_10892.558 | Acc: T_0.000) V_0.000\n",
      "Epoch 1640: : Loss: T_9175.165 V_10872.802 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10528.54296875\n",
      "Epoch 1650: : Loss: T_8546.809 V_10528.543 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_8863.785 V_11079.247 | Acc: T_0.000) V_0.000\n",
      "Epoch 1670: : Loss: T_7879.536 V_10967.217 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10191.6796875\n",
      "Epoch 1680: : Loss: T_8393.459 V_10191.680 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9852.12890625\n",
      "Epoch 1690: : Loss: T_7620.069 V_9852.129 | Acc: T_0.000) V_0.000\n",
      "Epoch 1700: : Loss: T_8197.597 V_10204.511 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_7959.380 V_9954.389 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_7804.458 V_9974.677 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_7867.136 V_9897.628 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9673.267578125\n",
      "Epoch 1740: : Loss: T_7217.425 V_9673.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9570.5322265625\n",
      "Epoch 1750: : Loss: T_7768.991 V_9570.532 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9532.294921875\n",
      "Epoch 1760: : Loss: T_8106.717 V_9532.295 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7331.301 V_9777.582 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9187.021484375\n",
      "Epoch 1780: : Loss: T_7654.464 V_9187.021 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9147.9921875\n",
      "Epoch 1790: : Loss: T_7343.597 V_9147.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_7192.511 V_9155.606 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8804.0029296875\n",
      "Epoch 1810: : Loss: T_7018.112 V_8804.003 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_7173.457 V_8823.032 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_6848.123 V_8981.019 | Acc: T_0.000) V_0.000\n",
      "Epoch 1840: : Loss: T_7044.844 V_8848.809 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8324.3544921875\n",
      "Epoch 1850: : Loss: T_7200.168 V_8324.354 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6525.245 V_8649.086 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_6861.965 V_8503.350 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8208.7744140625\n",
      "Epoch 1880: : Loss: T_6540.604 V_8208.774 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7979.4736328125\n",
      "Epoch 1890: : Loss: T_6245.565 V_7979.474 | Acc: T_0.000) V_0.000\n",
      "Epoch 1900: : Loss: T_6314.868 V_8106.336 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7842.74560546875\n",
      "Epoch 1910: : Loss: T_6721.325 V_7842.746 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6017.349 V_7920.635 | Acc: T_0.000) V_0.000\n",
      "Epoch 1930: : Loss: T_6373.243 V_8005.560 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7839.96923828125\n",
      "Epoch 1940: : Loss: T_5950.609 V_7839.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7703.20751953125\n",
      "Epoch 1950: : Loss: T_6437.434 V_7703.208 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7687.990234375\n",
      "Epoch 1960: : Loss: T_5898.104 V_7687.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7572.8642578125\n",
      "Epoch 1970: : Loss: T_6487.605 V_7572.864 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7566.9931640625\n",
      "Epoch 1980: : Loss: T_6073.127 V_7566.993 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7514.33984375\n",
      "Epoch 1990: : Loss: T_6356.703 V_7514.340 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7265.0146484375\n",
      "Epoch 2000: : Loss: T_5549.080 V_7265.015 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7068.6005859375\n",
      "Epoch 2010: : Loss: T_5501.587 V_7068.601 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_5878.365 V_7231.838 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6791.046875\n",
      "Epoch 2030: : Loss: T_5492.985 V_6791.047 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_5933.657 V_6887.271 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5258.906 V_6851.575 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5671.852 V_6948.612 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6553.6572265625\n",
      "Epoch 2070: : Loss: T_5093.993 V_6553.657 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6458.86669921875\n",
      "Epoch 2080: : Loss: T_5454.060 V_6458.867 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5217.197 V_6559.206 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6426.04248046875\n",
      "Epoch 2100: : Loss: T_5943.855 V_6426.042 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6359.22314453125\n",
      "Epoch 2110: : Loss: T_5449.574 V_6359.223 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6349.84619140625\n",
      "Epoch 2120: : Loss: T_5073.103 V_6349.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_5245.967 V_6558.352 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_5072.848 V_6351.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6113.98583984375\n",
      "Epoch 2150: : Loss: T_5025.484 V_6113.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_5431.285 V_6290.600 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6035.322265625\n",
      "Epoch 2170: : Loss: T_4853.399 V_6035.322 | Acc: T_0.000) V_0.000\n",
      "Epoch 2180: : Loss: T_5185.946 V_6043.889 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6024.07275390625\n",
      "Epoch 2190: : Loss: T_5072.087 V_6024.073 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5904.9755859375\n",
      "Epoch 2200: : Loss: T_4881.388 V_5904.976 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5774.669921875\n",
      "Epoch 2210: : Loss: T_4840.466 V_5774.670 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_4824.991 V_5883.430 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5714.80810546875\n",
      "Epoch 2230: : Loss: T_4660.167 V_5714.808 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5546.60888671875\n",
      "Epoch 2240: : Loss: T_4957.065 V_5546.609 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5546.29931640625\n",
      "Epoch 2250: : Loss: T_4365.858 V_5546.299 | Acc: T_0.000) V_0.000\n",
      "Epoch 2260: : Loss: T_4275.299 V_5587.418 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5488.58447265625\n",
      "Epoch 2270: : Loss: T_4717.050 V_5488.584 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5407.8935546875\n",
      "Epoch 2280: : Loss: T_4672.194 V_5407.894 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_4876.186 V_5581.346 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4255.243 V_5538.141 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4452.920 V_5491.899 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5231.18115234375\n",
      "Epoch 2320: : Loss: T_4164.315 V_5231.181 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_4598.412 V_5301.806 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5147.24853515625\n",
      "Epoch 2340: : Loss: T_4134.419 V_5147.249 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4985.85888671875\n",
      "Epoch 2350: : Loss: T_4723.866 V_4985.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4117.516 V_5059.560 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_4328.519 V_5098.877 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4476.200 V_5107.556 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4967.4462890625\n",
      "Epoch 2390: : Loss: T_3708.260 V_4967.446 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4109.225 V_5108.240 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4210.755 V_5023.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4765.3466796875\n",
      "Epoch 2420: : Loss: T_4251.815 V_4765.347 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_4354.974 V_4856.124 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4272.374 V_4875.150 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4752.8359375\n",
      "Epoch 2450: : Loss: T_4584.721 V_4752.836 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_4702.152 V_4780.500 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4133.206 V_4790.106 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4727.12939453125\n",
      "Epoch 2480: : Loss: T_4775.185 V_4727.129 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_4416.739 V_4728.722 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_4005.790 V_4855.130 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_3574.472 V_4732.384 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4589.18994140625\n",
      "Epoch 2520: : Loss: T_3613.225 V_4589.190 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4546.056640625\n",
      "Epoch 2530: : Loss: T_3986.346 V_4546.057 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4544.8154296875\n",
      "Epoch 2540: : Loss: T_4344.766 V_4544.815 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_4244.215 V_4557.048 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4528.5595703125\n",
      "Epoch 2560: : Loss: T_3937.054 V_4528.560 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4480.8994140625\n",
      "Epoch 2570: : Loss: T_4011.736 V_4480.899 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_4115.488 V_4494.339 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4363.201171875\n",
      "Epoch 2590: : Loss: T_4224.900 V_4363.201 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_4169.509 V_4444.741 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4321.974609375\n",
      "Epoch 2610: : Loss: T_4293.954 V_4321.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4237.58154296875\n",
      "Epoch 2620: : Loss: T_3874.309 V_4237.582 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4406.743 V_4369.249 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_3785.442 V_4399.943 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4225.073 V_4369.113 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3570.446 V_4275.400 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4236.03466796875\n",
      "Epoch 2670: : Loss: T_3735.615 V_4236.035 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_3910.813 V_4253.712 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4234.65380859375\n",
      "Epoch 2690: : Loss: T_3921.148 V_4234.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4138.74609375\n",
      "Epoch 2700: : Loss: T_4371.875 V_4138.746 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_3399.359 V_4163.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4122.59130859375\n",
      "Epoch 2720: : Loss: T_3882.347 V_4122.591 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3865.467 V_4233.177 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4007.574462890625\n",
      "Epoch 2740: : Loss: T_3728.786 V_4007.574 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3931.264 V_4111.833 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3747.786 V_4165.898 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3690.960 V_4187.409 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3757.416 V_4172.989 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_4405.330 V_4077.078 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3646.314 V_4115.082 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_4011.872 V_4117.913 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3405.403 V_4166.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4288.706 V_4162.564 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_3940.261 V_4121.011 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_4135.104 V_4183.138 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3986.70068359375\n",
      "Epoch 2860: : Loss: T_3649.780 V_3986.701 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3447.330 V_4019.031 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3685.723 V_4027.547 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3558.852 V_3988.178 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3864.685791015625\n",
      "Epoch 2900: : Loss: T_3863.141 V_3864.686 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_4144.573 V_3940.346 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_4500.438 V_3909.282 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3945.275 V_3958.876 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3818.75830078125\n",
      "Epoch 2940: : Loss: T_3865.323 V_3818.758 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3597.115 V_3865.388 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3788.780 V_3868.075 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3573.517 V_3850.980 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3808.828857421875\n",
      "Epoch 2980: : Loss: T_3695.312 V_3808.829 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3806.806396484375\n",
      "Epoch 2990: : Loss: T_3735.572 V_3806.806 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3921.472 V_3809.224 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3666.544 V_3926.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3762.360107421875\n",
      "Epoch 3020: : Loss: T_3524.404 V_3762.360 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3671.547 V_3836.215 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3580.274 V_3813.736 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_4064.582 V_3856.675 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3864.365 V_3869.809 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3991.225 V_3773.511 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_4032.034 V_3868.808 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3745.615234375\n",
      "Epoch 3090: : Loss: T_3965.161 V_3745.615 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3588.778 V_3768.673 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3482.399 V_3825.474 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_4022.759 V_3756.098 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3821.705 V_3746.325 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3722.12939453125\n",
      "Epoch 3140: : Loss: T_3568.516 V_3722.129 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3712.622802734375\n",
      "Epoch 3150: : Loss: T_3167.355 V_3712.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3910.984 V_3782.923 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3705.345947265625\n",
      "Epoch 3170: : Loss: T_3289.359 V_3705.346 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3845.024 V_3732.088 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3656.65771484375\n",
      "Epoch 3190: : Loss: T_3732.346 V_3656.658 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_3712.698 V_3722.202 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_4266.498 V_3716.825 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3909.457 V_3702.657 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3888.948 V_3704.014 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3636.461 V_3742.429 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3468.891 V_3672.385 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3771.368 V_3684.510 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_3343.099 V_3705.681 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3630.677001953125\n",
      "Epoch 3280: : Loss: T_3773.954 V_3630.677 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_4056.693 V_3635.933 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3713.704 V_3734.399 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3281.338 V_3729.356 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3608.077392578125\n",
      "Epoch 3320: : Loss: T_3976.719 V_3608.077 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3921.539 V_3688.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3757.357 V_3751.419 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_4353.044 V_3645.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3591.114 V_3808.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3264.130 V_3773.865 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3754.088 V_3743.706 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3536.494 V_3616.124 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_4301.573 V_3695.829 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3678.491 V_3827.537 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3958.021 V_3818.350 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3753.373 V_3652.164 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_4380.347 V_3670.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3851.228 V_3756.928 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3929.546 V_3797.755 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3474.888 V_3771.672 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3219.701 V_3741.492 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3576.920 V_3727.794 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_4068.239 V_3666.874 | Acc: T_0.000) V_0.000\n"
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "for i in range(NUM_ENSEMBLE_MODELS):\n",
    "    model = BasicRegressor()\n",
    "    model.to(device)\n",
    "\n",
    "    # criterion = nn.L1Loss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    bagg_indices = np.random.choice(range(len(x_train)), len(x_train), replace=True)\n",
    "\n",
    "    x_train_bagg = x_train[bagg_indices, :]\n",
    "    y_train_bagg = y_train[bagg_indices, :]\n",
    "    # train_data = TrainData(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "    train_data = TrainData(torch.FloatTensor(x_train_bagg), torch.FloatTensor(y_train_bagg))\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "\n",
    "    num_train_data = len(train_loader)\n",
    "    num_eval_data = len(valid_loader)\n",
    "\n",
    "\n",
    "    elapsed_time_basic_ann = []\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    best_model = train_model(num_train_data, num_eval_data)\n",
    "\n",
    "    best_models.append(best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "sum_output = np.zeros(y_test.shape)\n",
    "\n",
    "for best_model in best_models:\n",
    "    best_model.eval()\n",
    "    output = best_model(data)\n",
    "    sum_output += output.detach().numpy()\n",
    "\n",
    "avg_output = sum_output / len(best_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare Loss  90.60466670989992\n",
      "Normal Loss  36.6066241243701\n",
      "Total Loss  43.887259079722426\n"
     ]
    }
   ],
   "source": [
    "rare_loss, normal_loss, total_loss = calc_l1_loss_by_shots(avg_output, answer.detach().numpy())\n",
    "print(\"Rare Loss \", rare_loss)\n",
    "print(\"Normal Loss \", normal_loss)\n",
    "print(\"Total Loss \", total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble ANN with REBAGG (REsampling Bagging Method, 2018, P Branco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENSEMBLE_MODELS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_value = threshold_rare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_indicies = np.where(y_train>threshold_rare)[0]\n",
    "normal_indicies = np.where(y_train<=threshold_rare)[0]\n",
    "\n",
    "ov_rare_indicies = np.random.choice(range(len(rare_indicies)), len(normal_indicies), replace=True)\n",
    "\n",
    "x_train_normal_bagg = x_train[normal_indicies, :]\n",
    "y_train_normal_bagg = y_train[normal_indicies, :]\n",
    "\n",
    "\n",
    "x_train_rare_bagg = x_train[ov_rare_indicies, :]\n",
    "y_train_rare_bagg = y_train[ov_rare_indicies, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model is copied - Best Loss :  31809.47265625\n",
      "Epoch 010: : Loss: T_27584.117 V_31809.473 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31728.5703125\n",
      "Epoch 020: : Loss: T_27516.529 V_31728.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31665.228515625\n",
      "Epoch 030: : Loss: T_27501.004 V_31665.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31600.890625\n",
      "Epoch 040: : Loss: T_27455.826 V_31600.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31544.732421875\n",
      "Epoch 050: : Loss: T_27428.688 V_31544.732 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31481.04296875\n",
      "Epoch 060: : Loss: T_27383.965 V_31481.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31440.837890625\n",
      "Epoch 070: : Loss: T_27312.703 V_31440.838 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31393.986328125\n",
      "Epoch 080: : Loss: T_27288.891 V_31393.986 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31347.2421875\n",
      "Epoch 090: : Loss: T_27265.301 V_31347.242 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31309.6796875\n",
      "Epoch 100: : Loss: T_27162.510 V_31309.680 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31267.25\n",
      "Epoch 110: : Loss: T_27139.760 V_31267.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31220.048828125\n",
      "Epoch 120: : Loss: T_27066.395 V_31220.049 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31182.939453125\n",
      "Epoch 130: : Loss: T_26975.727 V_31182.939 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31090.666015625\n",
      "Epoch 140: : Loss: T_26941.041 V_31090.666 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31001.578125\n",
      "Epoch 150: : Loss: T_26892.260 V_31001.578 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30955.17578125\n",
      "Epoch 160: : Loss: T_26786.793 V_30955.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30875.2109375\n",
      "Epoch 170: : Loss: T_26809.504 V_30875.211 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30842.07421875\n",
      "Epoch 180: : Loss: T_26608.652 V_30842.074 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30833.478515625\n",
      "Epoch 190: : Loss: T_26636.637 V_30833.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30715.736328125\n",
      "Epoch 200: : Loss: T_26559.705 V_30715.736 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30544.7421875\n",
      "Epoch 210: : Loss: T_26464.453 V_30544.742 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30491.830078125\n",
      "Epoch 220: : Loss: T_26342.664 V_30491.830 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30369.197265625\n",
      "Epoch 230: : Loss: T_26272.094 V_30369.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30196.974609375\n",
      "Epoch 240: : Loss: T_26169.158 V_30196.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30129.810546875\n",
      "Epoch 250: : Loss: T_26057.953 V_30129.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30093.14453125\n",
      "Epoch 260: : Loss: T_26069.168 V_30093.145 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30084.095703125\n",
      "Epoch 270: : Loss: T_25940.953 V_30084.096 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29957.517578125\n",
      "Epoch 280: : Loss: T_25902.371 V_29957.518 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29834.6015625\n",
      "Epoch 290: : Loss: T_25740.625 V_29834.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 300: : Loss: T_25495.656 V_29859.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29691.478515625\n",
      "Epoch 310: : Loss: T_25506.592 V_29691.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29596.587890625\n",
      "Epoch 320: : Loss: T_25335.816 V_29596.588 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29448.3984375\n",
      "Epoch 330: : Loss: T_25354.740 V_29448.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29192.05078125\n",
      "Epoch 340: : Loss: T_25152.252 V_29192.051 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29082.044921875\n",
      "Epoch 350: : Loss: T_25071.002 V_29082.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28987.96875\n",
      "Epoch 360: : Loss: T_24900.301 V_28987.969 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28927.873046875\n",
      "Epoch 370: : Loss: T_24731.680 V_28927.873 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28760.3671875\n",
      "Epoch 380: : Loss: T_24726.709 V_28760.367 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28544.185546875\n",
      "Epoch 390: : Loss: T_24817.283 V_28544.186 | Acc: T_0.000) V_0.000\n",
      "Epoch 400: : Loss: T_24713.068 V_28703.088 | Acc: T_0.000) V_0.000\n",
      "Epoch 410: : Loss: T_24243.564 V_28704.262 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28377.1875\n",
      "Epoch 420: : Loss: T_24456.590 V_28377.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27861.486328125\n",
      "Epoch 430: : Loss: T_24261.260 V_27861.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27786.388671875\n",
      "Epoch 440: : Loss: T_24078.025 V_27786.389 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27659.546875\n",
      "Epoch 450: : Loss: T_23881.926 V_27659.547 | Acc: T_0.000) V_0.000\n",
      "Epoch 460: : Loss: T_23856.264 V_27820.416 | Acc: T_0.000) V_0.000\n",
      "Epoch 470: : Loss: T_23710.598 V_27845.047 | Acc: T_0.000) V_0.000\n",
      "Epoch 480: : Loss: T_23322.688 V_27668.068 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27354.80859375\n",
      "Epoch 490: : Loss: T_23343.264 V_27354.809 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27137.775390625\n",
      "Epoch 500: : Loss: T_23012.373 V_27137.775 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27012.98046875\n",
      "Epoch 510: : Loss: T_23185.875 V_27012.980 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26747.048828125\n",
      "Epoch 520: : Loss: T_22875.492 V_26747.049 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26425.560546875\n",
      "Epoch 530: : Loss: T_22734.908 V_26425.561 | Acc: T_0.000) V_0.000\n",
      "Epoch 540: : Loss: T_22812.049 V_26765.824 | Acc: T_0.000) V_0.000\n",
      "Epoch 550: : Loss: T_22430.055 V_26603.953 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_22561.779 V_26497.887 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26120.794921875\n",
      "Epoch 570: : Loss: T_22308.686 V_26120.795 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26045.90234375\n",
      "Epoch 580: : Loss: T_22241.738 V_26045.902 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25967.509765625\n",
      "Epoch 590: : Loss: T_22141.852 V_25967.510 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25655.466796875\n",
      "Epoch 600: : Loss: T_21993.238 V_25655.467 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25451.0703125\n",
      "Epoch 610: : Loss: T_21724.047 V_25451.070 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_21561.723 V_25497.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25246.3125\n",
      "Epoch 630: : Loss: T_21778.902 V_25246.312 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24730.27734375\n",
      "Epoch 640: : Loss: T_21323.549 V_24730.277 | Acc: T_0.000) V_0.000\n",
      "Epoch 650: : Loss: T_21304.137 V_25066.691 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_21010.307 V_25043.760 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24513.703125\n",
      "Epoch 670: : Loss: T_20655.414 V_24513.703 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24295.4765625\n",
      "Epoch 680: : Loss: T_20723.393 V_24295.477 | Acc: T_0.000) V_0.000\n",
      "Epoch 690: : Loss: T_20571.318 V_24742.803 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24127.68359375\n",
      "Epoch 700: : Loss: T_20368.918 V_24127.684 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23838.109375\n",
      "Epoch 710: : Loss: T_20464.982 V_23838.109 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_20141.037 V_24068.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23716.310546875\n",
      "Epoch 730: : Loss: T_19962.848 V_23716.311 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23542.009765625\n",
      "Epoch 740: : Loss: T_19955.447 V_23542.010 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23333.4609375\n",
      "Epoch 750: : Loss: T_19924.070 V_23333.461 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22937.580078125\n",
      "Epoch 760: : Loss: T_19200.924 V_22937.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22912.115234375\n",
      "Epoch 770: : Loss: T_19829.527 V_22912.115 | Acc: T_0.000) V_0.000\n",
      "Epoch 780: : Loss: T_19253.184 V_22912.635 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22621.642578125\n",
      "Epoch 790: : Loss: T_19392.279 V_22621.643 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22285.146484375\n",
      "Epoch 800: : Loss: T_18868.625 V_22285.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 810: : Loss: T_19050.104 V_22861.768 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_18861.564 V_22463.848 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21932.052734375\n",
      "Epoch 830: : Loss: T_18736.908 V_21932.053 | Acc: T_0.000) V_0.000\n",
      "Epoch 840: : Loss: T_18312.461 V_22009.266 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21858.021484375\n",
      "Epoch 850: : Loss: T_18340.830 V_21858.021 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21538.3125\n",
      "Epoch 860: : Loss: T_18642.676 V_21538.312 | Acc: T_0.000) V_0.000\n",
      "Epoch 870: : Loss: T_18111.270 V_21719.744 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_17395.576 V_21765.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21078.62890625\n",
      "Epoch 890: : Loss: T_18105.801 V_21078.629 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20533.16015625\n",
      "Epoch 900: : Loss: T_17657.574 V_20533.160 | Acc: T_0.000) V_0.000\n",
      "Epoch 910: : Loss: T_17211.178 V_20823.566 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_17657.291 V_20874.838 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_17108.773 V_21178.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19949.810546875\n",
      "Epoch 940: : Loss: T_17409.881 V_19949.811 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_16963.680 V_20070.119 | Acc: T_0.000) V_0.000\n",
      "Epoch 960: : Loss: T_16856.533 V_20224.232 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19947.634765625\n",
      "Epoch 970: : Loss: T_16905.590 V_19947.635 | Acc: T_0.000) V_0.000\n",
      "Epoch 980: : Loss: T_16649.807 V_19958.625 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19817.119140625\n",
      "Epoch 990: : Loss: T_16452.959 V_19817.119 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19319.939453125\n",
      "Epoch 1000: : Loss: T_16070.678 V_19319.939 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19130.533203125\n",
      "Epoch 1010: : Loss: T_16379.354 V_19130.533 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19065.59765625\n",
      "Epoch 1020: : Loss: T_16438.092 V_19065.598 | Acc: T_0.000) V_0.000\n",
      "Epoch 1030: : Loss: T_15746.222 V_19082.805 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18669.669921875\n",
      "Epoch 1040: : Loss: T_15548.198 V_18669.670 | Acc: T_0.000) V_0.000\n",
      "Epoch 1050: : Loss: T_15625.363 V_18833.951 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18495.66796875\n",
      "Epoch 1060: : Loss: T_15393.626 V_18495.668 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18045.09765625\n",
      "Epoch 1070: : Loss: T_15683.400 V_18045.098 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_15452.803 V_18119.338 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17810.265625\n",
      "Epoch 1090: : Loss: T_15321.667 V_17810.266 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14955.213 V_18279.117 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_14996.995 V_17930.752 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17377.578125\n",
      "Epoch 1120: : Loss: T_14625.903 V_17377.578 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17323.013671875\n",
      "Epoch 1130: : Loss: T_14816.228 V_17323.014 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_15155.463 V_17670.674 | Acc: T_0.000) V_0.000\n",
      "Epoch 1150: : Loss: T_14179.044 V_17341.711 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17206.009765625\n",
      "Epoch 1160: : Loss: T_14464.924 V_17206.010 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16589.189453125\n",
      "Epoch 1170: : Loss: T_13756.359 V_16589.189 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_13913.952 V_16602.258 | Acc: T_0.000) V_0.000\n",
      "Epoch 1190: : Loss: T_14563.559 V_16619.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16060.158203125\n",
      "Epoch 1200: : Loss: T_14249.115 V_16060.158 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_13899.134 V_16581.697 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_13154.526 V_16504.736 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15700.4228515625\n",
      "Epoch 1230: : Loss: T_13115.413 V_15700.423 | Acc: T_0.000) V_0.000\n",
      "Epoch 1240: : Loss: T_12863.204 V_15905.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15669.5439453125\n",
      "Epoch 1250: : Loss: T_12878.801 V_15669.544 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15359.642578125\n",
      "Epoch 1260: : Loss: T_12802.695 V_15359.643 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15172.3837890625\n",
      "Epoch 1270: : Loss: T_12614.836 V_15172.384 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_12578.523 V_15340.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15135.0224609375\n",
      "Epoch 1290: : Loss: T_13211.669 V_15135.022 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14862.748046875\n",
      "Epoch 1300: : Loss: T_12478.268 V_14862.748 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14222.1337890625\n",
      "Epoch 1310: : Loss: T_12595.491 V_14222.134 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_11994.180 V_14606.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_11586.207 V_14530.806 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11965.059 V_14232.494 | Acc: T_0.000) V_0.000\n",
      "Epoch 1350: : Loss: T_12410.608 V_14353.090 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14123.06640625\n",
      "Epoch 1360: : Loss: T_11936.318 V_14123.066 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13930.7060546875\n",
      "Epoch 1370: : Loss: T_11618.433 V_13930.706 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_11554.902 V_14006.908 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_11436.327 V_14053.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13335.6865234375\n",
      "Epoch 1400: : Loss: T_11298.646 V_13335.687 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_10989.025 V_13335.805 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_11494.689 V_13460.014 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13111.18359375\n",
      "Epoch 1430: : Loss: T_10759.498 V_13111.184 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12960.2275390625\n",
      "Epoch 1440: : Loss: T_11045.945 V_12960.228 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12907.359375\n",
      "Epoch 1450: : Loss: T_11047.558 V_12907.359 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12446.849609375\n",
      "Epoch 1460: : Loss: T_10421.349 V_12446.850 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_10542.735 V_12567.575 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_10565.312 V_12451.325 | Acc: T_0.000) V_0.000\n",
      "Epoch 1490: : Loss: T_9852.462 V_12519.202 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11984.498046875\n",
      "Epoch 1500: : Loss: T_10694.221 V_11984.498 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11888.7216796875\n",
      "Epoch 1510: : Loss: T_10195.165 V_11888.722 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_10054.593 V_12081.336 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11840.0576171875\n",
      "Epoch 1530: : Loss: T_9715.922 V_11840.058 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11824.7236328125\n",
      "Epoch 1540: : Loss: T_10086.093 V_11824.724 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11600.2236328125\n",
      "Epoch 1550: : Loss: T_9026.213 V_11600.224 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11568.08203125\n",
      "Epoch 1560: : Loss: T_9311.404 V_11568.082 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11540.4541015625\n",
      "Epoch 1570: : Loss: T_9241.027 V_11540.454 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11250.01953125\n",
      "Epoch 1580: : Loss: T_9303.593 V_11250.020 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11022.359375\n",
      "Epoch 1590: : Loss: T_9359.245 V_11022.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_8659.071 V_11036.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10831.8798828125\n",
      "Epoch 1610: : Loss: T_9251.168 V_10831.880 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10830.3798828125\n",
      "Epoch 1620: : Loss: T_9739.604 V_10830.380 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10702.734375\n",
      "Epoch 1630: : Loss: T_8939.662 V_10702.734 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10673.4296875\n",
      "Epoch 1640: : Loss: T_8645.870 V_10673.430 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10406.5634765625\n",
      "Epoch 1650: : Loss: T_8452.396 V_10406.563 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_8184.675 V_10473.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10247.33984375\n",
      "Epoch 1670: : Loss: T_8514.693 V_10247.340 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_8492.802 V_10261.405 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_7858.720 V_10420.286 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9692.1083984375\n",
      "Epoch 1700: : Loss: T_8555.516 V_9692.108 | Acc: T_0.000) V_0.000\n",
      "Epoch 1710: : Loss: T_8244.426 V_9827.266 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_8505.771 V_9841.400 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9355.4345703125\n",
      "Epoch 1730: : Loss: T_7413.119 V_9355.435 | Acc: T_0.000) V_0.000\n",
      "Epoch 1740: : Loss: T_7999.414 V_9571.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9324.9833984375\n",
      "Epoch 1750: : Loss: T_7298.440 V_9324.983 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9247.5546875\n",
      "Epoch 1760: : Loss: T_7909.708 V_9247.555 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7901.252 V_9397.669 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8999.181640625\n",
      "Epoch 1780: : Loss: T_8263.007 V_8999.182 | Acc: T_0.000) V_0.000\n",
      "Epoch 1790: : Loss: T_7282.061 V_9020.552 | Acc: T_0.000) V_0.000\n",
      "Epoch 1800: : Loss: T_7460.188 V_9074.816 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8830.2490234375\n",
      "Epoch 1810: : Loss: T_7448.014 V_8830.249 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8595.263671875\n",
      "Epoch 1820: : Loss: T_7646.408 V_8595.264 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_7598.470 V_8787.751 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8312.958984375\n",
      "Epoch 1840: : Loss: T_7338.962 V_8312.959 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6989.082 V_8487.978 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6844.451 V_8535.320 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_6787.413 V_8355.523 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8150.36865234375\n",
      "Epoch 1880: : Loss: T_6934.787 V_8150.369 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6463.194 V_8241.203 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7837.482421875\n",
      "Epoch 1900: : Loss: T_6163.625 V_7837.482 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_7016.111 V_8357.800 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6458.098 V_8063.053 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7713.4736328125\n",
      "Epoch 1930: : Loss: T_6709.729 V_7713.474 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7661.44873046875\n",
      "Epoch 1940: : Loss: T_6815.307 V_7661.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 1950: : Loss: T_6657.267 V_7889.825 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7449.5458984375\n",
      "Epoch 1960: : Loss: T_6790.012 V_7449.546 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_6692.949 V_7777.129 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7346.5400390625\n",
      "Epoch 1980: : Loss: T_5845.529 V_7346.540 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_6481.464 V_7368.836 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7253.3486328125\n",
      "Epoch 2000: : Loss: T_6126.803 V_7253.349 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7027.443359375\n",
      "Epoch 2010: : Loss: T_6216.475 V_7027.443 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_5755.125 V_7150.244 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_5883.550 V_7301.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7020.2099609375\n",
      "Epoch 2040: : Loss: T_5914.334 V_7020.210 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6893.1904296875\n",
      "Epoch 2050: : Loss: T_5301.681 V_6893.190 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5896.959 V_6980.315 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6807.79052734375\n",
      "Epoch 2070: : Loss: T_5315.771 V_6807.791 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6752.56640625\n",
      "Epoch 2080: : Loss: T_5376.728 V_6752.566 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6734.94287109375\n",
      "Epoch 2090: : Loss: T_5879.548 V_6734.943 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6583.20947265625\n",
      "Epoch 2100: : Loss: T_6254.344 V_6583.209 | Acc: T_0.000) V_0.000\n",
      "Epoch 2110: : Loss: T_5321.690 V_6647.032 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6529.1328125\n",
      "Epoch 2120: : Loss: T_5559.275 V_6529.133 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6478.6337890625\n",
      "Epoch 2130: : Loss: T_5449.894 V_6478.634 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_5590.569 V_6500.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6400.60546875\n",
      "Epoch 2150: : Loss: T_5046.038 V_6400.605 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6320.93603515625\n",
      "Epoch 2160: : Loss: T_5268.068 V_6320.936 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6284.23974609375\n",
      "Epoch 2170: : Loss: T_5335.646 V_6284.240 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6135.43115234375\n",
      "Epoch 2180: : Loss: T_5749.922 V_6135.431 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_5514.539 V_6223.535 | Acc: T_0.000) V_0.000\n",
      "Epoch 2200: : Loss: T_5186.049 V_6206.844 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6043.23388671875\n",
      "Epoch 2210: : Loss: T_5071.199 V_6043.234 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_5022.398 V_6049.431 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_4746.837 V_6070.801 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5922.32568359375\n",
      "Epoch 2240: : Loss: T_5229.530 V_5922.326 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_5024.925 V_5991.259 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5869.271484375\n",
      "Epoch 2260: : Loss: T_5263.235 V_5869.271 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5837.2041015625\n",
      "Epoch 2270: : Loss: T_4605.942 V_5837.204 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5822.55322265625\n",
      "Epoch 2280: : Loss: T_4975.491 V_5822.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5685.26416015625\n",
      "Epoch 2290: : Loss: T_4910.856 V_5685.264 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4513.809 V_5784.314 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4386.770 V_5786.277 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5614.34765625\n",
      "Epoch 2320: : Loss: T_5163.142 V_5614.348 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5488.93896484375\n",
      "Epoch 2330: : Loss: T_5325.804 V_5488.939 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4551.252 V_5600.988 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5470.52197265625\n",
      "Epoch 2350: : Loss: T_4308.180 V_5470.522 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4748.354 V_5530.104 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5460.1015625\n",
      "Epoch 2370: : Loss: T_4395.865 V_5460.102 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4214.583 V_5535.792 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5455.92138671875\n",
      "Epoch 2390: : Loss: T_4892.177 V_5455.921 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5269.0869140625\n",
      "Epoch 2400: : Loss: T_4381.264 V_5269.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4932.013 V_5280.181 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_4370.990 V_5277.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_4629.115 V_5274.073 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4788.953 V_5276.308 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5153.58984375\n",
      "Epoch 2450: : Loss: T_4807.760 V_5153.590 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5135.830078125\n",
      "Epoch 2460: : Loss: T_4427.483 V_5135.830 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4693.975 V_5184.035 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_4410.883 V_5192.347 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5044.421875\n",
      "Epoch 2490: : Loss: T_4163.189 V_5044.422 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_4064.349 V_5077.079 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4971.740234375\n",
      "Epoch 2510: : Loss: T_3938.276 V_4971.740 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_4301.725 V_4991.595 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_4292.780 V_4983.350 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_3789.559 V_4989.313 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_4380.860 V_4999.344 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4970.25341796875\n",
      "Epoch 2560: : Loss: T_4475.521 V_4970.253 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4947.43359375\n",
      "Epoch 2570: : Loss: T_4079.757 V_4947.434 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4944.0986328125\n",
      "Epoch 2580: : Loss: T_3786.391 V_4944.099 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4938.56005859375\n",
      "Epoch 2590: : Loss: T_3757.856 V_4938.560 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4886.21044921875\n",
      "Epoch 2600: : Loss: T_4367.089 V_4886.210 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4750.77001953125\n",
      "Epoch 2610: : Loss: T_4772.724 V_4750.770 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_4397.618 V_4899.895 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4107.665 V_4864.407 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_4757.052 V_4794.115 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4277.761 V_4814.039 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4747.1796875\n",
      "Epoch 2660: : Loss: T_3867.900 V_4747.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4726.74365234375\n",
      "Epoch 2670: : Loss: T_4223.194 V_4726.744 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4072.733 V_4786.595 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3978.420 V_4785.879 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4643.7734375\n",
      "Epoch 2700: : Loss: T_4221.500 V_4643.773 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_4098.546 V_4765.368 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3975.632 V_4792.962 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_4341.420 V_4686.116 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_4366.514 V_4662.706 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_4220.973 V_4710.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4594.50634765625\n",
      "Epoch 2760: : Loss: T_4168.848 V_4594.506 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4554.4140625\n",
      "Epoch 2770: : Loss: T_3646.197 V_4554.414 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_4295.332 V_4596.978 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_3884.379 V_4706.077 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_4387.289 V_4616.840 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_4471.833 V_4629.854 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_4338.374 V_4599.819 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4457.65869140625\n",
      "Epoch 2830: : Loss: T_3616.665 V_4457.659 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4540.491 V_4609.578 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3925.346 V_4646.084 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3768.065 V_4461.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3844.573 V_4522.230 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_4355.161 V_4556.238 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3839.606 V_4515.724 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4444.85986328125\n",
      "Epoch 2900: : Loss: T_4132.626 V_4444.860 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3768.606 V_4467.596 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_4081.172 V_4589.437 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_4024.381 V_4465.388 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_4073.766 V_4460.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_4541.926 V_4503.744 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3879.450 V_4508.029 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3765.412 V_4510.173 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3918.134 V_4448.230 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3798.878 V_4502.734 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_4298.399 V_4455.892 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_4575.013 V_4449.682 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_4805.151 V_4547.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4387.18115234375\n",
      "Epoch 3030: : Loss: T_3884.977 V_4387.181 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4369.833984375\n",
      "Epoch 3040: : Loss: T_4351.633 V_4369.834 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3488.838 V_4369.957 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4347.71875\n",
      "Epoch 3060: : Loss: T_4529.684 V_4347.719 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_4262.071 V_4414.794 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3831.156 V_4359.824 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4332.7568359375\n",
      "Epoch 3090: : Loss: T_3975.610 V_4332.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3723.955 V_4391.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4330.53564453125\n",
      "Epoch 3110: : Loss: T_4426.301 V_4330.536 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4241.27880859375\n",
      "Epoch 3120: : Loss: T_4024.403 V_4241.279 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3981.067 V_4269.216 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_4046.459 V_4255.162 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_4175.380 V_4258.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_4524.825 V_4301.236 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3962.921 V_4267.450 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_4023.406 V_4295.224 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3747.530 V_4343.211 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_4000.723 V_4331.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3891.675 V_4357.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3952.923 V_4253.703 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_4644.984 V_4341.259 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4237.26904296875\n",
      "Epoch 3240: : Loss: T_3772.961 V_4237.269 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4229.365234375\n",
      "Epoch 3250: : Loss: T_4080.792 V_4229.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_4077.458 V_4320.873 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4224.5078125\n",
      "Epoch 3270: : Loss: T_4201.458 V_4224.508 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4159.93115234375\n",
      "Epoch 3280: : Loss: T_3971.299 V_4159.931 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3789.768 V_4264.833 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3943.163 V_4214.659 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_4260.001 V_4227.468 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_4310.444 V_4273.003 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3876.977 V_4236.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4148.01318359375\n",
      "Epoch 3340: : Loss: T_4066.871 V_4148.013 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_4306.853 V_4166.028 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3858.816 V_4214.895 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3699.557 V_4252.180 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_4415.237 V_4274.193 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3179.273 V_4241.511 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3857.602 V_4201.567 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_4171.964 V_4221.912 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_4447.866 V_4185.661 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3898.279 V_4220.938 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_4433.511 V_4178.591 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3513.671 V_4193.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4141.859375\n",
      "Epoch 3460: : Loss: T_3403.723 V_4141.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_4180.889 V_4166.218 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3929.941 V_4163.120 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3945.784 V_4178.994 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_4020.164 V_4177.656 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31773.54296875\n",
      "Epoch 010: : Loss: T_27578.328 V_31773.543 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31694.5\n",
      "Epoch 020: : Loss: T_27550.586 V_31694.500 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31646.39453125\n",
      "Epoch 030: : Loss: T_27543.779 V_31646.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31617.59765625\n",
      "Epoch 040: : Loss: T_27489.418 V_31617.598 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31595.705078125\n",
      "Epoch 050: : Loss: T_27437.049 V_31595.705 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31578.580078125\n",
      "Epoch 060: : Loss: T_27433.533 V_31578.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31555.947265625\n",
      "Epoch 070: : Loss: T_27412.803 V_31555.947 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31507.9609375\n",
      "Epoch 080: : Loss: T_27357.363 V_31507.961 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31482.1015625\n",
      "Epoch 090: : Loss: T_27269.180 V_31482.102 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31442.974609375\n",
      "Epoch 100: : Loss: T_27250.172 V_31442.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31400.884765625\n",
      "Epoch 110: : Loss: T_27183.453 V_31400.885 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31361.5703125\n",
      "Epoch 120: : Loss: T_27121.373 V_31361.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31306.478515625\n",
      "Epoch 130: : Loss: T_27087.967 V_31306.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31248.07421875\n",
      "Epoch 140: : Loss: T_27029.963 V_31248.074 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31214.42578125\n",
      "Epoch 150: : Loss: T_26972.334 V_31214.426 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31130.97265625\n",
      "Epoch 160: : Loss: T_26857.025 V_31130.973 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31091.13671875\n",
      "Epoch 170: : Loss: T_26820.502 V_31091.137 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31044.0\n",
      "Epoch 180: : Loss: T_26758.742 V_31044.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30919.36328125\n",
      "Epoch 190: : Loss: T_26654.928 V_30919.363 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30775.21484375\n",
      "Epoch 200: : Loss: T_26622.543 V_30775.215 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30688.140625\n",
      "Epoch 210: : Loss: T_26569.863 V_30688.141 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30636.67578125\n",
      "Epoch 220: : Loss: T_26435.447 V_30636.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30538.134765625\n",
      "Epoch 230: : Loss: T_26314.494 V_30538.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30427.39453125\n",
      "Epoch 240: : Loss: T_26285.805 V_30427.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30291.619140625\n",
      "Epoch 250: : Loss: T_26190.566 V_30291.619 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30185.22265625\n",
      "Epoch 260: : Loss: T_25987.555 V_30185.223 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30171.419921875\n",
      "Epoch 270: : Loss: T_25953.934 V_30171.420 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30132.689453125\n",
      "Epoch 280: : Loss: T_25836.221 V_30132.689 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29949.267578125\n",
      "Epoch 290: : Loss: T_25782.352 V_29949.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29824.7421875\n",
      "Epoch 300: : Loss: T_25679.830 V_29824.742 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29728.337890625\n",
      "Epoch 310: : Loss: T_25667.662 V_29728.338 | Acc: T_0.000) V_0.000\n",
      "Epoch 320: : Loss: T_25340.191 V_29752.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29665.447265625\n",
      "Epoch 330: : Loss: T_25325.361 V_29665.447 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29347.8125\n",
      "Epoch 340: : Loss: T_25264.562 V_29347.812 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29225.787109375\n",
      "Epoch 350: : Loss: T_25152.717 V_29225.787 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29096.75\n",
      "Epoch 360: : Loss: T_25049.342 V_29096.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 370: : Loss: T_24970.945 V_29175.508 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29096.109375\n",
      "Epoch 380: : Loss: T_24832.871 V_29096.109 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28914.224609375\n",
      "Epoch 390: : Loss: T_24721.873 V_28914.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28789.20703125\n",
      "Epoch 400: : Loss: T_24517.352 V_28789.207 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28583.474609375\n",
      "Epoch 410: : Loss: T_24403.355 V_28583.475 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28496.58984375\n",
      "Epoch 420: : Loss: T_24472.805 V_28496.590 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28226.794921875\n",
      "Epoch 430: : Loss: T_24192.068 V_28226.795 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28169.32421875\n",
      "Epoch 440: : Loss: T_24067.061 V_28169.324 | Acc: T_0.000) V_0.000\n",
      "Epoch 450: : Loss: T_24064.518 V_28267.615 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27868.16015625\n",
      "Epoch 460: : Loss: T_23951.836 V_27868.160 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27725.7890625\n",
      "Epoch 470: : Loss: T_23548.059 V_27725.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 480: : Loss: T_23703.303 V_27793.852 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27720.70703125\n",
      "Epoch 490: : Loss: T_23591.273 V_27720.707 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27414.173828125\n",
      "Epoch 500: : Loss: T_23364.523 V_27414.174 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27257.48828125\n",
      "Epoch 510: : Loss: T_23477.613 V_27257.488 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27084.501953125\n",
      "Epoch 520: : Loss: T_23061.336 V_27084.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_22761.445 V_27093.736 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26833.658203125\n",
      "Epoch 540: : Loss: T_22940.018 V_26833.658 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26802.91796875\n",
      "Epoch 550: : Loss: T_22929.311 V_26802.918 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26662.587890625\n",
      "Epoch 560: : Loss: T_22551.299 V_26662.588 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26246.197265625\n",
      "Epoch 570: : Loss: T_22292.857 V_26246.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_22377.238 V_26307.170 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26211.326171875\n",
      "Epoch 590: : Loss: T_21953.346 V_26211.326 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25788.25\n",
      "Epoch 600: : Loss: T_21710.121 V_25788.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25626.890625\n",
      "Epoch 610: : Loss: T_21945.209 V_25626.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25490.40234375\n",
      "Epoch 620: : Loss: T_21536.611 V_25490.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25223.388671875\n",
      "Epoch 630: : Loss: T_21706.344 V_25223.389 | Acc: T_0.000) V_0.000\n",
      "Epoch 640: : Loss: T_21318.295 V_25292.385 | Acc: T_0.000) V_0.000\n",
      "Epoch 650: : Loss: T_21039.717 V_25376.041 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24986.3515625\n",
      "Epoch 660: : Loss: T_21314.473 V_24986.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24878.365234375\n",
      "Epoch 670: : Loss: T_21013.658 V_24878.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24505.267578125\n",
      "Epoch 680: : Loss: T_21043.926 V_24505.268 | Acc: T_0.000) V_0.000\n",
      "Epoch 690: : Loss: T_20844.572 V_24528.463 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_20525.064 V_24701.957 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24075.46484375\n",
      "Epoch 710: : Loss: T_20229.342 V_24075.465 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23942.791015625\n",
      "Epoch 720: : Loss: T_20169.215 V_23942.791 | Acc: T_0.000) V_0.000\n",
      "Epoch 730: : Loss: T_20322.322 V_23956.271 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23677.65234375\n",
      "Epoch 740: : Loss: T_19746.264 V_23677.652 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23387.978515625\n",
      "Epoch 750: : Loss: T_19612.604 V_23387.979 | Acc: T_0.000) V_0.000\n",
      "Epoch 760: : Loss: T_19639.414 V_23509.152 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_19464.770 V_23433.854 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23122.42578125\n",
      "Epoch 780: : Loss: T_19730.996 V_23122.426 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22728.365234375\n",
      "Epoch 790: : Loss: T_19100.953 V_22728.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 800: : Loss: T_19824.961 V_22981.184 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22696.25390625\n",
      "Epoch 810: : Loss: T_18823.570 V_22696.254 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22571.3046875\n",
      "Epoch 820: : Loss: T_18739.730 V_22571.305 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22237.08984375\n",
      "Epoch 830: : Loss: T_18822.588 V_22237.090 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22170.53515625\n",
      "Epoch 840: : Loss: T_18671.375 V_22170.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22021.7890625\n",
      "Epoch 850: : Loss: T_18339.221 V_22021.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21913.65625\n",
      "Epoch 860: : Loss: T_18341.945 V_21913.656 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21627.904296875\n",
      "Epoch 870: : Loss: T_17898.549 V_21627.904 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21233.0625\n",
      "Epoch 880: : Loss: T_18158.451 V_21233.062 | Acc: T_0.000) V_0.000\n",
      "Epoch 890: : Loss: T_18242.750 V_21390.527 | Acc: T_0.000) V_0.000\n",
      "Epoch 900: : Loss: T_17586.438 V_21311.096 | Acc: T_0.000) V_0.000\n",
      "Epoch 910: : Loss: T_17461.930 V_21388.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21121.177734375\n",
      "Epoch 920: : Loss: T_17078.447 V_21121.178 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20869.623046875\n",
      "Epoch 930: : Loss: T_17421.684 V_20869.623 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20623.69921875\n",
      "Epoch 940: : Loss: T_16981.309 V_20623.699 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20497.73046875\n",
      "Epoch 950: : Loss: T_16992.012 V_20497.730 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19899.59765625\n",
      "Epoch 960: : Loss: T_16732.168 V_19899.598 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16835.463 V_20272.711 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19859.080078125\n",
      "Epoch 980: : Loss: T_16683.344 V_19859.080 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19661.21484375\n",
      "Epoch 990: : Loss: T_16065.409 V_19661.215 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19591.9375\n",
      "Epoch 1000: : Loss: T_16222.860 V_19591.938 | Acc: T_0.000) V_0.000\n",
      "Epoch 1010: : Loss: T_16119.741 V_19634.141 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19539.45703125\n",
      "Epoch 1020: : Loss: T_16778.762 V_19539.457 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19180.8125\n",
      "Epoch 1030: : Loss: T_15986.305 V_19180.812 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19069.96484375\n",
      "Epoch 1040: : Loss: T_15589.342 V_19069.965 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18973.6484375\n",
      "Epoch 1050: : Loss: T_15743.426 V_18973.648 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18776.998046875\n",
      "Epoch 1060: : Loss: T_15415.552 V_18776.998 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18510.806640625\n",
      "Epoch 1070: : Loss: T_14895.562 V_18510.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18437.19140625\n",
      "Epoch 1080: : Loss: T_15316.520 V_18437.191 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18308.81640625\n",
      "Epoch 1090: : Loss: T_14569.365 V_18308.816 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14785.514 V_18486.053 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18305.5625\n",
      "Epoch 1110: : Loss: T_14808.207 V_18305.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17961.357421875\n",
      "Epoch 1120: : Loss: T_15030.619 V_17961.357 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17805.986328125\n",
      "Epoch 1130: : Loss: T_14634.064 V_17805.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14453.562 V_17929.598 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17172.27734375\n",
      "Epoch 1150: : Loss: T_14034.637 V_17172.277 | Acc: T_0.000) V_0.000\n",
      "Epoch 1160: : Loss: T_13961.527 V_17511.701 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_13883.688 V_17437.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_14002.359 V_17291.357 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16963.90234375\n",
      "Epoch 1190: : Loss: T_13826.955 V_16963.902 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16583.033203125\n",
      "Epoch 1200: : Loss: T_13515.851 V_16583.033 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_13168.935 V_16633.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16171.17578125\n",
      "Epoch 1220: : Loss: T_13195.718 V_16171.176 | Acc: T_0.000) V_0.000\n",
      "Epoch 1230: : Loss: T_13400.306 V_16558.910 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16135.4951171875\n",
      "Epoch 1240: : Loss: T_12907.399 V_16135.495 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16022.158203125\n",
      "Epoch 1250: : Loss: T_13124.365 V_16022.158 | Acc: T_0.000) V_0.000\n",
      "Epoch 1260: : Loss: T_12808.485 V_16026.505 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_12738.197 V_16093.766 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15715.71875\n",
      "Epoch 1280: : Loss: T_12393.194 V_15715.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15212.732421875\n",
      "Epoch 1290: : Loss: T_12377.293 V_15212.732 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_12548.742 V_15271.178 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_12436.328 V_15322.320 | Acc: T_0.000) V_0.000\n",
      "Epoch 1320: : Loss: T_12226.237 V_15367.199 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_11905.404 V_15228.129 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14533.1240234375\n",
      "Epoch 1340: : Loss: T_11773.743 V_14533.124 | Acc: T_0.000) V_0.000\n",
      "Epoch 1350: : Loss: T_11867.176 V_14948.261 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_11411.359 V_14781.248 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14202.2578125\n",
      "Epoch 1370: : Loss: T_11443.368 V_14202.258 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_11610.342 V_14315.445 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14100.1298828125\n",
      "Epoch 1390: : Loss: T_10827.568 V_14100.130 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_11164.489 V_14432.660 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13935.4013671875\n",
      "Epoch 1410: : Loss: T_10918.851 V_13935.401 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13752.44140625\n",
      "Epoch 1420: : Loss: T_11282.574 V_13752.441 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13599.3984375\n",
      "Epoch 1430: : Loss: T_11221.051 V_13599.398 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_11013.877 V_13783.810 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13490.9599609375\n",
      "Epoch 1450: : Loss: T_10785.152 V_13490.960 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13305.759765625\n",
      "Epoch 1460: : Loss: T_11107.337 V_13305.760 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13277.46875\n",
      "Epoch 1470: : Loss: T_10754.956 V_13277.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12672.5517578125\n",
      "Epoch 1480: : Loss: T_10225.972 V_12672.552 | Acc: T_0.000) V_0.000\n",
      "Epoch 1490: : Loss: T_10830.903 V_12674.298 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12570.7119140625\n",
      "Epoch 1500: : Loss: T_9538.773 V_12570.712 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_9784.407 V_12675.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12562.0009765625\n",
      "Epoch 1520: : Loss: T_9994.004 V_12562.001 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12164.630859375\n",
      "Epoch 1530: : Loss: T_9582.773 V_12164.631 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_9892.923 V_12269.826 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_9991.399 V_12222.498 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11751.5771484375\n",
      "Epoch 1560: : Loss: T_9690.265 V_11751.577 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9597.574 V_11924.951 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_9441.370 V_12173.861 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11624.6748046875\n",
      "Epoch 1590: : Loss: T_9070.137 V_11624.675 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11510.0615234375\n",
      "Epoch 1600: : Loss: T_9136.935 V_11510.062 | Acc: T_0.000) V_0.000\n",
      "Epoch 1610: : Loss: T_8818.592 V_11531.257 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11385.1669921875\n",
      "Epoch 1620: : Loss: T_9086.140 V_11385.167 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11279.8203125\n",
      "Epoch 1630: : Loss: T_8842.934 V_11279.820 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10762.7041015625\n",
      "Epoch 1640: : Loss: T_8137.523 V_10762.704 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_8225.404 V_10956.491 | Acc: T_0.000) V_0.000\n",
      "Epoch 1660: : Loss: T_8264.422 V_10778.025 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10584.345703125\n",
      "Epoch 1670: : Loss: T_8178.078 V_10584.346 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10538.58984375\n",
      "Epoch 1680: : Loss: T_8777.871 V_10538.590 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_7954.993 V_10643.542 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10329.9423828125\n",
      "Epoch 1700: : Loss: T_8215.849 V_10329.942 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10299.576171875\n",
      "Epoch 1710: : Loss: T_7990.988 V_10299.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10115.5126953125\n",
      "Epoch 1720: : Loss: T_8221.780 V_10115.513 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_7716.655 V_10276.006 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9811.3046875\n",
      "Epoch 1740: : Loss: T_6923.085 V_9811.305 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_7495.048 V_9819.440 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_7260.500 V_9879.064 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9584.2822265625\n",
      "Epoch 1770: : Loss: T_7394.464 V_9584.282 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9490.943359375\n",
      "Epoch 1780: : Loss: T_7592.005 V_9490.943 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9472.2978515625\n",
      "Epoch 1790: : Loss: T_7296.914 V_9472.298 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9400.5654296875\n",
      "Epoch 1800: : Loss: T_7643.151 V_9400.565 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9128.0068359375\n",
      "Epoch 1810: : Loss: T_7086.835 V_9128.007 | Acc: T_0.000) V_0.000\n",
      "Epoch 1820: : Loss: T_6959.711 V_9209.990 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_7094.091 V_9280.421 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9106.9892578125\n",
      "Epoch 1840: : Loss: T_7373.114 V_9106.989 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8899.23046875\n",
      "Epoch 1850: : Loss: T_6406.550 V_8899.230 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6751.366 V_9195.540 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8664.2138671875\n",
      "Epoch 1870: : Loss: T_6715.283 V_8664.214 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_6690.084 V_8722.343 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8447.66796875\n",
      "Epoch 1890: : Loss: T_6902.159 V_8447.668 | Acc: T_0.000) V_0.000\n",
      "Epoch 1900: : Loss: T_6481.677 V_8583.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_7039.100 V_8595.672 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6454.968 V_8533.165 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8250.3134765625\n",
      "Epoch 1930: : Loss: T_6278.649 V_8250.313 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8224.2900390625\n",
      "Epoch 1940: : Loss: T_6042.218 V_8224.290 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8061.46630859375\n",
      "Epoch 1950: : Loss: T_6032.635 V_8061.466 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8005.572265625\n",
      "Epoch 1960: : Loss: T_6233.959 V_8005.572 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_5815.517 V_8064.404 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_5689.260 V_8014.023 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_5948.404 V_8057.567 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7621.7666015625\n",
      "Epoch 2000: : Loss: T_5865.238 V_7621.767 | Acc: T_0.000) V_0.000\n",
      "Epoch 2010: : Loss: T_5873.753 V_7851.828 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7511.66357421875\n",
      "Epoch 2020: : Loss: T_5844.203 V_7511.664 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7385.0341796875\n",
      "Epoch 2030: : Loss: T_6024.471 V_7385.034 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7314.59423828125\n",
      "Epoch 2040: : Loss: T_4893.929 V_7314.594 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5676.627 V_7321.682 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7173.72998046875\n",
      "Epoch 2060: : Loss: T_5376.309 V_7173.730 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7171.62255859375\n",
      "Epoch 2070: : Loss: T_6070.825 V_7171.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 2080: : Loss: T_5762.690 V_7367.179 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7132.521484375\n",
      "Epoch 2090: : Loss: T_6286.901 V_7132.521 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7021.7919921875\n",
      "Epoch 2100: : Loss: T_5179.297 V_7021.792 | Acc: T_0.000) V_0.000\n",
      "Epoch 2110: : Loss: T_4993.796 V_7023.342 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6636.60986328125\n",
      "Epoch 2120: : Loss: T_5517.200 V_6636.610 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_5521.352 V_6911.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_5204.444 V_6920.134 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_4880.565 V_6806.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_5341.959 V_6650.411 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6555.10400390625\n",
      "Epoch 2170: : Loss: T_4923.892 V_6555.104 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6514.61279296875\n",
      "Epoch 2180: : Loss: T_5124.593 V_6514.613 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_4811.872 V_6526.480 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6350.53466796875\n",
      "Epoch 2200: : Loss: T_5261.702 V_6350.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6185.44775390625\n",
      "Epoch 2210: : Loss: T_5058.353 V_6185.448 | Acc: T_0.000) V_0.000\n",
      "Epoch 2220: : Loss: T_4994.031 V_6251.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_5412.570 V_6192.434 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6063.65625\n",
      "Epoch 2240: : Loss: T_4924.869 V_6063.656 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4598.146 V_6204.102 | Acc: T_0.000) V_0.000\n",
      "Epoch 2260: : Loss: T_4695.050 V_6260.932 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6009.82470703125\n",
      "Epoch 2270: : Loss: T_5260.042 V_6009.825 | Acc: T_0.000) V_0.000\n",
      "Epoch 2280: : Loss: T_4483.343 V_6047.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_4564.665 V_6022.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5785.62451171875\n",
      "Epoch 2300: : Loss: T_4937.714 V_5785.625 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5701.53173828125\n",
      "Epoch 2310: : Loss: T_5180.589 V_5701.532 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_5017.039 V_5784.318 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_4053.196 V_5962.009 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5667.693359375\n",
      "Epoch 2340: : Loss: T_4704.736 V_5667.693 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5665.02783203125\n",
      "Epoch 2350: : Loss: T_5127.850 V_5665.028 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_5042.362 V_5742.375 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5544.880859375\n",
      "Epoch 2370: : Loss: T_4252.498 V_5544.881 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4320.215 V_5557.509 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4298.965 V_5562.670 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5351.64453125\n",
      "Epoch 2400: : Loss: T_4531.391 V_5351.645 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4675.703 V_5573.479 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_4089.557 V_5663.139 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_3918.082 V_5544.806 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4276.769 V_5416.318 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5347.39697265625\n",
      "Epoch 2450: : Loss: T_4337.577 V_5347.397 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_5183.935 V_5381.783 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5294.3076171875\n",
      "Epoch 2470: : Loss: T_4072.385 V_5294.308 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5152.96923828125\n",
      "Epoch 2480: : Loss: T_4259.481 V_5152.969 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_4473.172 V_5190.180 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_4404.980 V_5250.333 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4779.986 V_5236.705 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_4096.556 V_5184.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5130.03369140625\n",
      "Epoch 2530: : Loss: T_4747.770 V_5130.034 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5121.35400390625\n",
      "Epoch 2540: : Loss: T_4269.724 V_5121.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5052.08984375\n",
      "Epoch 2550: : Loss: T_4207.497 V_5052.090 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_4172.622 V_5084.443 | Acc: T_0.000) V_0.000\n",
      "Epoch 2570: : Loss: T_3710.290 V_5082.125 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5008.40576171875\n",
      "Epoch 2580: : Loss: T_4098.654 V_5008.406 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_4701.242 V_5016.877 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4922.783203125\n",
      "Epoch 2600: : Loss: T_4892.578 V_4922.783 | Acc: T_0.000) V_0.000\n",
      "Epoch 2610: : Loss: T_4224.427 V_4962.299 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_4354.802 V_5003.759 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4825.4951171875\n",
      "Epoch 2630: : Loss: T_3888.058 V_4825.495 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_4099.949 V_4833.650 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4137.688 V_4855.450 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4692.140625\n",
      "Epoch 2660: : Loss: T_4043.554 V_4692.141 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4668.73095703125\n",
      "Epoch 2670: : Loss: T_4111.930 V_4668.731 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4660.695 V_4705.991 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3884.012 V_4802.271 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3449.823 V_4675.578 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4600.8271484375\n",
      "Epoch 2710: : Loss: T_4148.637 V_4600.827 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3944.210 V_4639.416 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3711.609 V_4620.881 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3609.832 V_4699.679 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3940.214 V_4651.448 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4556.3818359375\n",
      "Epoch 2760: : Loss: T_4279.893 V_4556.382 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_4150.637 V_4596.259 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_4378.263 V_4582.989 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4538.56298828125\n",
      "Epoch 2790: : Loss: T_3846.566 V_4538.563 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4520.576171875\n",
      "Epoch 2800: : Loss: T_4273.225 V_4520.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4441.53369140625\n",
      "Epoch 2810: : Loss: T_3915.122 V_4441.534 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_4035.888 V_4521.662 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4103.261 V_4497.661 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4264.689 V_4488.217 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_3750.021 V_4549.858 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_3991.273 V_4574.881 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4391.39794921875\n",
      "Epoch 2870: : Loss: T_4255.094 V_4391.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4315.65234375\n",
      "Epoch 2880: : Loss: T_3847.929 V_4315.652 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_4089.866 V_4522.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_4191.737 V_4423.256 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3654.092 V_4372.870 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_4185.986 V_4344.813 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4270.81689453125\n",
      "Epoch 2930: : Loss: T_3465.422 V_4270.817 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3867.379 V_4316.177 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_4225.776 V_4367.661 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3854.749 V_4378.334 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3718.373 V_4355.529 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3925.571 V_4310.362 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_4130.551 V_4392.365 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_4177.148 V_4405.833 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3890.265 V_4384.173 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_4048.414 V_4453.474 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4252.1875\n",
      "Epoch 3030: : Loss: T_4034.358 V_4252.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4226.0908203125\n",
      "Epoch 3040: : Loss: T_3864.148 V_4226.091 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_4131.491 V_4276.841 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_4030.367 V_4284.796 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_4517.734 V_4283.942 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3737.824 V_4271.771 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3607.337 V_4267.420 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3921.566 V_4348.284 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4195.95361328125\n",
      "Epoch 3110: : Loss: T_4527.128 V_4195.954 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4136.0439453125\n",
      "Epoch 3120: : Loss: T_4332.335 V_4136.044 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4110.357421875\n",
      "Epoch 3130: : Loss: T_3974.666 V_4110.357 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3733.621 V_4175.343 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3878.398 V_4177.502 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_4234.328 V_4156.318 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_4278.852 V_4225.801 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_3658.173 V_4234.969 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3806.669 V_4178.220 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_4074.395 V_4142.909 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4072.4365234375\n",
      "Epoch 3210: : Loss: T_3640.792 V_4072.437 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3821.860 V_4163.777 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3622.862 V_4177.060 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_4103.695 V_4144.051 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_4196.677 V_4246.388 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_4298.273 V_4271.190 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4069.355224609375\n",
      "Epoch 3270: : Loss: T_3872.479 V_4069.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3752.160 V_4137.984 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3840.655 V_4174.507 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3858.058 V_4187.432 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3990.516 V_4190.639 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3925.749 V_4136.463 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_4508.167 V_4191.962 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3785.577 V_4221.504 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_4164.250 V_4186.647 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_4439.992 V_4137.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3257.590 V_4167.723 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3355.787 V_4122.823 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_4581.654 V_4158.552 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3639.656 V_4163.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_4025.163 V_4138.271 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3499.008 V_4131.936 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4044.16015625\n",
      "Epoch 3430: : Loss: T_4216.433 V_4044.160 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4023.98583984375\n",
      "Epoch 3440: : Loss: T_3566.731 V_4023.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_4361.838 V_4151.868 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_4204.963 V_4170.514 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_4307.737 V_4189.064 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3352.022 V_4134.761 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3766.310 V_4108.743 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3948.847 V_4034.530 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31890.236328125\n",
      "Epoch 010: : Loss: T_27590.395 V_31890.236 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31881.240234375\n",
      "Epoch 020: : Loss: T_27555.221 V_31881.240 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31846.974609375\n",
      "Epoch 030: : Loss: T_27546.373 V_31846.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31801.79296875\n",
      "Epoch 040: : Loss: T_27508.043 V_31801.793 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31752.376953125\n",
      "Epoch 050: : Loss: T_27490.008 V_31752.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31702.078125\n",
      "Epoch 060: : Loss: T_27468.273 V_31702.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31646.93359375\n",
      "Epoch 070: : Loss: T_27383.311 V_31646.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31596.1015625\n",
      "Epoch 080: : Loss: T_27359.539 V_31596.102 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31543.806640625\n",
      "Epoch 090: : Loss: T_27307.729 V_31543.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31480.806640625\n",
      "Epoch 100: : Loss: T_27248.367 V_31480.807 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31398.341796875\n",
      "Epoch 110: : Loss: T_27161.576 V_31398.342 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31322.873046875\n",
      "Epoch 120: : Loss: T_27090.148 V_31322.873 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31239.662109375\n",
      "Epoch 130: : Loss: T_27048.605 V_31239.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31172.904296875\n",
      "Epoch 140: : Loss: T_26982.656 V_31172.904 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31114.482421875\n",
      "Epoch 150: : Loss: T_26921.635 V_31114.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31051.90234375\n",
      "Epoch 160: : Loss: T_26823.127 V_31051.902 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30966.9375\n",
      "Epoch 170: : Loss: T_26776.275 V_30966.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30899.404296875\n",
      "Epoch 180: : Loss: T_26697.871 V_30899.404 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30856.455078125\n",
      "Epoch 190: : Loss: T_26627.145 V_30856.455 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30752.3515625\n",
      "Epoch 200: : Loss: T_26557.760 V_30752.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30640.837890625\n",
      "Epoch 210: : Loss: T_26524.041 V_30640.838 | Acc: T_0.000) V_0.000\n",
      "Epoch 220: : Loss: T_26358.109 V_30642.201 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30558.75390625\n",
      "Epoch 230: : Loss: T_26285.129 V_30558.754 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30365.521484375\n",
      "Epoch 240: : Loss: T_26192.723 V_30365.521 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30319.759765625\n",
      "Epoch 250: : Loss: T_26110.137 V_30319.760 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30223.1875\n",
      "Epoch 260: : Loss: T_26075.695 V_30223.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30042.10546875\n",
      "Epoch 270: : Loss: T_25841.025 V_30042.105 | Acc: T_0.000) V_0.000\n",
      "Epoch 280: : Loss: T_25751.488 V_30075.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29890.13671875\n",
      "Epoch 290: : Loss: T_25645.055 V_29890.137 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29781.087890625\n",
      "Epoch 300: : Loss: T_25558.539 V_29781.088 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29655.654296875\n",
      "Epoch 310: : Loss: T_25565.363 V_29655.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29596.1015625\n",
      "Epoch 320: : Loss: T_25468.592 V_29596.102 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29341.560546875\n",
      "Epoch 330: : Loss: T_25389.949 V_29341.561 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29225.78125\n",
      "Epoch 340: : Loss: T_25148.014 V_29225.781 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29124.09765625\n",
      "Epoch 350: : Loss: T_25019.125 V_29124.098 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28991.771484375\n",
      "Epoch 360: : Loss: T_24933.836 V_28991.771 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28852.015625\n",
      "Epoch 370: : Loss: T_24794.549 V_28852.016 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28822.8203125\n",
      "Epoch 380: : Loss: T_24620.664 V_28822.820 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28716.228515625\n",
      "Epoch 390: : Loss: T_24559.279 V_28716.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28510.318359375\n",
      "Epoch 400: : Loss: T_24335.910 V_28510.318 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28249.525390625\n",
      "Epoch 410: : Loss: T_24414.836 V_28249.525 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28095.412109375\n",
      "Epoch 420: : Loss: T_24155.645 V_28095.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28016.466796875\n",
      "Epoch 430: : Loss: T_23967.490 V_28016.467 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27934.353515625\n",
      "Epoch 440: : Loss: T_23976.668 V_27934.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27872.39453125\n",
      "Epoch 450: : Loss: T_23757.221 V_27872.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27696.001953125\n",
      "Epoch 460: : Loss: T_23748.627 V_27696.002 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27442.548828125\n",
      "Epoch 470: : Loss: T_23816.900 V_27442.549 | Acc: T_0.000) V_0.000\n",
      "Epoch 480: : Loss: T_23345.627 V_27540.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27317.251953125\n",
      "Epoch 490: : Loss: T_23174.086 V_27317.252 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26928.3671875\n",
      "Epoch 500: : Loss: T_23081.197 V_26928.367 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26719.61328125\n",
      "Epoch 510: : Loss: T_23222.133 V_26719.613 | Acc: T_0.000) V_0.000\n",
      "Epoch 520: : Loss: T_23107.686 V_27009.258 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_22806.834 V_26945.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26210.41796875\n",
      "Epoch 540: : Loss: T_23088.654 V_26210.418 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26137.400390625\n",
      "Epoch 550: : Loss: T_22666.266 V_26137.400 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_22594.561 V_26319.938 | Acc: T_0.000) V_0.000\n",
      "Epoch 570: : Loss: T_22770.078 V_26174.248 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_22151.045 V_26282.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25927.421875\n",
      "Epoch 590: : Loss: T_21883.266 V_25927.422 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25448.728515625\n",
      "Epoch 600: : Loss: T_21886.732 V_25448.729 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25235.52734375\n",
      "Epoch 610: : Loss: T_21736.086 V_25235.527 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_21405.123 V_25424.391 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_21544.959 V_25305.879 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25171.986328125\n",
      "Epoch 640: : Loss: T_21189.328 V_25171.986 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24556.4609375\n",
      "Epoch 650: : Loss: T_20833.475 V_24556.461 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_20925.043 V_24787.289 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24530.759765625\n",
      "Epoch 670: : Loss: T_20855.562 V_24530.760 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24430.685546875\n",
      "Epoch 680: : Loss: T_20517.100 V_24430.686 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24136.40234375\n",
      "Epoch 690: : Loss: T_20251.234 V_24136.402 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_20259.041 V_24151.693 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23800.62890625\n",
      "Epoch 710: : Loss: T_20230.975 V_23800.629 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_20318.895 V_23833.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23583.68359375\n",
      "Epoch 730: : Loss: T_19911.369 V_23583.684 | Acc: T_0.000) V_0.000\n",
      "Epoch 740: : Loss: T_20107.219 V_23698.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23192.71484375\n",
      "Epoch 750: : Loss: T_19825.803 V_23192.715 | Acc: T_0.000) V_0.000\n",
      "Epoch 760: : Loss: T_19329.072 V_23247.781 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_19570.549 V_23194.410 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23089.416015625\n",
      "Epoch 780: : Loss: T_19744.230 V_23089.416 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22552.19921875\n",
      "Epoch 790: : Loss: T_19338.615 V_22552.199 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22496.189453125\n",
      "Epoch 800: : Loss: T_18723.201 V_22496.189 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22225.333984375\n",
      "Epoch 810: : Loss: T_18626.586 V_22225.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22217.546875\n",
      "Epoch 820: : Loss: T_18767.725 V_22217.547 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22054.64453125\n",
      "Epoch 830: : Loss: T_18598.461 V_22054.645 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21725.5625\n",
      "Epoch 840: : Loss: T_18042.395 V_21725.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21545.3125\n",
      "Epoch 850: : Loss: T_18294.180 V_21545.312 | Acc: T_0.000) V_0.000\n",
      "Epoch 860: : Loss: T_18175.900 V_21584.879 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21367.78125\n",
      "Epoch 870: : Loss: T_18321.875 V_21367.781 | Acc: T_0.000) V_0.000\n",
      "Epoch 880: : Loss: T_17793.600 V_21515.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21318.990234375\n",
      "Epoch 890: : Loss: T_18279.562 V_21318.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21232.919921875\n",
      "Epoch 900: : Loss: T_17513.809 V_21232.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20436.921875\n",
      "Epoch 910: : Loss: T_17540.125 V_20436.922 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_17617.277 V_20467.002 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20390.763671875\n",
      "Epoch 930: : Loss: T_17355.461 V_20390.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 940: : Loss: T_17197.736 V_20546.295 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_17110.289 V_20403.498 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19901.716796875\n",
      "Epoch 960: : Loss: T_17239.781 V_19901.717 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16833.850 V_20180.834 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19593.591796875\n",
      "Epoch 980: : Loss: T_16443.975 V_19593.592 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19590.962890625\n",
      "Epoch 990: : Loss: T_16558.805 V_19590.963 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19113.990234375\n",
      "Epoch 1000: : Loss: T_16279.502 V_19113.990 | Acc: T_0.000) V_0.000\n",
      "Epoch 1010: : Loss: T_16115.044 V_19177.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 1020: : Loss: T_16133.589 V_19253.555 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18533.615234375\n",
      "Epoch 1030: : Loss: T_16057.293 V_18533.615 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_15372.126 V_18842.203 | Acc: T_0.000) V_0.000\n",
      "Epoch 1050: : Loss: T_15520.224 V_18781.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_15284.803 V_18870.436 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18128.861328125\n",
      "Epoch 1070: : Loss: T_14861.292 V_18128.861 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_15193.745 V_18166.271 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17940.828125\n",
      "Epoch 1090: : Loss: T_15129.967 V_17940.828 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14292.824 V_18206.387 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_14842.342 V_17985.527 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17783.478515625\n",
      "Epoch 1120: : Loss: T_14227.774 V_17783.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17678.373046875\n",
      "Epoch 1130: : Loss: T_14343.074 V_17678.373 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14657.670 V_17793.607 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16387.42578125\n",
      "Epoch 1150: : Loss: T_14416.678 V_16387.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 1160: : Loss: T_14066.353 V_17265.805 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_13430.774 V_17494.549 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_13900.401 V_16735.674 | Acc: T_0.000) V_0.000\n",
      "Epoch 1190: : Loss: T_13338.261 V_16551.895 | Acc: T_0.000) V_0.000\n",
      "Epoch 1200: : Loss: T_13586.010 V_16401.076 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16381.6728515625\n",
      "Epoch 1210: : Loss: T_13329.863 V_16381.673 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_13308.268 V_16498.041 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16163.4228515625\n",
      "Epoch 1230: : Loss: T_13050.437 V_16163.423 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16084.1904296875\n",
      "Epoch 1240: : Loss: T_13423.191 V_16084.190 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15754.3486328125\n",
      "Epoch 1250: : Loss: T_12828.942 V_15754.349 | Acc: T_0.000) V_0.000\n",
      "Epoch 1260: : Loss: T_13121.870 V_15920.368 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15615.572265625\n",
      "Epoch 1270: : Loss: T_12643.296 V_15615.572 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15607.7744140625\n",
      "Epoch 1280: : Loss: T_12464.718 V_15607.774 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15279.0634765625\n",
      "Epoch 1290: : Loss: T_12394.459 V_15279.063 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14977.2099609375\n",
      "Epoch 1300: : Loss: T_12483.348 V_14977.210 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_12114.646 V_15294.024 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14839.5771484375\n",
      "Epoch 1320: : Loss: T_11646.476 V_14839.577 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_12096.076 V_14890.480 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14809.6513671875\n",
      "Epoch 1340: : Loss: T_11454.689 V_14809.651 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14407.9287109375\n",
      "Epoch 1350: : Loss: T_11308.730 V_14407.929 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_11735.789 V_14500.641 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11882.973 V_14459.340 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13813.888671875\n",
      "Epoch 1380: : Loss: T_11195.370 V_13813.889 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_11581.426 V_14178.298 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13644.1787109375\n",
      "Epoch 1400: : Loss: T_10969.785 V_13644.179 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_10895.502 V_13745.125 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_11300.807 V_13816.210 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13471.2197265625\n",
      "Epoch 1430: : Loss: T_10965.890 V_13471.220 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_10808.072 V_13594.889 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12923.67578125\n",
      "Epoch 1450: : Loss: T_10405.876 V_12923.676 | Acc: T_0.000) V_0.000\n",
      "Epoch 1460: : Loss: T_10521.377 V_13452.310 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_9967.739 V_13017.157 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12830.6923828125\n",
      "Epoch 1480: : Loss: T_10479.210 V_12830.692 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12724.03515625\n",
      "Epoch 1490: : Loss: T_11010.374 V_12724.035 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12186.65234375\n",
      "Epoch 1500: : Loss: T_9483.807 V_12186.652 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_10529.344 V_12472.161 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_10003.254 V_12415.872 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11861.25390625\n",
      "Epoch 1530: : Loss: T_9706.698 V_11861.254 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_9814.803 V_12168.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_9427.646 V_12142.726 | Acc: T_0.000) V_0.000\n",
      "Epoch 1560: : Loss: T_9675.203 V_12004.604 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9921.626 V_11878.906 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11629.205078125\n",
      "Epoch 1580: : Loss: T_8827.175 V_11629.205 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11525.3984375\n",
      "Epoch 1590: : Loss: T_8800.109 V_11525.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11412.6435546875\n",
      "Epoch 1600: : Loss: T_9086.702 V_11412.644 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11042.798828125\n",
      "Epoch 1610: : Loss: T_8880.410 V_11042.799 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_8673.679 V_11248.872 | Acc: T_0.000) V_0.000\n",
      "Epoch 1630: : Loss: T_8579.433 V_11157.530 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10872.3603515625\n",
      "Epoch 1640: : Loss: T_8232.143 V_10872.360 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_8263.855 V_10985.787 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10533.435546875\n",
      "Epoch 1660: : Loss: T_8391.459 V_10533.436 | Acc: T_0.000) V_0.000\n",
      "Epoch 1670: : Loss: T_8159.188 V_10780.894 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_8301.109 V_10560.171 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_8366.390 V_10726.446 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10425.265625\n",
      "Epoch 1700: : Loss: T_8100.553 V_10425.266 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10087.1435546875\n",
      "Epoch 1710: : Loss: T_7856.387 V_10087.144 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10043.5390625\n",
      "Epoch 1720: : Loss: T_7528.787 V_10043.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9956.6728515625\n",
      "Epoch 1730: : Loss: T_7832.430 V_9956.673 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9866.5107421875\n",
      "Epoch 1740: : Loss: T_7524.306 V_9866.511 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9604.400390625\n",
      "Epoch 1750: : Loss: T_7148.386 V_9604.400 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_7564.289 V_9675.738 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9564.6025390625\n",
      "Epoch 1770: : Loss: T_7930.815 V_9564.603 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9497.7060546875\n",
      "Epoch 1780: : Loss: T_7308.174 V_9497.706 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9321.126953125\n",
      "Epoch 1790: : Loss: T_7111.810 V_9321.127 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9292.970703125\n",
      "Epoch 1800: : Loss: T_7301.495 V_9292.971 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_7372.257 V_9347.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9180.3759765625\n",
      "Epoch 1820: : Loss: T_7308.405 V_9180.376 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8899.2138671875\n",
      "Epoch 1830: : Loss: T_6677.192 V_8899.214 | Acc: T_0.000) V_0.000\n",
      "Epoch 1840: : Loss: T_7255.286 V_8957.664 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6877.220 V_8919.946 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8843.8515625\n",
      "Epoch 1860: : Loss: T_7235.729 V_8843.852 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8434.8359375\n",
      "Epoch 1870: : Loss: T_6733.630 V_8434.836 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_6395.235 V_8535.944 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6311.566 V_8446.152 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8381.919921875\n",
      "Epoch 1900: : Loss: T_6652.419 V_8381.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8353.75390625\n",
      "Epoch 1910: : Loss: T_5952.451 V_8353.754 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8094.8642578125\n",
      "Epoch 1920: : Loss: T_6078.595 V_8094.864 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8072.15771484375\n",
      "Epoch 1930: : Loss: T_6168.714 V_8072.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7866.45263671875\n",
      "Epoch 1940: : Loss: T_6133.005 V_7866.453 | Acc: T_0.000) V_0.000\n",
      "Epoch 1950: : Loss: T_6470.692 V_7870.763 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7738.04248046875\n",
      "Epoch 1960: : Loss: T_6208.743 V_7738.042 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_6119.555 V_7767.419 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_6533.729 V_7780.520 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_6123.468 V_7754.868 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7372.10107421875\n",
      "Epoch 2000: : Loss: T_6272.645 V_7372.101 | Acc: T_0.000) V_0.000\n",
      "Epoch 2010: : Loss: T_5780.769 V_7717.211 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_5487.897 V_7437.056 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7228.0263671875\n",
      "Epoch 2030: : Loss: T_5704.138 V_7228.026 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_5508.656 V_7272.671 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5891.535 V_7273.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5575.802 V_7305.213 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_5380.289 V_7304.338 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6827.45263671875\n",
      "Epoch 2080: : Loss: T_5171.596 V_6827.453 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5545.600 V_6923.825 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_5982.085 V_6872.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6728.63525390625\n",
      "Epoch 2110: : Loss: T_5512.152 V_6728.635 | Acc: T_0.000) V_0.000\n",
      "Epoch 2120: : Loss: T_5804.630 V_6814.885 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6565.8330078125\n",
      "Epoch 2130: : Loss: T_5129.668 V_6565.833 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_5394.421 V_6566.001 | Acc: T_0.000) V_0.000\n",
      "Epoch 2150: : Loss: T_5796.715 V_6641.035 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6366.380859375\n",
      "Epoch 2160: : Loss: T_5418.740 V_6366.381 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_5158.353 V_6418.417 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6222.63720703125\n",
      "Epoch 2180: : Loss: T_5299.351 V_6222.637 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_5776.224 V_6392.743 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6206.73486328125\n",
      "Epoch 2200: : Loss: T_5473.918 V_6206.735 | Acc: T_0.000) V_0.000\n",
      "Epoch 2210: : Loss: T_4616.099 V_6221.336 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6146.57080078125\n",
      "Epoch 2220: : Loss: T_4994.093 V_6146.571 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6050.220703125\n",
      "Epoch 2230: : Loss: T_4834.920 V_6050.221 | Acc: T_0.000) V_0.000\n",
      "Epoch 2240: : Loss: T_5171.462 V_6087.017 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6014.5693359375\n",
      "Epoch 2250: : Loss: T_5332.252 V_6014.569 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5883.16650390625\n",
      "Epoch 2260: : Loss: T_5546.804 V_5883.167 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_4555.235 V_5970.982 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5863.0859375\n",
      "Epoch 2280: : Loss: T_5200.838 V_5863.086 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5723.56005859375\n",
      "Epoch 2290: : Loss: T_4643.197 V_5723.560 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5686.61865234375\n",
      "Epoch 2300: : Loss: T_5184.034 V_5686.619 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_5479.952 V_5708.473 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_4890.263 V_5688.623 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5582.26123046875\n",
      "Epoch 2330: : Loss: T_4921.677 V_5582.261 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4483.734 V_5782.543 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5496.35595703125\n",
      "Epoch 2350: : Loss: T_4299.036 V_5496.356 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4247.779 V_5538.531 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_3930.751 V_5586.877 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5483.505859375\n",
      "Epoch 2380: : Loss: T_4596.859 V_5483.506 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4225.552 V_5503.958 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5382.37158203125\n",
      "Epoch 2400: : Loss: T_4209.150 V_5382.372 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5214.5361328125\n",
      "Epoch 2410: : Loss: T_4396.187 V_5214.536 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_4529.671 V_5220.300 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_5197.528 V_5282.675 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4187.366 V_5258.688 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_3844.276 V_5235.485 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5105.22119140625\n",
      "Epoch 2460: : Loss: T_4783.544 V_5105.221 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4525.045 V_5223.939 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_4391.293 V_5115.272 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5054.47998046875\n",
      "Epoch 2490: : Loss: T_4911.301 V_5054.480 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5022.63232421875\n",
      "Epoch 2500: : Loss: T_4237.219 V_5022.632 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4857.76025390625\n",
      "Epoch 2510: : Loss: T_3957.857 V_4857.760 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_4277.527 V_5040.167 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_4164.122 V_4982.082 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_4455.527 V_4994.498 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4838.552734375\n",
      "Epoch 2550: : Loss: T_4587.924 V_4838.553 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_4611.454 V_4861.681 | Acc: T_0.000) V_0.000\n",
      "Epoch 2570: : Loss: T_4280.302 V_5027.423 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4747.64990234375\n",
      "Epoch 2580: : Loss: T_4551.230 V_4747.650 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4726.41748046875\n",
      "Epoch 2590: : Loss: T_4500.372 V_4726.417 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_4111.574 V_4749.586 | Acc: T_0.000) V_0.000\n",
      "Epoch 2610: : Loss: T_4252.900 V_4778.591 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4628.78857421875\n",
      "Epoch 2620: : Loss: T_4145.137 V_4628.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4274.204 V_4674.598 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_4625.159 V_4752.807 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_3893.171 V_4664.396 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4548.82177734375\n",
      "Epoch 2660: : Loss: T_3880.185 V_4548.822 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_4122.668 V_4722.143 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4376.053 V_4642.021 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_4335.813 V_4628.695 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4546.32666015625\n",
      "Epoch 2700: : Loss: T_4599.503 V_4546.327 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_3888.982 V_4589.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_4185.267 V_4630.119 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_4114.872 V_4647.234 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_4309.360 V_4595.684 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_3722.519 V_4554.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4523.5712890625\n",
      "Epoch 2760: : Loss: T_4569.009 V_4523.571 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4398.04052734375\n",
      "Epoch 2770: : Loss: T_3626.017 V_4398.041 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_4304.737 V_4495.863 | Acc: T_0.000) V_0.000\n",
      "Epoch 2790: : Loss: T_4964.256 V_4520.577 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_3631.296 V_4534.851 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4373.11474609375\n",
      "Epoch 2810: : Loss: T_4073.762 V_4373.115 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3851.154 V_4434.447 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4469.743 V_4525.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4127.637 V_4410.810 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4352.28515625\n",
      "Epoch 2850: : Loss: T_3740.133 V_4352.285 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_4096.529 V_4359.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_3958.418 V_4378.341 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3872.310 V_4425.461 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4316.31103515625\n",
      "Epoch 2890: : Loss: T_4280.909 V_4316.311 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3793.129 V_4358.274 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3485.600 V_4362.059 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4225.25927734375\n",
      "Epoch 2920: : Loss: T_4118.698 V_4225.259 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4211.09228515625\n",
      "Epoch 2930: : Loss: T_4223.719 V_4211.092 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3985.697 V_4417.484 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_4519.447 V_4329.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3709.327 V_4317.840 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_4522.281 V_4220.954 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4158.419921875\n",
      "Epoch 2980: : Loss: T_3875.710 V_4158.420 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3880.815 V_4258.338 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3928.949 V_4190.908 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_3427.120 V_4253.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3945.627 V_4162.792 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_4024.535 V_4192.373 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3794.699 V_4161.947 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_4141.075 V_4177.088 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_4086.689 V_4231.166 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3853.115 V_4190.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4066.2197265625\n",
      "Epoch 3080: : Loss: T_4312.301 V_4066.220 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_4169.160 V_4111.248 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3993.860 V_4173.998 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_4299.757 V_4171.733 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_4534.067 V_4135.535 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3527.953 V_4153.902 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_4119.993 V_4161.803 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3623.696 V_4160.771 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_4198.134 V_4135.542 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_4037.499 V_4072.653 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_4225.790 V_4126.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3544.539 V_4160.648 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_4101.131 V_4197.471 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4031.7138671875\n",
      "Epoch 3210: : Loss: T_4098.473 V_4031.714 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3931.881 V_4123.560 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_4069.288 V_4092.951 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3847.425 V_4081.719 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3692.148 V_4042.960 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3850.076 V_4044.283 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_4412.713 V_4111.384 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3532.752 V_4070.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3904.559 V_4099.193 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3872.064 V_4059.629 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3776.640 V_4062.635 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3969.0888671875\n",
      "Epoch 3320: : Loss: T_3789.987 V_3969.089 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_4125.988 V_4074.415 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_4163.962 V_4023.739 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3952.471923828125\n",
      "Epoch 3350: : Loss: T_4238.158 V_3952.472 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3622.208 V_4098.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3969.204 V_4053.412 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_4031.091 V_4103.612 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3780.347 V_4062.920 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_4163.932 V_4033.947 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3552.031 V_4082.842 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3885.1376953125\n",
      "Epoch 3420: : Loss: T_3872.259 V_3885.138 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_4225.026 V_3969.856 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_4124.302 V_4070.914 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3688.488 V_4030.938 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_4535.060 V_3983.970 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3769.802 V_4019.446 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3568.818 V_3964.496 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3872.429931640625\n",
      "Epoch 3490: : Loss: T_4095.071 V_3872.430 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3540.313 V_3994.155 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31918.166015625\n",
      "Epoch 010: : Loss: T_27685.467 V_31918.166 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31898.828125\n",
      "Epoch 020: : Loss: T_27616.455 V_31898.828 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31880.64453125\n",
      "Epoch 030: : Loss: T_27601.990 V_31880.645 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31860.35546875\n",
      "Epoch 040: : Loss: T_27579.406 V_31860.355 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31827.486328125\n",
      "Epoch 050: : Loss: T_27531.529 V_31827.486 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31789.0\n",
      "Epoch 060: : Loss: T_27531.592 V_31789.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31737.767578125\n",
      "Epoch 070: : Loss: T_27418.623 V_31737.768 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31690.14453125\n",
      "Epoch 080: : Loss: T_27416.324 V_31690.145 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31634.294921875\n",
      "Epoch 090: : Loss: T_27347.938 V_31634.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31579.3984375\n",
      "Epoch 100: : Loss: T_27291.041 V_31579.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31526.044921875\n",
      "Epoch 110: : Loss: T_27258.059 V_31526.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31479.013671875\n",
      "Epoch 120: : Loss: T_27252.852 V_31479.014 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31433.81640625\n",
      "Epoch 130: : Loss: T_27163.799 V_31433.816 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31397.25\n",
      "Epoch 140: : Loss: T_26993.121 V_31397.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31333.197265625\n",
      "Epoch 150: : Loss: T_27008.631 V_31333.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31268.763671875\n",
      "Epoch 160: : Loss: T_26952.482 V_31268.764 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31217.2578125\n",
      "Epoch 170: : Loss: T_26823.588 V_31217.258 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31123.654296875\n",
      "Epoch 180: : Loss: T_26776.381 V_31123.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31058.025390625\n",
      "Epoch 190: : Loss: T_26636.725 V_31058.025 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30995.654296875\n",
      "Epoch 200: : Loss: T_26625.875 V_30995.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30856.513671875\n",
      "Epoch 210: : Loss: T_26612.799 V_30856.514 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30750.70703125\n",
      "Epoch 220: : Loss: T_26367.209 V_30750.707 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30727.154296875\n",
      "Epoch 230: : Loss: T_26438.514 V_30727.154 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30703.580078125\n",
      "Epoch 240: : Loss: T_26239.760 V_30703.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30585.876953125\n",
      "Epoch 250: : Loss: T_26160.490 V_30585.877 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30409.333984375\n",
      "Epoch 260: : Loss: T_26083.164 V_30409.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30395.078125\n",
      "Epoch 270: : Loss: T_25975.545 V_30395.078 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30296.96484375\n",
      "Epoch 280: : Loss: T_25881.951 V_30296.965 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30124.197265625\n",
      "Epoch 290: : Loss: T_25793.721 V_30124.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29992.509765625\n",
      "Epoch 300: : Loss: T_25755.334 V_29992.510 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29895.5703125\n",
      "Epoch 310: : Loss: T_25437.990 V_29895.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29858.43359375\n",
      "Epoch 320: : Loss: T_25457.170 V_29858.434 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29674.95703125\n",
      "Epoch 330: : Loss: T_25305.895 V_29674.957 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29516.4375\n",
      "Epoch 340: : Loss: T_25170.564 V_29516.438 | Acc: T_0.000) V_0.000\n",
      "Epoch 350: : Loss: T_25173.695 V_29558.930 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29324.9375\n",
      "Epoch 360: : Loss: T_24948.463 V_29324.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29084.921875\n",
      "Epoch 370: : Loss: T_24941.727 V_29084.922 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29075.07421875\n",
      "Epoch 380: : Loss: T_24886.773 V_29075.074 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28818.166015625\n",
      "Epoch 390: : Loss: T_24684.391 V_28818.166 | Acc: T_0.000) V_0.000\n",
      "Epoch 400: : Loss: T_24650.695 V_28983.160 | Acc: T_0.000) V_0.000\n",
      "Epoch 410: : Loss: T_24532.025 V_28842.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28660.6953125\n",
      "Epoch 420: : Loss: T_24351.779 V_28660.695 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28416.349609375\n",
      "Epoch 430: : Loss: T_24474.709 V_28416.350 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28215.216796875\n",
      "Epoch 440: : Loss: T_24187.252 V_28215.217 | Acc: T_0.000) V_0.000\n",
      "Epoch 450: : Loss: T_23981.619 V_28257.193 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28126.263671875\n",
      "Epoch 460: : Loss: T_23886.436 V_28126.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28053.365234375\n",
      "Epoch 470: : Loss: T_23590.035 V_28053.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27750.275390625\n",
      "Epoch 480: : Loss: T_23539.699 V_27750.275 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27607.353515625\n",
      "Epoch 490: : Loss: T_23378.533 V_27607.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27543.3125\n",
      "Epoch 500: : Loss: T_23548.014 V_27543.312 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27292.91015625\n",
      "Epoch 510: : Loss: T_23139.014 V_27292.910 | Acc: T_0.000) V_0.000\n",
      "Epoch 520: : Loss: T_22950.799 V_27529.975 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27116.056640625\n",
      "Epoch 530: : Loss: T_22818.883 V_27116.057 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26970.611328125\n",
      "Epoch 540: : Loss: T_22849.625 V_26970.611 | Acc: T_0.000) V_0.000\n",
      "Epoch 550: : Loss: T_22557.400 V_27185.211 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26612.35546875\n",
      "Epoch 560: : Loss: T_22394.061 V_26612.355 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26428.2578125\n",
      "Epoch 570: : Loss: T_22326.234 V_26428.258 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_22121.270 V_26463.506 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26398.27734375\n",
      "Epoch 590: : Loss: T_21771.822 V_26398.277 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26169.5859375\n",
      "Epoch 600: : Loss: T_21741.746 V_26169.586 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25990.65234375\n",
      "Epoch 610: : Loss: T_21679.186 V_25990.652 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25763.15234375\n",
      "Epoch 620: : Loss: T_21683.857 V_25763.152 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25587.251953125\n",
      "Epoch 630: : Loss: T_21476.568 V_25587.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 640: : Loss: T_21673.617 V_25765.531 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25272.296875\n",
      "Epoch 650: : Loss: T_21398.299 V_25272.297 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24995.4921875\n",
      "Epoch 660: : Loss: T_21047.119 V_24995.492 | Acc: T_0.000) V_0.000\n",
      "Epoch 670: : Loss: T_21092.152 V_25283.934 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24828.19921875\n",
      "Epoch 680: : Loss: T_20479.859 V_24828.199 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24599.79296875\n",
      "Epoch 690: : Loss: T_20572.246 V_24599.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 700: : Loss: T_20533.199 V_24660.916 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24550.72265625\n",
      "Epoch 710: : Loss: T_20145.139 V_24550.723 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24412.197265625\n",
      "Epoch 720: : Loss: T_20130.760 V_24412.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24206.79296875\n",
      "Epoch 730: : Loss: T_19958.895 V_24206.793 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24155.986328125\n",
      "Epoch 740: : Loss: T_20134.184 V_24155.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 750: : Loss: T_19959.521 V_24217.148 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23517.294921875\n",
      "Epoch 760: : Loss: T_20183.252 V_23517.295 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23444.5546875\n",
      "Epoch 770: : Loss: T_19352.826 V_23444.555 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23270.58203125\n",
      "Epoch 780: : Loss: T_18928.365 V_23270.582 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23101.541015625\n",
      "Epoch 790: : Loss: T_19163.529 V_23101.541 | Acc: T_0.000) V_0.000\n",
      "Epoch 800: : Loss: T_18910.943 V_23377.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23058.572265625\n",
      "Epoch 810: : Loss: T_18831.105 V_23058.572 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22539.876953125\n",
      "Epoch 820: : Loss: T_18911.744 V_22539.877 | Acc: T_0.000) V_0.000\n",
      "Epoch 830: : Loss: T_18351.604 V_22677.115 | Acc: T_0.000) V_0.000\n",
      "Epoch 840: : Loss: T_18728.781 V_22719.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22373.775390625\n",
      "Epoch 850: : Loss: T_18281.645 V_22373.775 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22122.203125\n",
      "Epoch 860: : Loss: T_18416.518 V_22122.203 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22088.755859375\n",
      "Epoch 870: : Loss: T_18242.875 V_22088.756 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21698.3203125\n",
      "Epoch 880: : Loss: T_18173.158 V_21698.320 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21681.6953125\n",
      "Epoch 890: : Loss: T_17375.299 V_21681.695 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21671.6328125\n",
      "Epoch 900: : Loss: T_17359.918 V_21671.633 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21452.115234375\n",
      "Epoch 910: : Loss: T_17548.328 V_21452.115 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21325.384765625\n",
      "Epoch 920: : Loss: T_17179.225 V_21325.385 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21306.064453125\n",
      "Epoch 930: : Loss: T_17361.004 V_21306.064 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20857.923828125\n",
      "Epoch 940: : Loss: T_16729.615 V_20857.924 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_16902.951 V_20892.201 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20180.28125\n",
      "Epoch 960: : Loss: T_16283.133 V_20180.281 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16413.086 V_20464.152 | Acc: T_0.000) V_0.000\n",
      "Epoch 980: : Loss: T_16367.063 V_20317.598 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_16533.572 V_20504.955 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19917.904296875\n",
      "Epoch 1000: : Loss: T_16311.348 V_19917.904 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19797.615234375\n",
      "Epoch 1010: : Loss: T_16256.619 V_19797.615 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19630.794921875\n",
      "Epoch 1020: : Loss: T_16432.789 V_19630.795 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19293.9453125\n",
      "Epoch 1030: : Loss: T_15336.265 V_19293.945 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_15657.500 V_19470.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19237.373046875\n",
      "Epoch 1050: : Loss: T_15096.906 V_19237.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19010.412109375\n",
      "Epoch 1060: : Loss: T_15478.237 V_19010.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18861.955078125\n",
      "Epoch 1070: : Loss: T_15208.839 V_18861.955 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_15135.397 V_19193.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18385.12890625\n",
      "Epoch 1090: : Loss: T_15119.591 V_18385.129 | Acc: T_0.000) V_0.000\n",
      "Epoch 1100: : Loss: T_14986.672 V_18612.760 | Acc: T_0.000) V_0.000\n",
      "Epoch 1110: : Loss: T_15301.305 V_18423.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17699.333984375\n",
      "Epoch 1120: : Loss: T_14704.350 V_17699.334 | Acc: T_0.000) V_0.000\n",
      "Epoch 1130: : Loss: T_14305.354 V_17832.260 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14045.024 V_18229.615 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17450.220703125\n",
      "Epoch 1150: : Loss: T_14018.229 V_17450.221 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17428.12109375\n",
      "Epoch 1160: : Loss: T_14096.685 V_17428.121 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17228.49609375\n",
      "Epoch 1170: : Loss: T_14222.112 V_17228.496 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17221.591796875\n",
      "Epoch 1180: : Loss: T_13555.907 V_17221.592 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16991.984375\n",
      "Epoch 1190: : Loss: T_13490.586 V_16991.984 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16909.90234375\n",
      "Epoch 1200: : Loss: T_13013.193 V_16909.902 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16684.240234375\n",
      "Epoch 1210: : Loss: T_13883.609 V_16684.240 | Acc: T_0.000) V_0.000\n",
      "Epoch 1220: : Loss: T_13743.789 V_16966.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16201.1865234375\n",
      "Epoch 1230: : Loss: T_13629.222 V_16201.187 | Acc: T_0.000) V_0.000\n",
      "Epoch 1240: : Loss: T_13277.981 V_16653.146 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_13054.493 V_16342.380 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15691.4365234375\n",
      "Epoch 1260: : Loss: T_13069.006 V_15691.437 | Acc: T_0.000) V_0.000\n",
      "Epoch 1270: : Loss: T_12653.158 V_16111.315 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_12443.502 V_16111.361 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15584.478515625\n",
      "Epoch 1290: : Loss: T_12333.236 V_15584.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15460.96484375\n",
      "Epoch 1300: : Loss: T_11766.543 V_15460.965 | Acc: T_0.000) V_0.000\n",
      "Epoch 1310: : Loss: T_11523.774 V_15562.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14729.4521484375\n",
      "Epoch 1320: : Loss: T_12227.872 V_14729.452 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_12202.224 V_14941.935 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11700.152 V_15224.979 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14591.345703125\n",
      "Epoch 1350: : Loss: T_11644.460 V_14591.346 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14524.5048828125\n",
      "Epoch 1360: : Loss: T_11976.493 V_14524.505 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11094.559 V_14741.599 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14266.40625\n",
      "Epoch 1380: : Loss: T_11238.874 V_14266.406 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14018.4482421875\n",
      "Epoch 1390: : Loss: T_11884.824 V_14018.448 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13967.44921875\n",
      "Epoch 1400: : Loss: T_11014.913 V_13967.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 1410: : Loss: T_11407.824 V_14155.604 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13535.587890625\n",
      "Epoch 1420: : Loss: T_11104.293 V_13535.588 | Acc: T_0.000) V_0.000\n",
      "Epoch 1430: : Loss: T_10996.356 V_13657.250 | Acc: T_0.000) V_0.000\n",
      "Epoch 1440: : Loss: T_10909.436 V_13707.896 | Acc: T_0.000) V_0.000\n",
      "Epoch 1450: : Loss: T_10295.177 V_13538.036 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13399.310546875\n",
      "Epoch 1460: : Loss: T_10120.285 V_13399.311 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13182.212890625\n",
      "Epoch 1470: : Loss: T_10302.974 V_13182.213 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13164.732421875\n",
      "Epoch 1480: : Loss: T_10111.149 V_13164.732 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13043.8203125\n",
      "Epoch 1490: : Loss: T_10351.312 V_13043.820 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12894.087890625\n",
      "Epoch 1500: : Loss: T_10302.481 V_12894.088 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12564.3740234375\n",
      "Epoch 1510: : Loss: T_10676.083 V_12564.374 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_9909.954 V_12813.023 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12297.3134765625\n",
      "Epoch 1530: : Loss: T_9925.413 V_12297.313 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12176.21875\n",
      "Epoch 1540: : Loss: T_9523.943 V_12176.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_8992.197 V_12212.647 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12034.40625\n",
      "Epoch 1560: : Loss: T_9459.302 V_12034.406 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9505.813 V_12331.512 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11860.2548828125\n",
      "Epoch 1580: : Loss: T_9274.010 V_11860.255 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11671.1298828125\n",
      "Epoch 1590: : Loss: T_9631.245 V_11671.130 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11570.248046875\n",
      "Epoch 1600: : Loss: T_9163.537 V_11570.248 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11317.9951171875\n",
      "Epoch 1610: : Loss: T_8978.194 V_11317.995 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_8656.869 V_11439.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11184.798828125\n",
      "Epoch 1630: : Loss: T_8454.982 V_11184.799 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10914.359375\n",
      "Epoch 1640: : Loss: T_8806.922 V_10914.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_8223.329 V_11169.880 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10759.1845703125\n",
      "Epoch 1660: : Loss: T_8422.265 V_10759.185 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10750.9951171875\n",
      "Epoch 1670: : Loss: T_8601.525 V_10750.995 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_8260.144 V_10770.925 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10572.2275390625\n",
      "Epoch 1690: : Loss: T_8129.194 V_10572.228 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10411.0\n",
      "Epoch 1700: : Loss: T_8463.840 V_10411.000 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10361.408203125\n",
      "Epoch 1710: : Loss: T_8458.457 V_10361.408 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10053.037109375\n",
      "Epoch 1720: : Loss: T_8120.839 V_10053.037 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9993.779296875\n",
      "Epoch 1730: : Loss: T_8360.253 V_9993.779 | Acc: T_0.000) V_0.000\n",
      "Epoch 1740: : Loss: T_8147.786 V_10260.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9796.5537109375\n",
      "Epoch 1750: : Loss: T_7774.603 V_9796.554 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9754.5546875\n",
      "Epoch 1760: : Loss: T_7478.112 V_9754.555 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7468.274 V_9831.996 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9702.6015625\n",
      "Epoch 1780: : Loss: T_7341.211 V_9702.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9536.6337890625\n",
      "Epoch 1790: : Loss: T_7457.583 V_9536.634 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9414.892578125\n",
      "Epoch 1800: : Loss: T_6675.370 V_9414.893 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9410.326171875\n",
      "Epoch 1810: : Loss: T_7404.203 V_9410.326 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9376.9287109375\n",
      "Epoch 1820: : Loss: T_7296.055 V_9376.929 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9009.0224609375\n",
      "Epoch 1830: : Loss: T_7644.235 V_9009.022 | Acc: T_0.000) V_0.000\n",
      "Epoch 1840: : Loss: T_6817.276 V_9191.575 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8909.71484375\n",
      "Epoch 1850: : Loss: T_7032.777 V_8909.715 | Acc: T_0.000) V_0.000\n",
      "Epoch 1860: : Loss: T_6569.458 V_9051.094 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8653.939453125\n",
      "Epoch 1870: : Loss: T_6830.571 V_8653.939 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_7027.801 V_8824.722 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6957.867 V_8868.535 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8625.5283203125\n",
      "Epoch 1900: : Loss: T_6466.974 V_8625.528 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8411.4599609375\n",
      "Epoch 1910: : Loss: T_6601.375 V_8411.460 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8260.7822265625\n",
      "Epoch 1920: : Loss: T_5716.271 V_8260.782 | Acc: T_0.000) V_0.000\n",
      "Epoch 1930: : Loss: T_6129.935 V_8585.842 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_6460.822 V_8386.610 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8203.451171875\n",
      "Epoch 1950: : Loss: T_6342.739 V_8203.451 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8198.6845703125\n",
      "Epoch 1960: : Loss: T_5719.629 V_8198.685 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7835.59619140625\n",
      "Epoch 1970: : Loss: T_5617.298 V_7835.596 | Acc: T_0.000) V_0.000\n",
      "Epoch 1980: : Loss: T_5968.450 V_7975.931 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_6029.892 V_7876.376 | Acc: T_0.000) V_0.000\n",
      "Epoch 2000: : Loss: T_5930.592 V_7869.181 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7648.123046875\n",
      "Epoch 2010: : Loss: T_6137.662 V_7648.123 | Acc: T_0.000) V_0.000\n",
      "Epoch 2020: : Loss: T_5627.089 V_7775.491 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7553.44970703125\n",
      "Epoch 2030: : Loss: T_5668.045 V_7553.450 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7390.68310546875\n",
      "Epoch 2040: : Loss: T_5873.202 V_7390.683 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_5566.142 V_7458.797 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_5778.212 V_7467.136 | Acc: T_0.000) V_0.000\n",
      "Epoch 2070: : Loss: T_5253.537 V_7398.674 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7073.12255859375\n",
      "Epoch 2080: : Loss: T_5751.456 V_7073.123 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5253.049 V_7149.108 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_5521.384 V_7117.712 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6991.4677734375\n",
      "Epoch 2110: : Loss: T_5370.151 V_6991.468 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6904.99658203125\n",
      "Epoch 2120: : Loss: T_5676.469 V_6904.997 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6895.548828125\n",
      "Epoch 2130: : Loss: T_5093.634 V_6895.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6837.37158203125\n",
      "Epoch 2140: : Loss: T_6041.962 V_6837.372 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6757.79052734375\n",
      "Epoch 2150: : Loss: T_5134.363 V_6757.791 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6715.0634765625\n",
      "Epoch 2160: : Loss: T_5815.936 V_6715.063 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6466.3046875\n",
      "Epoch 2170: : Loss: T_5528.610 V_6466.305 | Acc: T_0.000) V_0.000\n",
      "Epoch 2180: : Loss: T_5143.008 V_6530.299 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_4825.849 V_6594.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6352.890625\n",
      "Epoch 2200: : Loss: T_5491.863 V_6352.891 | Acc: T_0.000) V_0.000\n",
      "Epoch 2210: : Loss: T_5171.347 V_6396.628 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6351.4296875\n",
      "Epoch 2220: : Loss: T_4963.105 V_6351.430 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6336.9306640625\n",
      "Epoch 2230: : Loss: T_4985.782 V_6336.931 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6258.9091796875\n",
      "Epoch 2240: : Loss: T_5051.148 V_6258.909 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6163.892578125\n",
      "Epoch 2250: : Loss: T_4880.817 V_6163.893 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6116.25341796875\n",
      "Epoch 2260: : Loss: T_4673.066 V_6116.253 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_4620.777 V_6233.326 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5888.79150390625\n",
      "Epoch 2280: : Loss: T_4853.736 V_5888.792 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_5146.738 V_6015.581 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5837.79248046875\n",
      "Epoch 2300: : Loss: T_4572.623 V_5837.792 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4579.817 V_5858.677 | Acc: T_0.000) V_0.000\n",
      "Epoch 2320: : Loss: T_4649.461 V_5877.467 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5717.3232421875\n",
      "Epoch 2330: : Loss: T_4677.340 V_5717.323 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4477.195 V_5782.723 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4770.978 V_5748.025 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5673.29833984375\n",
      "Epoch 2360: : Loss: T_4010.316 V_5673.298 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5492.482421875\n",
      "Epoch 2370: : Loss: T_4861.315 V_5492.482 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5407.5732421875\n",
      "Epoch 2380: : Loss: T_4785.667 V_5407.573 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4708.972 V_5662.065 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4274.181 V_5575.081 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5307.6689453125\n",
      "Epoch 2410: : Loss: T_4381.636 V_5307.669 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_4670.554 V_5518.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_4422.534 V_5323.775 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4620.964 V_5373.050 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_4565.144 V_5362.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5305.79248046875\n",
      "Epoch 2460: : Loss: T_4264.761 V_5305.792 | Acc: T_0.000) V_0.000\n",
      "Epoch 2470: : Loss: T_4501.121 V_5320.920 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5167.267578125\n",
      "Epoch 2480: : Loss: T_4193.770 V_5167.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5103.84716796875\n",
      "Epoch 2490: : Loss: T_4838.730 V_5103.847 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_4108.029 V_5145.231 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4307.806 V_5128.757 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_3860.883 V_5128.384 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4992.287109375\n",
      "Epoch 2530: : Loss: T_4510.679 V_4992.287 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_3818.774 V_5091.496 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_4069.189 V_5025.034 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4977.369140625\n",
      "Epoch 2560: : Loss: T_4021.094 V_4977.369 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4976.6064453125\n",
      "Epoch 2570: : Loss: T_4649.268 V_4976.606 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4963.79833984375\n",
      "Epoch 2580: : Loss: T_4297.775 V_4963.798 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_3687.051 V_4964.942 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4828.73974609375\n",
      "Epoch 2600: : Loss: T_4588.023 V_4828.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4825.26416015625\n",
      "Epoch 2610: : Loss: T_4550.619 V_4825.264 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4813.0146484375\n",
      "Epoch 2620: : Loss: T_4415.401 V_4813.015 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4216.783 V_4894.200 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4741.04931640625\n",
      "Epoch 2640: : Loss: T_4031.162 V_4741.049 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4605.724 V_4744.173 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4642.8671875\n",
      "Epoch 2660: : Loss: T_4252.318 V_4642.867 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_4069.022 V_4646.012 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4036.053 V_4663.380 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_4431.655 V_4645.050 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4570.6962890625\n",
      "Epoch 2700: : Loss: T_3637.922 V_4570.696 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_4173.864 V_4625.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_4692.357 V_4635.185 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4560.2099609375\n",
      "Epoch 2730: : Loss: T_4401.584 V_4560.210 | Acc: T_0.000) V_0.000\n",
      "Epoch 2740: : Loss: T_3738.917 V_4614.927 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4467.0654296875\n",
      "Epoch 2750: : Loss: T_4199.340 V_4467.065 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3757.165 V_4582.770 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3984.242 V_4537.846 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_3788.621 V_4501.597 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4420.80224609375\n",
      "Epoch 2790: : Loss: T_3603.334 V_4420.802 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_4069.259 V_4486.261 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_3934.104 V_4451.288 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_4348.779 V_4474.359 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4053.079 V_4459.250 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4279.783 V_4430.814 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4341.08154296875\n",
      "Epoch 2850: : Loss: T_3818.398 V_4341.082 | Acc: T_0.000) V_0.000\n",
      "Epoch 2860: : Loss: T_4248.516 V_4383.511 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_4186.995 V_4436.364 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_4122.207 V_4371.857 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3955.598 V_4467.839 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_4103.397 V_4437.170 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_3901.101 V_4390.843 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4324.859375\n",
      "Epoch 2920: : Loss: T_3691.689 V_4324.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3755.412 V_4334.436 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4294.232421875\n",
      "Epoch 2940: : Loss: T_4144.287 V_4294.232 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_3486.718 V_4355.073 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3765.651 V_4310.154 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4238.25244140625\n",
      "Epoch 2970: : Loss: T_3758.068 V_4238.252 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3784.538 V_4260.611 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_4244.238 V_4239.059 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_4354.903 V_4302.764 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_4049.054 V_4276.071 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3888.660 V_4341.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4220.96826171875\n",
      "Epoch 3030: : Loss: T_4257.844 V_4220.968 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4213.86376953125\n",
      "Epoch 3040: : Loss: T_4165.247 V_4213.864 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4209.4755859375\n",
      "Epoch 3050: : Loss: T_4395.432 V_4209.476 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_4094.422 V_4254.957 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4187.3203125\n",
      "Epoch 3070: : Loss: T_3866.137 V_4187.320 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_4384.974 V_4191.598 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3766.971 V_4235.897 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4173.431640625\n",
      "Epoch 3100: : Loss: T_3959.607 V_4173.432 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_3584.221 V_4203.819 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4153.25732421875\n",
      "Epoch 3120: : Loss: T_3729.509 V_4153.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_4258.650 V_4244.667 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_3904.432 V_4199.914 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_3691.306 V_4226.839 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_3951.487 V_4209.950 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4118.63671875\n",
      "Epoch 3170: : Loss: T_3571.723 V_4118.637 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_4436.703 V_4250.036 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3940.195 V_4213.589 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4104.5556640625\n",
      "Epoch 3200: : Loss: T_4181.919 V_4104.556 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_4302.789 V_4143.662 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3824.537 V_4218.752 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_4373.991 V_4204.808 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3361.604 V_4124.570 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3269.084 V_4173.049 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4090.67333984375\n",
      "Epoch 3260: : Loss: T_3481.665 V_4090.673 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_4240.030 V_4198.724 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3689.161 V_4134.623 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3723.415 V_4181.658 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3474.236 V_4126.100 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_3821.837 V_4106.583 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3810.623 V_4149.304 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_4021.606 V_4094.633 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_4079.441 V_4093.135 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4049.792724609375\n",
      "Epoch 3350: : Loss: T_4499.035 V_4049.793 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3594.527 V_4097.069 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3451.202 V_4101.465 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3558.560 V_4086.801 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3988.360595703125\n",
      "Epoch 3390: : Loss: T_4284.729 V_3988.361 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3343.956 V_4066.937 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3717.304 V_4076.719 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3504.833 V_4128.890 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_4242.109 V_3994.335 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3413.803 V_4044.529 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3740.946 V_4133.256 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3945.800 V_4033.141 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3781.178 V_4060.235 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3301.813 V_4054.179 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3872.080 V_4043.243 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3760.525 V_4136.763 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31903.408203125\n",
      "Epoch 010: : Loss: T_27578.242 V_31903.408 | Acc: T_0.000) V_0.000\n",
      "Epoch 020: : Loss: T_27551.660 V_31946.391 | Acc: T_0.000) V_0.000\n",
      "Epoch 030: : Loss: T_27542.996 V_31951.443 | Acc: T_0.000) V_0.000\n",
      "Epoch 040: : Loss: T_27518.172 V_31920.865 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31865.154296875\n",
      "Epoch 050: : Loss: T_27499.072 V_31865.154 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31798.2421875\n",
      "Epoch 060: : Loss: T_27437.047 V_31798.242 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31723.376953125\n",
      "Epoch 070: : Loss: T_27399.592 V_31723.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31660.8515625\n",
      "Epoch 080: : Loss: T_27374.221 V_31660.852 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31578.365234375\n",
      "Epoch 090: : Loss: T_27314.891 V_31578.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31541.298828125\n",
      "Epoch 100: : Loss: T_27253.479 V_31541.299 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31434.123046875\n",
      "Epoch 110: : Loss: T_27203.721 V_31434.123 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31370.158203125\n",
      "Epoch 120: : Loss: T_27171.086 V_31370.158 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31336.228515625\n",
      "Epoch 130: : Loss: T_27060.285 V_31336.229 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31295.662109375\n",
      "Epoch 140: : Loss: T_27038.340 V_31295.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31267.45703125\n",
      "Epoch 150: : Loss: T_26956.396 V_31267.457 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31175.560546875\n",
      "Epoch 160: : Loss: T_26923.178 V_31175.561 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31126.552734375\n",
      "Epoch 170: : Loss: T_26842.824 V_31126.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31076.044921875\n",
      "Epoch 180: : Loss: T_26712.889 V_31076.045 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31010.310546875\n",
      "Epoch 190: : Loss: T_26643.361 V_31010.311 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30849.990234375\n",
      "Epoch 200: : Loss: T_26592.027 V_30849.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30779.21484375\n",
      "Epoch 210: : Loss: T_26464.531 V_30779.215 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30715.373046875\n",
      "Epoch 220: : Loss: T_26449.432 V_30715.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30679.376953125\n",
      "Epoch 230: : Loss: T_26302.209 V_30679.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30572.7421875\n",
      "Epoch 240: : Loss: T_26208.951 V_30572.742 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30510.689453125\n",
      "Epoch 250: : Loss: T_26230.918 V_30510.689 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30466.052734375\n",
      "Epoch 260: : Loss: T_26085.812 V_30466.053 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30301.548828125\n",
      "Epoch 270: : Loss: T_25894.686 V_30301.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30279.6484375\n",
      "Epoch 280: : Loss: T_25889.225 V_30279.648 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30231.1875\n",
      "Epoch 290: : Loss: T_25864.766 V_30231.188 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30067.197265625\n",
      "Epoch 300: : Loss: T_25683.129 V_30067.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29736.447265625\n",
      "Epoch 310: : Loss: T_25673.340 V_29736.447 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29677.6015625\n",
      "Epoch 320: : Loss: T_25575.963 V_29677.602 | Acc: T_0.000) V_0.000\n",
      "Epoch 330: : Loss: T_25464.082 V_29769.859 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29603.25\n",
      "Epoch 340: : Loss: T_25290.496 V_29603.250 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29543.091796875\n",
      "Epoch 350: : Loss: T_25003.160 V_29543.092 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29306.943359375\n",
      "Epoch 360: : Loss: T_25185.738 V_29306.943 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29164.5625\n",
      "Epoch 370: : Loss: T_24851.756 V_29164.562 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29020.18359375\n",
      "Epoch 380: : Loss: T_25071.359 V_29020.184 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29012.146484375\n",
      "Epoch 390: : Loss: T_24754.404 V_29012.146 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28817.3984375\n",
      "Epoch 400: : Loss: T_24756.250 V_28817.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28791.947265625\n",
      "Epoch 410: : Loss: T_24306.982 V_28791.947 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28701.67578125\n",
      "Epoch 420: : Loss: T_24139.664 V_28701.676 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28543.478515625\n",
      "Epoch 430: : Loss: T_24124.332 V_28543.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28416.478515625\n",
      "Epoch 440: : Loss: T_24101.627 V_28416.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28296.107421875\n",
      "Epoch 450: : Loss: T_24136.150 V_28296.107 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28186.666015625\n",
      "Epoch 460: : Loss: T_23877.078 V_28186.666 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28067.09375\n",
      "Epoch 470: : Loss: T_23789.266 V_28067.094 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27928.236328125\n",
      "Epoch 480: : Loss: T_23601.566 V_27928.236 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27799.224609375\n",
      "Epoch 490: : Loss: T_23709.596 V_27799.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27673.23828125\n",
      "Epoch 500: : Loss: T_23319.609 V_27673.238 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27458.251953125\n",
      "Epoch 510: : Loss: T_23221.535 V_27458.252 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27230.40234375\n",
      "Epoch 520: : Loss: T_22939.807 V_27230.402 | Acc: T_0.000) V_0.000\n",
      "Epoch 530: : Loss: T_23010.852 V_27305.912 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27024.380859375\n",
      "Epoch 540: : Loss: T_22745.895 V_27024.381 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26586.859375\n",
      "Epoch 550: : Loss: T_22685.262 V_26586.859 | Acc: T_0.000) V_0.000\n",
      "Epoch 560: : Loss: T_22617.787 V_26703.766 | Acc: T_0.000) V_0.000\n",
      "Epoch 570: : Loss: T_22554.914 V_26737.627 | Acc: T_0.000) V_0.000\n",
      "Epoch 580: : Loss: T_22353.377 V_26758.518 | Acc: T_0.000) V_0.000\n",
      "Epoch 590: : Loss: T_22121.779 V_26659.266 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26382.388671875\n",
      "Epoch 600: : Loss: T_21909.691 V_26382.389 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26166.94921875\n",
      "Epoch 610: : Loss: T_22043.059 V_26166.949 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26125.431640625\n",
      "Epoch 620: : Loss: T_21911.316 V_26125.432 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25903.064453125\n",
      "Epoch 630: : Loss: T_21643.309 V_25903.064 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25453.107421875\n",
      "Epoch 640: : Loss: T_21226.117 V_25453.107 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25414.75\n",
      "Epoch 650: : Loss: T_21079.102 V_25414.750 | Acc: T_0.000) V_0.000\n",
      "Epoch 660: : Loss: T_21328.457 V_25443.010 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25166.009765625\n",
      "Epoch 670: : Loss: T_20884.549 V_25166.010 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25158.509765625\n",
      "Epoch 680: : Loss: T_21563.590 V_25158.510 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25058.173828125\n",
      "Epoch 690: : Loss: T_20800.045 V_25058.174 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24868.21484375\n",
      "Epoch 700: : Loss: T_20550.170 V_24868.215 | Acc: T_0.000) V_0.000\n",
      "Epoch 710: : Loss: T_20667.256 V_25064.375 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24646.3515625\n",
      "Epoch 720: : Loss: T_20406.109 V_24646.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24361.740234375\n",
      "Epoch 730: : Loss: T_20308.441 V_24361.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24230.859375\n",
      "Epoch 740: : Loss: T_20219.789 V_24230.859 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23998.736328125\n",
      "Epoch 750: : Loss: T_20160.215 V_23998.736 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23762.119140625\n",
      "Epoch 760: : Loss: T_19798.760 V_23762.119 | Acc: T_0.000) V_0.000\n",
      "Epoch 770: : Loss: T_19406.227 V_23892.949 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23584.966796875\n",
      "Epoch 780: : Loss: T_19221.824 V_23584.967 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23157.056640625\n",
      "Epoch 790: : Loss: T_18997.473 V_23157.057 | Acc: T_0.000) V_0.000\n",
      "Epoch 800: : Loss: T_19071.295 V_23223.977 | Acc: T_0.000) V_0.000\n",
      "Epoch 810: : Loss: T_18900.123 V_23482.416 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23025.7421875\n",
      "Epoch 820: : Loss: T_19000.971 V_23025.742 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22737.7109375\n",
      "Epoch 830: : Loss: T_18785.510 V_22737.711 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22550.21875\n",
      "Epoch 840: : Loss: T_18710.092 V_22550.219 | Acc: T_0.000) V_0.000\n",
      "Epoch 850: : Loss: T_18527.688 V_22642.043 | Acc: T_0.000) V_0.000\n",
      "Epoch 860: : Loss: T_18135.902 V_22789.115 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22406.224609375\n",
      "Epoch 870: : Loss: T_18164.051 V_22406.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21849.71484375\n",
      "Epoch 880: : Loss: T_18240.506 V_21849.715 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21760.169921875\n",
      "Epoch 890: : Loss: T_18062.996 V_21760.170 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21601.185546875\n",
      "Epoch 900: : Loss: T_17998.895 V_21601.186 | Acc: T_0.000) V_0.000\n",
      "Epoch 910: : Loss: T_17701.414 V_21738.627 | Acc: T_0.000) V_0.000\n",
      "Epoch 920: : Loss: T_17416.879 V_21608.689 | Acc: T_0.000) V_0.000\n",
      "Epoch 930: : Loss: T_17278.705 V_21860.279 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21081.205078125\n",
      "Epoch 940: : Loss: T_16906.061 V_21081.205 | Acc: T_0.000) V_0.000\n",
      "Epoch 950: : Loss: T_16833.113 V_21255.965 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21066.30859375\n",
      "Epoch 960: : Loss: T_17119.088 V_21066.309 | Acc: T_0.000) V_0.000\n",
      "Epoch 970: : Loss: T_16497.416 V_21234.695 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20979.1015625\n",
      "Epoch 980: : Loss: T_16990.701 V_20979.102 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20520.73828125\n",
      "Epoch 990: : Loss: T_16203.041 V_20520.738 | Acc: T_0.000) V_0.000\n",
      "Epoch 1000: : Loss: T_16300.048 V_20585.457 | Acc: T_0.000) V_0.000\n",
      "Epoch 1010: : Loss: T_16141.819 V_20684.793 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20117.83203125\n",
      "Epoch 1020: : Loss: T_15917.878 V_20117.832 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20112.28515625\n",
      "Epoch 1030: : Loss: T_16123.672 V_20112.285 | Acc: T_0.000) V_0.000\n",
      "Epoch 1040: : Loss: T_15733.812 V_20463.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19464.90234375\n",
      "Epoch 1050: : Loss: T_16003.433 V_19464.902 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_15466.881 V_19721.557 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19422.16796875\n",
      "Epoch 1070: : Loss: T_15103.302 V_19422.168 | Acc: T_0.000) V_0.000\n",
      "Epoch 1080: : Loss: T_15739.328 V_19801.418 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19224.650390625\n",
      "Epoch 1090: : Loss: T_14887.626 V_19224.650 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19202.69921875\n",
      "Epoch 1100: : Loss: T_15228.635 V_19202.699 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18871.25390625\n",
      "Epoch 1110: : Loss: T_14659.117 V_18871.254 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18764.01953125\n",
      "Epoch 1120: : Loss: T_14742.136 V_18764.020 | Acc: T_0.000) V_0.000\n",
      "Epoch 1130: : Loss: T_14718.424 V_19544.986 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18259.9921875\n",
      "Epoch 1140: : Loss: T_14292.291 V_18259.992 | Acc: T_0.000) V_0.000\n",
      "Epoch 1150: : Loss: T_15061.853 V_18485.240 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18153.46875\n",
      "Epoch 1160: : Loss: T_13870.139 V_18153.469 | Acc: T_0.000) V_0.000\n",
      "Epoch 1170: : Loss: T_14013.868 V_18455.289 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_14368.361 V_18512.064 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18044.748046875\n",
      "Epoch 1190: : Loss: T_13797.688 V_18044.748 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17873.5390625\n",
      "Epoch 1200: : Loss: T_13088.111 V_17873.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17825.62109375\n",
      "Epoch 1210: : Loss: T_13696.195 V_17825.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17197.998046875\n",
      "Epoch 1220: : Loss: T_13595.420 V_17197.998 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17004.958984375\n",
      "Epoch 1230: : Loss: T_13139.037 V_17004.959 | Acc: T_0.000) V_0.000\n",
      "Epoch 1240: : Loss: T_13350.719 V_17108.678 | Acc: T_0.000) V_0.000\n",
      "Epoch 1250: : Loss: T_13219.769 V_17322.545 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16868.8125\n",
      "Epoch 1260: : Loss: T_13068.024 V_16868.812 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16496.4765625\n",
      "Epoch 1270: : Loss: T_12665.005 V_16496.477 | Acc: T_0.000) V_0.000\n",
      "Epoch 1280: : Loss: T_12632.822 V_16960.811 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_12328.488 V_16674.557 | Acc: T_0.000) V_0.000\n",
      "Epoch 1300: : Loss: T_12697.424 V_16522.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16463.572265625\n",
      "Epoch 1310: : Loss: T_12818.849 V_16463.572 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16265.3115234375\n",
      "Epoch 1320: : Loss: T_12707.267 V_16265.312 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_11845.533 V_16573.025 | Acc: T_0.000) V_0.000\n",
      "Epoch 1340: : Loss: T_11750.294 V_16615.861 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16101.576171875\n",
      "Epoch 1350: : Loss: T_11990.560 V_16101.576 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15584.5654296875\n",
      "Epoch 1360: : Loss: T_11798.473 V_15584.565 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11827.451 V_16005.476 | Acc: T_0.000) V_0.000\n",
      "Epoch 1380: : Loss: T_11642.332 V_16055.877 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_11243.685 V_16143.979 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_11801.051 V_15639.844 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15322.7978515625\n",
      "Epoch 1410: : Loss: T_11278.093 V_15322.798 | Acc: T_0.000) V_0.000\n",
      "Epoch 1420: : Loss: T_11347.208 V_15571.905 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15069.53125\n",
      "Epoch 1430: : Loss: T_11063.883 V_15069.531 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14933.0703125\n",
      "Epoch 1440: : Loss: T_10746.352 V_14933.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14754.466796875\n",
      "Epoch 1450: : Loss: T_10842.309 V_14754.467 | Acc: T_0.000) V_0.000\n",
      "Epoch 1460: : Loss: T_10198.211 V_14802.754 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_10455.516 V_14885.759 | Acc: T_0.000) V_0.000\n",
      "Epoch 1480: : Loss: T_10077.346 V_14823.956 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14199.0703125\n",
      "Epoch 1490: : Loss: T_9864.083 V_14199.070 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14006.986328125\n",
      "Epoch 1500: : Loss: T_10342.292 V_14006.986 | Acc: T_0.000) V_0.000\n",
      "Epoch 1510: : Loss: T_10082.111 V_14341.626 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_10064.938 V_14185.391 | Acc: T_0.000) V_0.000\n",
      "Epoch 1530: : Loss: T_9878.817 V_14032.816 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13469.5703125\n",
      "Epoch 1540: : Loss: T_9720.566 V_13469.570 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13365.587890625\n",
      "Epoch 1550: : Loss: T_9560.272 V_13365.588 | Acc: T_0.000) V_0.000\n",
      "Epoch 1560: : Loss: T_9658.367 V_13510.466 | Acc: T_0.000) V_0.000\n",
      "Epoch 1570: : Loss: T_9330.009 V_13674.008 | Acc: T_0.000) V_0.000\n",
      "Epoch 1580: : Loss: T_9297.412 V_13433.808 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13104.6826171875\n",
      "Epoch 1590: : Loss: T_9038.051 V_13104.683 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13039.2568359375\n",
      "Epoch 1600: : Loss: T_9490.327 V_13039.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 1610: : Loss: T_9123.830 V_13253.415 | Acc: T_0.000) V_0.000\n",
      "Epoch 1620: : Loss: T_9212.762 V_13159.730 | Acc: T_0.000) V_0.000\n",
      "Epoch 1630: : Loss: T_8747.998 V_13071.437 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12495.404296875\n",
      "Epoch 1640: : Loss: T_8539.672 V_12495.404 | Acc: T_0.000) V_0.000\n",
      "Epoch 1650: : Loss: T_8679.330 V_12781.730 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12334.1630859375\n",
      "Epoch 1660: : Loss: T_9260.441 V_12334.163 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12232.0078125\n",
      "Epoch 1670: : Loss: T_7996.100 V_12232.008 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12005.3271484375\n",
      "Epoch 1680: : Loss: T_8415.813 V_12005.327 | Acc: T_0.000) V_0.000\n",
      "Epoch 1690: : Loss: T_8408.062 V_12082.856 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11910.5556640625\n",
      "Epoch 1700: : Loss: T_8065.859 V_11910.556 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11746.703125\n",
      "Epoch 1710: : Loss: T_8395.324 V_11746.703 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11593.517578125\n",
      "Epoch 1720: : Loss: T_8011.222 V_11593.518 | Acc: T_0.000) V_0.000\n",
      "Epoch 1730: : Loss: T_7339.736 V_11635.817 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11484.5126953125\n",
      "Epoch 1740: : Loss: T_7905.065 V_11484.513 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11230.646484375\n",
      "Epoch 1750: : Loss: T_7919.358 V_11230.646 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_7895.978 V_11262.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10971.56640625\n",
      "Epoch 1770: : Loss: T_7888.245 V_10971.566 | Acc: T_0.000) V_0.000\n",
      "Epoch 1780: : Loss: T_7644.206 V_11034.162 | Acc: T_0.000) V_0.000\n",
      "Epoch 1790: : Loss: T_8425.650 V_11062.392 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10814.7724609375\n",
      "Epoch 1800: : Loss: T_7531.207 V_10814.772 | Acc: T_0.000) V_0.000\n",
      "Epoch 1810: : Loss: T_7245.716 V_10815.094 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10452.9951171875\n",
      "Epoch 1820: : Loss: T_7603.520 V_10452.995 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_6983.263 V_10482.686 | Acc: T_0.000) V_0.000\n",
      "Epoch 1840: : Loss: T_7220.562 V_10767.534 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_7248.854 V_10456.729 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10177.46875\n",
      "Epoch 1860: : Loss: T_7253.063 V_10177.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10091.826171875\n",
      "Epoch 1870: : Loss: T_6602.098 V_10091.826 | Acc: T_0.000) V_0.000\n",
      "Epoch 1880: : Loss: T_7086.100 V_10201.201 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6768.430 V_10233.237 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9608.3076171875\n",
      "Epoch 1900: : Loss: T_6804.454 V_9608.308 | Acc: T_0.000) V_0.000\n",
      "Epoch 1910: : Loss: T_6962.859 V_10136.609 | Acc: T_0.000) V_0.000\n",
      "Epoch 1920: : Loss: T_6192.999 V_9942.303 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9447.197265625\n",
      "Epoch 1930: : Loss: T_6617.639 V_9447.197 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9249.1064453125\n",
      "Epoch 1940: : Loss: T_6157.144 V_9249.106 | Acc: T_0.000) V_0.000\n",
      "Epoch 1950: : Loss: T_6525.604 V_9740.651 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_6429.233 V_9745.002 | Acc: T_0.000) V_0.000\n",
      "Epoch 1970: : Loss: T_6488.508 V_9414.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9123.4306640625\n",
      "Epoch 1980: : Loss: T_6053.757 V_9123.431 | Acc: T_0.000) V_0.000\n",
      "Epoch 1990: : Loss: T_6396.251 V_9127.951 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9001.244140625\n",
      "Epoch 2000: : Loss: T_5963.566 V_9001.244 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8841.193359375\n",
      "Epoch 2010: : Loss: T_5666.680 V_8841.193 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8581.1337890625\n",
      "Epoch 2020: : Loss: T_5699.675 V_8581.134 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_5529.827 V_8793.205 | Acc: T_0.000) V_0.000\n",
      "Epoch 2040: : Loss: T_6045.618 V_8623.988 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8468.728515625\n",
      "Epoch 2050: : Loss: T_5608.921 V_8468.729 | Acc: T_0.000) V_0.000\n",
      "Epoch 2060: : Loss: T_6051.042 V_8710.366 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8439.1767578125\n",
      "Epoch 2070: : Loss: T_5850.551 V_8439.177 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8315.4775390625\n",
      "Epoch 2080: : Loss: T_5880.345 V_8315.478 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5502.513 V_8382.998 | Acc: T_0.000) V_0.000\n",
      "Epoch 2100: : Loss: T_5083.019 V_8365.531 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7986.62841796875\n",
      "Epoch 2110: : Loss: T_4889.813 V_7986.628 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7742.44873046875\n",
      "Epoch 2120: : Loss: T_5547.288 V_7742.449 | Acc: T_0.000) V_0.000\n",
      "Epoch 2130: : Loss: T_5647.168 V_7838.464 | Acc: T_0.000) V_0.000\n",
      "Epoch 2140: : Loss: T_5331.369 V_7775.117 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7664.78515625\n",
      "Epoch 2150: : Loss: T_5448.880 V_7664.785 | Acc: T_0.000) V_0.000\n",
      "Epoch 2160: : Loss: T_5606.141 V_7851.131 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7653.55810546875\n",
      "Epoch 2170: : Loss: T_4918.565 V_7653.558 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7533.734375\n",
      "Epoch 2180: : Loss: T_5108.455 V_7533.734 | Acc: T_0.000) V_0.000\n",
      "Epoch 2190: : Loss: T_5398.175 V_7658.585 | Acc: T_0.000) V_0.000\n",
      "Epoch 2200: : Loss: T_5430.680 V_7755.778 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7504.28955078125\n",
      "Epoch 2210: : Loss: T_5194.694 V_7504.290 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7382.099609375\n",
      "Epoch 2220: : Loss: T_4718.009 V_7382.100 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7145.33447265625\n",
      "Epoch 2230: : Loss: T_5230.950 V_7145.334 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6783.3505859375\n",
      "Epoch 2240: : Loss: T_5436.569 V_6783.351 | Acc: T_0.000) V_0.000\n",
      "Epoch 2250: : Loss: T_4454.500 V_6800.426 | Acc: T_0.000) V_0.000\n",
      "Epoch 2260: : Loss: T_4492.946 V_6966.068 | Acc: T_0.000) V_0.000\n",
      "Epoch 2270: : Loss: T_4666.850 V_6941.143 | Acc: T_0.000) V_0.000\n",
      "Epoch 2280: : Loss: T_4587.229 V_6908.527 | Acc: T_0.000) V_0.000\n",
      "Epoch 2290: : Loss: T_4451.377 V_6794.929 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6652.9208984375\n",
      "Epoch 2300: : Loss: T_4701.874 V_6652.921 | Acc: T_0.000) V_0.000\n",
      "Epoch 2310: : Loss: T_4806.161 V_6672.896 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6497.56005859375\n",
      "Epoch 2320: : Loss: T_4774.238 V_6497.560 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_4736.263 V_6767.601 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4050.192 V_6701.084 | Acc: T_0.000) V_0.000\n",
      "Epoch 2350: : Loss: T_4883.914 V_6633.828 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6456.5029296875\n",
      "Epoch 2360: : Loss: T_5092.653 V_6456.503 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_4867.814 V_6532.954 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4531.830 V_6492.178 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6077.07861328125\n",
      "Epoch 2390: : Loss: T_4600.425 V_6077.079 | Acc: T_0.000) V_0.000\n",
      "Epoch 2400: : Loss: T_4137.862 V_6187.694 | Acc: T_0.000) V_0.000\n",
      "Epoch 2410: : Loss: T_4501.579 V_6208.239 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5914.1962890625\n",
      "Epoch 2420: : Loss: T_4350.616 V_5914.196 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_4728.156 V_6259.832 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4534.492 V_6258.322 | Acc: T_0.000) V_0.000\n",
      "Epoch 2450: : Loss: T_4164.814 V_6053.402 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_4228.685 V_6029.369 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5788.376953125\n",
      "Epoch 2470: : Loss: T_4153.623 V_5788.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5763.68701171875\n",
      "Epoch 2480: : Loss: T_3949.300 V_5763.687 | Acc: T_0.000) V_0.000\n",
      "Epoch 2490: : Loss: T_3873.938 V_6052.037 | Acc: T_0.000) V_0.000\n",
      "Epoch 2500: : Loss: T_3557.940 V_6032.581 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4122.200 V_5823.996 | Acc: T_0.000) V_0.000\n",
      "Epoch 2520: : Loss: T_4207.985 V_5959.864 | Acc: T_0.000) V_0.000\n",
      "Epoch 2530: : Loss: T_4266.035 V_5837.789 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_4068.503 V_6017.213 | Acc: T_0.000) V_0.000\n",
      "Epoch 2550: : Loss: T_4642.410 V_5863.087 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_4637.029 V_5764.759 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5712.53271484375\n",
      "Epoch 2570: : Loss: T_4715.791 V_5712.533 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5689.8408203125\n",
      "Epoch 2580: : Loss: T_4229.816 V_5689.841 | Acc: T_0.000) V_0.000\n",
      "Epoch 2590: : Loss: T_4354.606 V_5785.976 | Acc: T_0.000) V_0.000\n",
      "Epoch 2600: : Loss: T_3625.877 V_5818.613 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5645.91357421875\n",
      "Epoch 2610: : Loss: T_4642.859 V_5645.914 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5407.02001953125\n",
      "Epoch 2620: : Loss: T_4572.028 V_5407.020 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5324.8720703125\n",
      "Epoch 2630: : Loss: T_3662.506 V_5324.872 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_3919.007 V_5411.424 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_3880.739 V_5649.851 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_3889.382 V_5533.951 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_3957.298 V_5487.663 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4082.561 V_5442.561 | Acc: T_0.000) V_0.000\n",
      "Epoch 2690: : Loss: T_3901.973 V_5493.962 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_4129.485 V_5457.988 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_4070.412 V_5411.480 | Acc: T_0.000) V_0.000\n",
      "Epoch 2720: : Loss: T_3935.190 V_5375.945 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5293.41064453125\n",
      "Epoch 2730: : Loss: T_4122.168 V_5293.411 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5275.97021484375\n",
      "Epoch 2740: : Loss: T_4214.057 V_5275.970 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5260.197265625\n",
      "Epoch 2750: : Loss: T_4339.248 V_5260.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 2760: : Loss: T_3289.167 V_5360.485 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3700.741 V_5293.614 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5204.12646484375\n",
      "Epoch 2780: : Loss: T_4085.915 V_5204.126 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5117.18994140625\n",
      "Epoch 2790: : Loss: T_4050.276 V_5117.190 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_4012.922 V_5284.047 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_4219.749 V_5183.639 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3751.715 V_5348.699 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4281.586 V_5313.488 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4215.041 V_5308.029 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_4536.922 V_5215.873 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5002.13623046875\n",
      "Epoch 2860: : Loss: T_3821.986 V_5002.136 | Acc: T_0.000) V_0.000\n",
      "Epoch 2870: : Loss: T_4783.923 V_5135.434 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3454.753 V_5155.930 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3904.339 V_5207.798 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3945.646 V_5030.334 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_4047.216 V_5136.852 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_4086.682 V_5108.029 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3604.421 V_5087.947 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_3810.498 V_5118.608 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_4204.748 V_5253.261 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3669.039 V_5196.292 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3771.629 V_5283.909 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3744.497 V_5210.396 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_4370.722 V_5271.117 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_3747.793 V_5160.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4918.8671875\n",
      "Epoch 3010: : Loss: T_4158.203 V_4918.867 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_3770.493 V_5243.725 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_4012.128 V_5137.668 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4875.2021484375\n",
      "Epoch 3040: : Loss: T_3862.134 V_4875.202 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_4127.070 V_4945.885 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4825.8876953125\n",
      "Epoch 3060: : Loss: T_4303.971 V_4825.888 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3749.237 V_4963.825 | Acc: T_0.000) V_0.000\n",
      "Epoch 3080: : Loss: T_3908.403 V_5023.243 | Acc: T_0.000) V_0.000\n",
      "Epoch 3090: : Loss: T_3976.882 V_5072.352 | Acc: T_0.000) V_0.000\n",
      "Epoch 3100: : Loss: T_3374.532 V_5056.868 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_4023.686 V_4936.762 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_4110.653 V_4985.585 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_4168.662 V_5068.008 | Acc: T_0.000) V_0.000\n",
      "Epoch 3140: : Loss: T_4051.716 V_4919.237 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_4154.810 V_4859.515 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4674.25146484375\n",
      "Epoch 3160: : Loss: T_3873.093 V_4674.251 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_3974.122 V_4855.117 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_4183.475 V_5074.842 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_4277.319 V_4888.406 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_4168.400 V_4765.786 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3955.536 V_4873.092 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3724.458 V_4940.069 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_3787.343 V_4820.179 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_4151.605 V_5020.528 | Acc: T_0.000) V_0.000\n",
      "Epoch 3250: : Loss: T_3675.439 V_4985.625 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_3953.100 V_4968.080 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_4142.137 V_5070.209 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3748.839 V_4890.191 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_3984.885 V_4926.555 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_4110.393 V_4778.312 | Acc: T_0.000) V_0.000\n",
      "Epoch 3310: : Loss: T_4119.147 V_4886.093 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_3590.467 V_4944.966 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_3684.369 V_5075.609 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_4354.097 V_4957.156 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3966.371 V_4867.048 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_3770.743 V_4881.470 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3701.331 V_4922.047 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_3774.103 V_5034.617 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3975.657 V_5091.517 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3739.247 V_5026.164 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_4042.287 V_4980.271 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_3607.951 V_4900.946 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3465.880 V_4926.654 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_4064.127 V_4972.178 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3735.583 V_4840.779 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_3531.606 V_4938.753 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3750.508 V_5013.232 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_4363.179 V_4984.042 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_3708.208 V_5017.042 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3661.868 V_5038.843 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31854.701171875\n",
      "Epoch 010: : Loss: T_27601.422 V_31854.701 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31826.552734375\n",
      "Epoch 020: : Loss: T_27574.895 V_31826.553 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31795.5078125\n",
      "Epoch 030: : Loss: T_27536.498 V_31795.508 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31753.9375\n",
      "Epoch 040: : Loss: T_27498.607 V_31753.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31706.9921875\n",
      "Epoch 050: : Loss: T_27473.736 V_31706.992 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31668.8984375\n",
      "Epoch 060: : Loss: T_27441.586 V_31668.898 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31604.580078125\n",
      "Epoch 070: : Loss: T_27399.209 V_31604.580 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31557.74609375\n",
      "Epoch 080: : Loss: T_27342.537 V_31557.746 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31521.626953125\n",
      "Epoch 090: : Loss: T_27297.760 V_31521.627 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31480.595703125\n",
      "Epoch 100: : Loss: T_27271.721 V_31480.596 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31445.830078125\n",
      "Epoch 110: : Loss: T_27209.080 V_31445.830 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31429.9609375\n",
      "Epoch 120: : Loss: T_27100.316 V_31429.961 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31386.654296875\n",
      "Epoch 130: : Loss: T_27095.355 V_31386.654 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31310.1796875\n",
      "Epoch 140: : Loss: T_27009.299 V_31310.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31191.126953125\n",
      "Epoch 150: : Loss: T_27004.510 V_31191.127 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31154.810546875\n",
      "Epoch 160: : Loss: T_26955.936 V_31154.811 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31110.3984375\n",
      "Epoch 170: : Loss: T_26788.270 V_31110.398 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  31052.267578125\n",
      "Epoch 180: : Loss: T_26812.547 V_31052.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30964.9375\n",
      "Epoch 190: : Loss: T_26676.244 V_30964.938 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30829.43359375\n",
      "Epoch 200: : Loss: T_26600.375 V_30829.434 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30695.71875\n",
      "Epoch 210: : Loss: T_26566.840 V_30695.719 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30681.162109375\n",
      "Epoch 220: : Loss: T_26381.557 V_30681.162 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30679.947265625\n",
      "Epoch 230: : Loss: T_26383.037 V_30679.947 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30537.908203125\n",
      "Epoch 240: : Loss: T_26262.451 V_30537.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30423.7890625\n",
      "Epoch 250: : Loss: T_26089.232 V_30423.789 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30392.337890625\n",
      "Epoch 260: : Loss: T_26019.355 V_30392.338 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30305.0625\n",
      "Epoch 270: : Loss: T_25970.447 V_30305.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30101.521484375\n",
      "Epoch 280: : Loss: T_25932.121 V_30101.521 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  30079.548828125\n",
      "Epoch 290: : Loss: T_25776.264 V_30079.549 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29988.43359375\n",
      "Epoch 300: : Loss: T_25675.586 V_29988.434 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29801.908203125\n",
      "Epoch 310: : Loss: T_25587.699 V_29801.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29630.82421875\n",
      "Epoch 320: : Loss: T_25468.434 V_29630.824 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29591.35546875\n",
      "Epoch 330: : Loss: T_25424.189 V_29591.355 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29392.876953125\n",
      "Epoch 340: : Loss: T_25350.754 V_29392.877 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29275.451171875\n",
      "Epoch 350: : Loss: T_25340.652 V_29275.451 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29251.59765625\n",
      "Epoch 360: : Loss: T_25193.277 V_29251.598 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  29085.376953125\n",
      "Epoch 370: : Loss: T_25058.734 V_29085.377 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28852.09375\n",
      "Epoch 380: : Loss: T_24902.367 V_28852.094 | Acc: T_0.000) V_0.000\n",
      "Epoch 390: : Loss: T_24731.283 V_28894.482 | Acc: T_0.000) V_0.000\n",
      "Epoch 400: : Loss: T_24568.869 V_28866.479 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28590.634765625\n",
      "Epoch 410: : Loss: T_24434.852 V_28590.635 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28430.369140625\n",
      "Epoch 420: : Loss: T_24237.824 V_28430.369 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28283.171875\n",
      "Epoch 430: : Loss: T_24266.984 V_28283.172 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28245.326171875\n",
      "Epoch 440: : Loss: T_23794.189 V_28245.326 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28147.54296875\n",
      "Epoch 450: : Loss: T_23954.625 V_28147.543 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  28064.009765625\n",
      "Epoch 460: : Loss: T_23974.209 V_28064.010 | Acc: T_0.000) V_0.000\n",
      "Epoch 470: : Loss: T_23704.318 V_28089.324 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27827.0625\n",
      "Epoch 480: : Loss: T_23657.232 V_27827.062 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27409.98046875\n",
      "Epoch 490: : Loss: T_23516.021 V_27409.980 | Acc: T_0.000) V_0.000\n",
      "Epoch 500: : Loss: T_23425.195 V_27480.777 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27349.662109375\n",
      "Epoch 510: : Loss: T_23333.625 V_27349.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  27069.763671875\n",
      "Epoch 520: : Loss: T_23154.635 V_27069.764 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26955.46875\n",
      "Epoch 530: : Loss: T_23065.215 V_26955.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26864.751953125\n",
      "Epoch 540: : Loss: T_22853.904 V_26864.752 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26815.353515625\n",
      "Epoch 550: : Loss: T_22893.859 V_26815.354 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26532.1328125\n",
      "Epoch 560: : Loss: T_22539.941 V_26532.133 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26387.724609375\n",
      "Epoch 570: : Loss: T_22588.971 V_26387.725 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26284.11328125\n",
      "Epoch 580: : Loss: T_22285.096 V_26284.113 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26170.19140625\n",
      "Epoch 590: : Loss: T_21875.277 V_26170.191 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  26076.845703125\n",
      "Epoch 600: : Loss: T_22230.215 V_26076.846 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  25549.455078125\n",
      "Epoch 610: : Loss: T_21954.666 V_25549.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 620: : Loss: T_21341.592 V_25669.223 | Acc: T_0.000) V_0.000\n",
      "Epoch 630: : Loss: T_21447.104 V_25750.285 | Acc: T_0.000) V_0.000\n",
      "Epoch 640: : Loss: T_21569.268 V_25698.270 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24966.615234375\n",
      "Epoch 650: : Loss: T_21424.537 V_24966.615 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24649.69140625\n",
      "Epoch 660: : Loss: T_21473.262 V_24649.691 | Acc: T_0.000) V_0.000\n",
      "Epoch 670: : Loss: T_21054.057 V_24947.533 | Acc: T_0.000) V_0.000\n",
      "Epoch 680: : Loss: T_21143.086 V_24897.098 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24455.423828125\n",
      "Epoch 690: : Loss: T_20460.273 V_24455.424 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  24400.537109375\n",
      "Epoch 700: : Loss: T_20597.131 V_24400.537 | Acc: T_0.000) V_0.000\n",
      "Epoch 710: : Loss: T_20257.764 V_24524.197 | Acc: T_0.000) V_0.000\n",
      "Epoch 720: : Loss: T_20111.283 V_24443.861 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23960.37890625\n",
      "Epoch 730: : Loss: T_19859.135 V_23960.379 | Acc: T_0.000) V_0.000\n",
      "Epoch 740: : Loss: T_19862.148 V_23978.105 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23751.19921875\n",
      "Epoch 750: : Loss: T_19695.992 V_23751.199 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23442.943359375\n",
      "Epoch 760: : Loss: T_19320.262 V_23442.943 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  23200.21875\n",
      "Epoch 770: : Loss: T_19680.014 V_23200.219 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22924.76953125\n",
      "Epoch 780: : Loss: T_19128.553 V_22924.770 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22832.259765625\n",
      "Epoch 790: : Loss: T_19325.539 V_22832.260 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22512.9921875\n",
      "Epoch 800: : Loss: T_19136.895 V_22512.992 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22397.5234375\n",
      "Epoch 810: : Loss: T_19120.949 V_22397.523 | Acc: T_0.000) V_0.000\n",
      "Epoch 820: : Loss: T_18873.990 V_22702.852 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22316.96875\n",
      "Epoch 830: : Loss: T_18246.352 V_22316.969 | Acc: T_0.000) V_0.000\n",
      "Epoch 840: : Loss: T_18720.256 V_22369.373 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  22265.39453125\n",
      "Epoch 850: : Loss: T_18237.008 V_22265.395 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21871.61328125\n",
      "Epoch 860: : Loss: T_17993.268 V_21871.613 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21801.791015625\n",
      "Epoch 870: : Loss: T_18182.801 V_21801.791 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21536.787109375\n",
      "Epoch 880: : Loss: T_17916.863 V_21536.787 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21183.171875\n",
      "Epoch 890: : Loss: T_17794.418 V_21183.172 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  21079.841796875\n",
      "Epoch 900: : Loss: T_17531.039 V_21079.842 | Acc: T_0.000) V_0.000\n",
      "Epoch 910: : Loss: T_17399.842 V_21169.453 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20595.283203125\n",
      "Epoch 920: : Loss: T_17464.496 V_20595.283 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20578.57421875\n",
      "Epoch 930: : Loss: T_17087.613 V_20578.574 | Acc: T_0.000) V_0.000\n",
      "Epoch 940: : Loss: T_17027.334 V_20813.758 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20570.365234375\n",
      "Epoch 950: : Loss: T_16336.935 V_20570.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  20530.2890625\n",
      "Epoch 960: : Loss: T_16998.467 V_20530.289 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19756.939453125\n",
      "Epoch 970: : Loss: T_16434.971 V_19756.939 | Acc: T_0.000) V_0.000\n",
      "Epoch 980: : Loss: T_16771.139 V_19886.225 | Acc: T_0.000) V_0.000\n",
      "Epoch 990: : Loss: T_16647.982 V_19828.490 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19673.705078125\n",
      "Epoch 1000: : Loss: T_16235.227 V_19673.705 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19295.25\n",
      "Epoch 1010: : Loss: T_15868.658 V_19295.250 | Acc: T_0.000) V_0.000\n",
      "Epoch 1020: : Loss: T_16116.718 V_19401.000 | Acc: T_0.000) V_0.000\n",
      "Epoch 1030: : Loss: T_16347.688 V_19415.365 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  19013.62109375\n",
      "Epoch 1040: : Loss: T_15966.174 V_19013.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18841.98046875\n",
      "Epoch 1050: : Loss: T_15490.559 V_18841.980 | Acc: T_0.000) V_0.000\n",
      "Epoch 1060: : Loss: T_15678.111 V_18891.225 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18729.626953125\n",
      "Epoch 1070: : Loss: T_14919.787 V_18729.627 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  18470.455078125\n",
      "Epoch 1080: : Loss: T_15772.553 V_18470.455 | Acc: T_0.000) V_0.000\n",
      "Epoch 1090: : Loss: T_15242.948 V_18630.268 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17997.822265625\n",
      "Epoch 1100: : Loss: T_14760.524 V_17997.822 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17759.509765625\n",
      "Epoch 1110: : Loss: T_14557.380 V_17759.510 | Acc: T_0.000) V_0.000\n",
      "Epoch 1120: : Loss: T_14300.736 V_17900.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17511.26953125\n",
      "Epoch 1130: : Loss: T_14436.484 V_17511.270 | Acc: T_0.000) V_0.000\n",
      "Epoch 1140: : Loss: T_14696.357 V_17800.719 | Acc: T_0.000) V_0.000\n",
      "Epoch 1150: : Loss: T_14752.867 V_17547.018 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  17188.412109375\n",
      "Epoch 1160: : Loss: T_14273.613 V_17188.412 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16916.6171875\n",
      "Epoch 1170: : Loss: T_14217.245 V_16916.617 | Acc: T_0.000) V_0.000\n",
      "Epoch 1180: : Loss: T_14019.053 V_16966.160 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16770.86328125\n",
      "Epoch 1190: : Loss: T_14046.485 V_16770.863 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16723.9453125\n",
      "Epoch 1200: : Loss: T_13613.480 V_16723.945 | Acc: T_0.000) V_0.000\n",
      "Epoch 1210: : Loss: T_13893.757 V_17033.693 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16313.0087890625\n",
      "Epoch 1220: : Loss: T_13316.874 V_16313.009 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  16144.0400390625\n",
      "Epoch 1230: : Loss: T_13536.280 V_16144.040 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15990.8359375\n",
      "Epoch 1240: : Loss: T_13194.804 V_15990.836 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15886.763671875\n",
      "Epoch 1250: : Loss: T_12951.431 V_15886.764 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15813.6005859375\n",
      "Epoch 1260: : Loss: T_13381.582 V_15813.601 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15474.1923828125\n",
      "Epoch 1270: : Loss: T_12758.938 V_15474.192 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15310.3291015625\n",
      "Epoch 1280: : Loss: T_12481.007 V_15310.329 | Acc: T_0.000) V_0.000\n",
      "Epoch 1290: : Loss: T_12688.231 V_15536.097 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  15196.8134765625\n",
      "Epoch 1300: : Loss: T_12493.961 V_15196.813 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14848.8349609375\n",
      "Epoch 1310: : Loss: T_12382.408 V_14848.835 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14728.2412109375\n",
      "Epoch 1320: : Loss: T_12115.051 V_14728.241 | Acc: T_0.000) V_0.000\n",
      "Epoch 1330: : Loss: T_12509.396 V_14813.180 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14662.1025390625\n",
      "Epoch 1340: : Loss: T_11582.841 V_14662.103 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  14365.46875\n",
      "Epoch 1350: : Loss: T_11904.858 V_14365.469 | Acc: T_0.000) V_0.000\n",
      "Epoch 1360: : Loss: T_12103.435 V_14433.583 | Acc: T_0.000) V_0.000\n",
      "Epoch 1370: : Loss: T_11769.792 V_14493.637 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13952.35546875\n",
      "Epoch 1380: : Loss: T_11752.224 V_13952.355 | Acc: T_0.000) V_0.000\n",
      "Epoch 1390: : Loss: T_11345.822 V_14011.607 | Acc: T_0.000) V_0.000\n",
      "Epoch 1400: : Loss: T_11467.056 V_14046.711 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13868.7294921875\n",
      "Epoch 1410: : Loss: T_11180.806 V_13868.729 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13430.01953125\n",
      "Epoch 1420: : Loss: T_11110.053 V_13430.020 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  13159.6484375\n",
      "Epoch 1430: : Loss: T_10836.233 V_13159.648 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12952.6884765625\n",
      "Epoch 1440: : Loss: T_10889.175 V_12952.688 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12633.3662109375\n",
      "Epoch 1450: : Loss: T_10920.530 V_12633.366 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12619.701171875\n",
      "Epoch 1460: : Loss: T_10257.348 V_12619.701 | Acc: T_0.000) V_0.000\n",
      "Epoch 1470: : Loss: T_10600.481 V_12769.548 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12565.56640625\n",
      "Epoch 1480: : Loss: T_10619.104 V_12565.566 | Acc: T_0.000) V_0.000\n",
      "Epoch 1490: : Loss: T_10537.489 V_12581.658 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12487.6796875\n",
      "Epoch 1500: : Loss: T_10145.322 V_12487.680 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  12197.853515625\n",
      "Epoch 1510: : Loss: T_10226.255 V_12197.854 | Acc: T_0.000) V_0.000\n",
      "Epoch 1520: : Loss: T_9978.724 V_12274.263 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11856.5712890625\n",
      "Epoch 1530: : Loss: T_9878.152 V_11856.571 | Acc: T_0.000) V_0.000\n",
      "Epoch 1540: : Loss: T_9520.338 V_12168.780 | Acc: T_0.000) V_0.000\n",
      "Epoch 1550: : Loss: T_9744.995 V_12011.587 | Acc: T_0.000) V_0.000\n",
      "Epoch 1560: : Loss: T_9794.974 V_11940.091 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11590.53125\n",
      "Epoch 1570: : Loss: T_9782.906 V_11590.531 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11537.9775390625\n",
      "Epoch 1580: : Loss: T_9784.565 V_11537.978 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11186.2451171875\n",
      "Epoch 1590: : Loss: T_9451.818 V_11186.245 | Acc: T_0.000) V_0.000\n",
      "Epoch 1600: : Loss: T_9312.170 V_11256.995 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  11147.908203125\n",
      "Epoch 1610: : Loss: T_9473.554 V_11147.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10956.3076171875\n",
      "Epoch 1620: : Loss: T_8480.886 V_10956.308 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10814.087890625\n",
      "Epoch 1630: : Loss: T_9410.774 V_10814.088 | Acc: T_0.000) V_0.000\n",
      "Epoch 1640: : Loss: T_8979.870 V_10852.430 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10509.17578125\n",
      "Epoch 1650: : Loss: T_9064.984 V_10509.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10451.0654296875\n",
      "Epoch 1660: : Loss: T_8918.694 V_10451.065 | Acc: T_0.000) V_0.000\n",
      "Epoch 1670: : Loss: T_8545.536 V_10591.142 | Acc: T_0.000) V_0.000\n",
      "Epoch 1680: : Loss: T_8398.180 V_10542.329 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10316.990234375\n",
      "Epoch 1690: : Loss: T_8752.060 V_10316.990 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10119.3916015625\n",
      "Epoch 1700: : Loss: T_8362.294 V_10119.392 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  10009.6171875\n",
      "Epoch 1710: : Loss: T_8472.778 V_10009.617 | Acc: T_0.000) V_0.000\n",
      "Epoch 1720: : Loss: T_7771.292 V_10029.520 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9819.4404296875\n",
      "Epoch 1730: : Loss: T_7746.954 V_9819.440 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9481.955078125\n",
      "Epoch 1740: : Loss: T_7972.360 V_9481.955 | Acc: T_0.000) V_0.000\n",
      "Epoch 1750: : Loss: T_7590.115 V_9897.021 | Acc: T_0.000) V_0.000\n",
      "Epoch 1760: : Loss: T_8264.265 V_9591.184 | Acc: T_0.000) V_0.000\n",
      "Epoch 1770: : Loss: T_7483.140 V_9488.470 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9377.0107421875\n",
      "Epoch 1780: : Loss: T_7726.383 V_9377.011 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9278.04296875\n",
      "Epoch 1790: : Loss: T_7801.708 V_9278.043 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  9138.6376953125\n",
      "Epoch 1800: : Loss: T_6888.659 V_9138.638 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8896.3720703125\n",
      "Epoch 1810: : Loss: T_7241.254 V_8896.372 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8880.6103515625\n",
      "Epoch 1820: : Loss: T_7261.469 V_8880.610 | Acc: T_0.000) V_0.000\n",
      "Epoch 1830: : Loss: T_7216.154 V_8966.200 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8663.5400390625\n",
      "Epoch 1840: : Loss: T_7183.120 V_8663.540 | Acc: T_0.000) V_0.000\n",
      "Epoch 1850: : Loss: T_6293.447 V_8747.066 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8473.255859375\n",
      "Epoch 1860: : Loss: T_6922.185 V_8473.256 | Acc: T_0.000) V_0.000\n",
      "Epoch 1870: : Loss: T_7111.798 V_8569.051 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8378.8017578125\n",
      "Epoch 1880: : Loss: T_6301.399 V_8378.802 | Acc: T_0.000) V_0.000\n",
      "Epoch 1890: : Loss: T_6852.278 V_8560.211 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8234.9453125\n",
      "Epoch 1900: : Loss: T_6594.768 V_8234.945 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8156.79296875\n",
      "Epoch 1910: : Loss: T_6598.668 V_8156.793 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8095.3994140625\n",
      "Epoch 1920: : Loss: T_6794.560 V_8095.399 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  8007.66796875\n",
      "Epoch 1930: : Loss: T_6438.479 V_8007.668 | Acc: T_0.000) V_0.000\n",
      "Epoch 1940: : Loss: T_6515.142 V_8131.944 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7703.61962890625\n",
      "Epoch 1950: : Loss: T_6777.531 V_7703.620 | Acc: T_0.000) V_0.000\n",
      "Epoch 1960: : Loss: T_6670.831 V_7834.958 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7669.62158203125\n",
      "Epoch 1970: : Loss: T_6108.906 V_7669.622 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7589.38037109375\n",
      "Epoch 1980: : Loss: T_6587.264 V_7589.380 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7579.54052734375\n",
      "Epoch 1990: : Loss: T_5883.488 V_7579.541 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7504.662109375\n",
      "Epoch 2000: : Loss: T_6242.762 V_7504.662 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7335.98095703125\n",
      "Epoch 2010: : Loss: T_5830.122 V_7335.981 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7309.638671875\n",
      "Epoch 2020: : Loss: T_5833.370 V_7309.639 | Acc: T_0.000) V_0.000\n",
      "Epoch 2030: : Loss: T_5513.040 V_7523.381 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7169.3564453125\n",
      "Epoch 2040: : Loss: T_5784.694 V_7169.356 | Acc: T_0.000) V_0.000\n",
      "Epoch 2050: : Loss: T_6228.205 V_7198.153 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  7152.62060546875\n",
      "Epoch 2060: : Loss: T_5716.910 V_7152.621 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6940.90771484375\n",
      "Epoch 2070: : Loss: T_5542.606 V_6940.908 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6932.7744140625\n",
      "Epoch 2080: : Loss: T_5461.699 V_6932.774 | Acc: T_0.000) V_0.000\n",
      "Epoch 2090: : Loss: T_5452.646 V_6987.683 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6875.12109375\n",
      "Epoch 2100: : Loss: T_5779.449 V_6875.121 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6849.38427734375\n",
      "Epoch 2110: : Loss: T_5177.167 V_6849.384 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6588.00830078125\n",
      "Epoch 2120: : Loss: T_5313.052 V_6588.008 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6583.5927734375\n",
      "Epoch 2130: : Loss: T_5296.938 V_6583.593 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6564.42626953125\n",
      "Epoch 2140: : Loss: T_5403.837 V_6564.426 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6476.35205078125\n",
      "Epoch 2150: : Loss: T_6011.350 V_6476.352 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6378.583984375\n",
      "Epoch 2160: : Loss: T_5348.311 V_6378.584 | Acc: T_0.000) V_0.000\n",
      "Epoch 2170: : Loss: T_5345.507 V_6403.553 | Acc: T_0.000) V_0.000\n",
      "Epoch 2180: : Loss: T_5058.623 V_6383.120 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6343.87060546875\n",
      "Epoch 2190: : Loss: T_5335.041 V_6343.871 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6281.03515625\n",
      "Epoch 2200: : Loss: T_5016.170 V_6281.035 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6221.81396484375\n",
      "Epoch 2210: : Loss: T_4722.316 V_6221.814 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6123.27685546875\n",
      "Epoch 2220: : Loss: T_4576.621 V_6123.277 | Acc: T_0.000) V_0.000\n",
      "Epoch 2230: : Loss: T_5204.302 V_6180.041 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  6073.3720703125\n",
      "Epoch 2240: : Loss: T_5045.074 V_6073.372 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5883.40185546875\n",
      "Epoch 2250: : Loss: T_5172.206 V_5883.402 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5857.06640625\n",
      "Epoch 2260: : Loss: T_5197.771 V_5857.066 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5824.3369140625\n",
      "Epoch 2270: : Loss: T_4882.053 V_5824.337 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5800.36669921875\n",
      "Epoch 2280: : Loss: T_4662.188 V_5800.367 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5745.30908203125\n",
      "Epoch 2290: : Loss: T_4541.599 V_5745.309 | Acc: T_0.000) V_0.000\n",
      "Epoch 2300: : Loss: T_4914.466 V_5800.193 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5725.17724609375\n",
      "Epoch 2310: : Loss: T_4315.101 V_5725.177 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5530.2900390625\n",
      "Epoch 2320: : Loss: T_4948.208 V_5530.290 | Acc: T_0.000) V_0.000\n",
      "Epoch 2330: : Loss: T_4681.923 V_5796.762 | Acc: T_0.000) V_0.000\n",
      "Epoch 2340: : Loss: T_4669.722 V_5670.382 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5306.931640625\n",
      "Epoch 2350: : Loss: T_4436.720 V_5306.932 | Acc: T_0.000) V_0.000\n",
      "Epoch 2360: : Loss: T_4869.694 V_5454.891 | Acc: T_0.000) V_0.000\n",
      "Epoch 2370: : Loss: T_5207.695 V_5511.325 | Acc: T_0.000) V_0.000\n",
      "Epoch 2380: : Loss: T_4408.291 V_5444.296 | Acc: T_0.000) V_0.000\n",
      "Epoch 2390: : Loss: T_4397.234 V_5342.740 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5281.9716796875\n",
      "Epoch 2400: : Loss: T_4523.224 V_5281.972 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5202.787109375\n",
      "Epoch 2410: : Loss: T_4496.341 V_5202.787 | Acc: T_0.000) V_0.000\n",
      "Epoch 2420: : Loss: T_3929.404 V_5389.898 | Acc: T_0.000) V_0.000\n",
      "Epoch 2430: : Loss: T_4314.035 V_5297.080 | Acc: T_0.000) V_0.000\n",
      "Epoch 2440: : Loss: T_4442.811 V_5236.016 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5084.77001953125\n",
      "Epoch 2450: : Loss: T_4227.309 V_5084.770 | Acc: T_0.000) V_0.000\n",
      "Epoch 2460: : Loss: T_4450.017 V_5161.773 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5053.201171875\n",
      "Epoch 2470: : Loss: T_4459.419 V_5053.201 | Acc: T_0.000) V_0.000\n",
      "Epoch 2480: : Loss: T_4345.140 V_5082.962 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  5010.1181640625\n",
      "Epoch 2490: : Loss: T_4633.863 V_5010.118 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4970.7646484375\n",
      "Epoch 2500: : Loss: T_4817.775 V_4970.765 | Acc: T_0.000) V_0.000\n",
      "Epoch 2510: : Loss: T_4399.789 V_4985.469 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4939.029296875\n",
      "Epoch 2520: : Loss: T_4529.516 V_4939.029 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4880.138671875\n",
      "Epoch 2530: : Loss: T_3903.084 V_4880.139 | Acc: T_0.000) V_0.000\n",
      "Epoch 2540: : Loss: T_4194.772 V_4941.114 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4848.09716796875\n",
      "Epoch 2550: : Loss: T_4487.237 V_4848.097 | Acc: T_0.000) V_0.000\n",
      "Epoch 2560: : Loss: T_4399.804 V_4941.205 | Acc: T_0.000) V_0.000\n",
      "Epoch 2570: : Loss: T_4372.137 V_4915.749 | Acc: T_0.000) V_0.000\n",
      "Epoch 2580: : Loss: T_4964.493 V_4879.218 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4823.1416015625\n",
      "Epoch 2590: : Loss: T_4098.777 V_4823.142 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4820.89111328125\n",
      "Epoch 2600: : Loss: T_4201.451 V_4820.891 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4551.50390625\n",
      "Epoch 2610: : Loss: T_3668.351 V_4551.504 | Acc: T_0.000) V_0.000\n",
      "Epoch 2620: : Loss: T_4446.733 V_4827.777 | Acc: T_0.000) V_0.000\n",
      "Epoch 2630: : Loss: T_4571.075 V_4701.666 | Acc: T_0.000) V_0.000\n",
      "Epoch 2640: : Loss: T_4524.793 V_4672.261 | Acc: T_0.000) V_0.000\n",
      "Epoch 2650: : Loss: T_4643.816 V_4571.558 | Acc: T_0.000) V_0.000\n",
      "Epoch 2660: : Loss: T_4767.882 V_4761.883 | Acc: T_0.000) V_0.000\n",
      "Epoch 2670: : Loss: T_4269.855 V_4611.887 | Acc: T_0.000) V_0.000\n",
      "Epoch 2680: : Loss: T_4374.950 V_4714.165 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4539.265625\n",
      "Epoch 2690: : Loss: T_3772.923 V_4539.266 | Acc: T_0.000) V_0.000\n",
      "Epoch 2700: : Loss: T_3653.566 V_4588.056 | Acc: T_0.000) V_0.000\n",
      "Epoch 2710: : Loss: T_4619.715 V_4601.534 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4507.416015625\n",
      "Epoch 2720: : Loss: T_4675.596 V_4507.416 | Acc: T_0.000) V_0.000\n",
      "Epoch 2730: : Loss: T_3829.899 V_4536.409 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4430.6201171875\n",
      "Epoch 2740: : Loss: T_4342.826 V_4430.620 | Acc: T_0.000) V_0.000\n",
      "Epoch 2750: : Loss: T_4186.047 V_4533.506 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4367.9765625\n",
      "Epoch 2760: : Loss: T_4413.928 V_4367.977 | Acc: T_0.000) V_0.000\n",
      "Epoch 2770: : Loss: T_3637.872 V_4451.933 | Acc: T_0.000) V_0.000\n",
      "Epoch 2780: : Loss: T_4112.443 V_4630.661 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4361.4248046875\n",
      "Epoch 2790: : Loss: T_3924.200 V_4361.425 | Acc: T_0.000) V_0.000\n",
      "Epoch 2800: : Loss: T_4063.569 V_4437.001 | Acc: T_0.000) V_0.000\n",
      "Epoch 2810: : Loss: T_4254.935 V_4390.855 | Acc: T_0.000) V_0.000\n",
      "Epoch 2820: : Loss: T_3673.254 V_4459.434 | Acc: T_0.000) V_0.000\n",
      "Epoch 2830: : Loss: T_4425.595 V_4411.223 | Acc: T_0.000) V_0.000\n",
      "Epoch 2840: : Loss: T_4489.347 V_4372.334 | Acc: T_0.000) V_0.000\n",
      "Epoch 2850: : Loss: T_4557.729 V_4371.440 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4325.53857421875\n",
      "Epoch 2860: : Loss: T_4805.668 V_4325.539 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4222.25732421875\n",
      "Epoch 2870: : Loss: T_4357.302 V_4222.257 | Acc: T_0.000) V_0.000\n",
      "Epoch 2880: : Loss: T_3885.665 V_4301.441 | Acc: T_0.000) V_0.000\n",
      "Epoch 2890: : Loss: T_3440.170 V_4348.403 | Acc: T_0.000) V_0.000\n",
      "Epoch 2900: : Loss: T_3685.625 V_4322.239 | Acc: T_0.000) V_0.000\n",
      "Epoch 2910: : Loss: T_4140.806 V_4360.422 | Acc: T_0.000) V_0.000\n",
      "Epoch 2920: : Loss: T_3872.845 V_4309.170 | Acc: T_0.000) V_0.000\n",
      "Epoch 2930: : Loss: T_3924.538 V_4290.469 | Acc: T_0.000) V_0.000\n",
      "Epoch 2940: : Loss: T_4374.175 V_4354.615 | Acc: T_0.000) V_0.000\n",
      "Epoch 2950: : Loss: T_4253.541 V_4369.078 | Acc: T_0.000) V_0.000\n",
      "Epoch 2960: : Loss: T_3620.012 V_4313.327 | Acc: T_0.000) V_0.000\n",
      "Epoch 2970: : Loss: T_3899.277 V_4308.660 | Acc: T_0.000) V_0.000\n",
      "Epoch 2980: : Loss: T_3846.794 V_4436.246 | Acc: T_0.000) V_0.000\n",
      "Epoch 2990: : Loss: T_3700.584 V_4232.108 | Acc: T_0.000) V_0.000\n",
      "Epoch 3000: : Loss: T_4355.922 V_4275.622 | Acc: T_0.000) V_0.000\n",
      "Epoch 3010: : Loss: T_4026.248 V_4306.673 | Acc: T_0.000) V_0.000\n",
      "Epoch 3020: : Loss: T_4082.583 V_4296.312 | Acc: T_0.000) V_0.000\n",
      "Epoch 3030: : Loss: T_3824.302 V_4237.211 | Acc: T_0.000) V_0.000\n",
      "Epoch 3040: : Loss: T_3769.724 V_4293.056 | Acc: T_0.000) V_0.000\n",
      "Epoch 3050: : Loss: T_3822.160 V_4229.357 | Acc: T_0.000) V_0.000\n",
      "Epoch 3060: : Loss: T_3430.513 V_4293.247 | Acc: T_0.000) V_0.000\n",
      "Epoch 3070: : Loss: T_3709.561 V_4262.568 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4184.34423828125\n",
      "Epoch 3080: : Loss: T_3946.553 V_4184.344 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4119.1416015625\n",
      "Epoch 3090: : Loss: T_3794.073 V_4119.142 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4088.985107421875\n",
      "Epoch 3100: : Loss: T_3768.991 V_4088.985 | Acc: T_0.000) V_0.000\n",
      "Epoch 3110: : Loss: T_4104.778 V_4174.934 | Acc: T_0.000) V_0.000\n",
      "Epoch 3120: : Loss: T_3602.309 V_4202.138 | Acc: T_0.000) V_0.000\n",
      "Epoch 3130: : Loss: T_3917.581 V_4135.732 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4086.342041015625\n",
      "Epoch 3140: : Loss: T_4190.153 V_4086.342 | Acc: T_0.000) V_0.000\n",
      "Epoch 3150: : Loss: T_4045.118 V_4188.159 | Acc: T_0.000) V_0.000\n",
      "Epoch 3160: : Loss: T_4070.819 V_4139.395 | Acc: T_0.000) V_0.000\n",
      "Epoch 3170: : Loss: T_4721.074 V_4227.860 | Acc: T_0.000) V_0.000\n",
      "Epoch 3180: : Loss: T_4237.088 V_4217.521 | Acc: T_0.000) V_0.000\n",
      "Epoch 3190: : Loss: T_3821.264 V_4192.170 | Acc: T_0.000) V_0.000\n",
      "Epoch 3200: : Loss: T_3477.977 V_4259.520 | Acc: T_0.000) V_0.000\n",
      "Epoch 3210: : Loss: T_3775.364 V_4148.936 | Acc: T_0.000) V_0.000\n",
      "Epoch 3220: : Loss: T_3871.548 V_4158.402 | Acc: T_0.000) V_0.000\n",
      "Epoch 3230: : Loss: T_4198.644 V_4118.596 | Acc: T_0.000) V_0.000\n",
      "Epoch 3240: : Loss: T_3898.837 V_4096.602 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  4034.732421875\n",
      "Epoch 3250: : Loss: T_4011.556 V_4034.732 | Acc: T_0.000) V_0.000\n",
      "Epoch 3260: : Loss: T_4090.122 V_4206.108 | Acc: T_0.000) V_0.000\n",
      "Epoch 3270: : Loss: T_4187.280 V_4155.887 | Acc: T_0.000) V_0.000\n",
      "Epoch 3280: : Loss: T_3893.021 V_4125.315 | Acc: T_0.000) V_0.000\n",
      "Epoch 3290: : Loss: T_4254.446 V_4078.095 | Acc: T_0.000) V_0.000\n",
      "Epoch 3300: : Loss: T_3690.942 V_4284.176 | Acc: T_0.000) V_0.000\n",
      "Best Model is copied - Best Loss :  3961.9140625\n",
      "Epoch 3310: : Loss: T_3631.668 V_3961.914 | Acc: T_0.000) V_0.000\n",
      "Epoch 3320: : Loss: T_4064.212 V_4099.749 | Acc: T_0.000) V_0.000\n",
      "Epoch 3330: : Loss: T_4049.062 V_4142.282 | Acc: T_0.000) V_0.000\n",
      "Epoch 3340: : Loss: T_3984.694 V_4042.900 | Acc: T_0.000) V_0.000\n",
      "Epoch 3350: : Loss: T_3910.098 V_4100.470 | Acc: T_0.000) V_0.000\n",
      "Epoch 3360: : Loss: T_4413.575 V_4079.468 | Acc: T_0.000) V_0.000\n",
      "Epoch 3370: : Loss: T_3794.796 V_4130.592 | Acc: T_0.000) V_0.000\n",
      "Epoch 3380: : Loss: T_4222.061 V_4151.721 | Acc: T_0.000) V_0.000\n",
      "Epoch 3390: : Loss: T_3575.722 V_4119.776 | Acc: T_0.000) V_0.000\n",
      "Epoch 3400: : Loss: T_3660.505 V_4068.077 | Acc: T_0.000) V_0.000\n",
      "Epoch 3410: : Loss: T_3665.461 V_4065.124 | Acc: T_0.000) V_0.000\n",
      "Epoch 3420: : Loss: T_4525.797 V_4018.543 | Acc: T_0.000) V_0.000\n",
      "Epoch 3430: : Loss: T_3991.313 V_4148.398 | Acc: T_0.000) V_0.000\n",
      "Epoch 3440: : Loss: T_3995.808 V_4061.979 | Acc: T_0.000) V_0.000\n",
      "Epoch 3450: : Loss: T_3878.184 V_4157.892 | Acc: T_0.000) V_0.000\n",
      "Epoch 3460: : Loss: T_4436.620 V_4035.118 | Acc: T_0.000) V_0.000\n",
      "Epoch 3470: : Loss: T_3968.292 V_4015.760 | Acc: T_0.000) V_0.000\n",
      "Epoch 3480: : Loss: T_3802.420 V_4086.682 | Acc: T_0.000) V_0.000\n",
      "Epoch 3490: : Loss: T_4060.546 V_4032.160 | Acc: T_0.000) V_0.000\n",
      "Epoch 3500: : Loss: T_3647.178 V_4002.730 | Acc: T_0.000) V_0.000\n"
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "for i in range(NUM_ENSEMBLE_MODELS):\n",
    "    model = BasicRegressor()\n",
    "    model.to(device)\n",
    "\n",
    "    # criterion = nn.L1Loss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    bagg_indices = np.random.choice(range(len(x_train)), len(x_train), replace=True)\n",
    "    # x_train_bagg = x_train[bagg_indices, :]\n",
    "    # y_train_bagg = y_train[bagg_indices, :]\n",
    "\n",
    "    rare_indicies = np.where(y_train>threshold_rare)[0]\n",
    "    normal_indicies = np.where(y_train<=threshold_rare)[0]\n",
    "\n",
    "    ov_rare_indicies = np.random.choice(range(len(rare_indicies)), len(normal_indicies), replace=True)\n",
    "\n",
    "    x_train_normal_bagg = x_train[normal_indicies, :]\n",
    "    y_train_normal_bagg = y_train[normal_indicies, :]\n",
    "\n",
    "\n",
    "    x_train_rare_bagg = x_train[rare_indicies, :]\n",
    "    y_train_rare_bagg = y_train[rare_indicies, :]\n",
    "\n",
    "\n",
    "    x_train_total_bagg = np.append(x_train_normal_bagg, x_train_rare_bagg, axis=0)\n",
    "    y_train_total_bagg = np.append(y_train_normal_bagg, y_train_rare_bagg, axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # train_data = TrainData(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "    train_data = TrainData(torch.FloatTensor(x_train_total_bagg), torch.FloatTensor(y_train_total_bagg))\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "\n",
    "    num_train_data = len(train_loader)\n",
    "    num_eval_data = len(valid_loader)\n",
    "\n",
    "\n",
    "    elapsed_time_basic_ann = []\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    best_model = train_model(num_train_data, num_eval_data)\n",
    "\n",
    "    best_models.append(best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "sum_output = np.zeros(y_test.shape)\n",
    "\n",
    "for best_model in best_models:\n",
    "    best_model.eval()\n",
    "    output = best_model(data)\n",
    "    sum_output += output.detach().numpy()\n",
    "\n",
    "avg_output = sum_output / len(best_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare Loss  89.92431640625\n",
      "Normal Loss  37.661736071367805\n",
      "Total Loss  44.708376116520455\n"
     ]
    }
   ],
   "source": [
    "rare_loss, normal_loss, total_loss = calc_l1_loss_by_shots(avg_output, answer.detach().numpy())\n",
    "print(\"Rare Loss \", rare_loss)\n",
    "print(\"Normal Loss \", normal_loss)\n",
    "print(\"Total Loss \", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [656], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mzero\n",
      "File \u001b[1;32mc:\\venv_python_3.10\\lib\\site-packages\\numpy\\__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 311\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zero'"
     ]
    }
   ],
   "source": [
    "np.zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89, 1])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum_output = np.zeros([output.shape[0], output.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 1)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BasicRegressor(\n",
       "   (layer_1): Linear(in_features=10, out_features=32, bias=True)\n",
       "   (layer_2): Linear(in_features=32, out_features=16, bias=True)\n",
       "   (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
       "   (actvation_1): ReLU()\n",
       "   (actvation_2): ReLU()\n",
       "   (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "   (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "   (batchnorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (batchnorm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " BasicRegressor(\n",
       "   (layer_1): Linear(in_features=10, out_features=32, bias=True)\n",
       "   (layer_2): Linear(in_features=32, out_features=16, bias=True)\n",
       "   (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
       "   (actvation_1): ReLU()\n",
       "   (actvation_2): ReLU()\n",
       "   (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "   (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "   (batchnorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (batchnorm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " BasicRegressor(\n",
       "   (layer_1): Linear(in_features=10, out_features=32, bias=True)\n",
       "   (layer_2): Linear(in_features=32, out_features=16, bias=True)\n",
       "   (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
       "   (actvation_1): ReLU()\n",
       "   (actvation_2): ReLU()\n",
       "   (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "   (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "   (batchnorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (batchnorm_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " )]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv_python_3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78d04299e464758119aa473303693f33db2a1bc5c94011f00bbd9c1618e77f98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
